{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.0-beta1', '2.2.4-tf')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAKN0lEQVR4nO3d20rWWx/F8WllWeYuUwtCSsIMCkqKiCDIrqOjovPooDvoIjrpCjrrHhZC1EHuyHaWFaXltkxts87eo/UfI3xe1zMe1vdzOpg+mxz9wR9zzqbfv38XAHl21PsNAPhnlBMIRTmBUJQTCEU5gVC7TM6fcvF/4yYDTU1N/9I7ifOPH5wnJxCKcgKhKCcQinICoSgnEIpyAqEoJxDKzTmxDcbGxiqzBw8eyLWjo6My//nzp8wPHTok85MnT1ZmV65ckWsvXLgg8//wHHNLeHICoSgnEIpyAqEoJxCKcgKhKCcQinICoZhzbsHExITMr1+/LvNHjx5VZj9+/JBrd+3S/2Q7duj/b13+/fv3La8dHByU+e3bt2V+48YNmf/X8OQEQlFOIBTlBEJRTiAU5QRCUU4gVJM5rrBhj8b89etXZeZGAk5fX5/M5+fnZd7R0VGZueMjm5ubZe5GMTt37pS523KmLCwsyPzIkSMyf/v27ZZfu1Z1PraTozGBRkI5gVCUEwhFOYFQlBMIRTmBUJQTCNWwW8bUHLOU2maZi4uLMndzzpaWFpnv27evMhsaGpJr3XY1N49z713NOd+8eSPXdnZ2yrytrU3mjx8/rsyGh4flWmc7f1+2S947AlBKoZxALMoJhKKcQCjKCYSinEAoygmEit3PuZ1zqYsXL8p8ZmZG5u69uVnj0tJSZaau4CullOXlZZm/ePFC5m4Ge+LEicrMzSndfkx17GYppWxsbFRm7t97bm5O5o7bx+r2wdaI/ZxAI6GcQCjKCYSinEAoygmEopxAKMoJhIrdz1nrOaF37typzJ4/fy7X9vf3y9ydDetmiWre52aFp06dkrmaoZbi91yq9/b69Wu51hkYGJC5Os/35cuXcu3Nmzdlfu/ePZlv8xxzS3hyAqEoJxCKcgKhKCcQinICoSgnECp2y1itLl++XJmtr6/LtW6Ms7a2JvM9e/bIfO/evZXZysqKXLt//36Zt7a2ytxtKVOvf+zYMbn28OHDMnff29evX7f0vkrx3/lff/0l8zpjyxjQSCgnEIpyAqEoJxCKcgKhKCcQinICoWK3jDnuKMMvX75UZmrOWEop7e3tMldX+JWij3h0uZvXuRltrcd2njt3rjJzM1Z3daLb9tXd3V2Z7dqlf1Xn5+dl7q4vdNsE64EnJxCKcgKhKCcQinICoSgnEIpyAqEoJxCqYeec7po+tf/Pzes2Nzdl7mZublapZrTu2E33s3t7e2XuZrBqT+WnT5/k2t27d8u8q6tL5up7cfNdd72gm4My5wTwxygnEIpyAqEoJxCKcgKhKCcQinICoRp2zun2Birfvn2TuZr1leLnpG4WqWaZ7mxXtxd1dXVV5u6zqxmum2O6a/Tce1teXq7M3Hm8bn/v+Pi4zIeHh2VeDzw5gVCUEwhFOYFQlBMIRTmBUJQTCEU5gVANO+d0c6sdO6r/31lYWJBr3717J/PTp0/L3M371CzT7bd059K2tbXJ3O0XVe/NzRLdfNftufz48WNldvDgQbnWfefufs5r167JvB54cgKhKCcQinICoSgnEIpyAqEoJxCqYUcps7OzMlcjB/dn99+/f8vcjQzcljN19KZ7b24U4o6QVCOmUkppbm6WueLemxulqO/NjYjctYxTU1MyT8STEwhFOYFQlBMIRTmBUJQTCEU5gVCUEwjVsHPOyclJmatZZVNTU02v7WaRbmuVmiW6WWCt3JYzNYN1Vx+6z+3WqyNH3WzZHds5NjYm80Q8OYFQlBMIRTmBUJQTCEU5gVCUEwhFOYFQDTvnfPr0qczVLFLN8v6Eu0bP7ZmsZQbrZoVuL2otM143I3V5S0uLzNWxoO5nO3NzczJ/9uyZzAcHB2t6/a3gyQmEopxAKMoJhKKcQCjKCYSinEAoygmEatg554cPH2R+4MCBysztmezs7JS5m7m5vYVqnudmgW5G686tddSc1O3XdK/tZqzq7Fn3ud2ZuY67UpI5J4D/oZxAKMoJhKKcQCjKCYSinEAoygmEatg5p9szqeZibh7nzkh1s0h3rq2a97n9mG6e5+7XdLNG9fPdXtJaPrd7bXfnqZstOx0dHTWt3w48OYFQlBMIRTmBUJQTCEU5gVCUEwjVsKMU92d59af1xcVFubanp0fmbqSwuroq871791Zma2trcq373K2trTJ3R0TW8tpqy1cppSwsLMj8+PHjldnU1JRc60ZrXV1dMndHY46MjMh8O/DkBEJRTiAU5QRCUU4gFOUEQlFOIBTlBELFzjndNXtue9L+/fsrs8+fP8u1Bw8elLnjZm7btbYUf+yn25Kmtpy5ozHdVjuXnz9/vjJ79eqVXOu2fLnZ9PT0tMzrgScnEIpyAqEoJxCKcgKhKCcQinICoSgnECp2zumOQnS5OmbR7Xns7e2V+fv372Wurh8spZSlpSWZK25PZa3r1ffmZrDuyNDZ2VmZqxlse3u7XDszMyNzd22ju1KyHnhyAqEoJxCKcgKhKCcQinICoSgnEIpyAqFi55zubFl19mspeu+hm3kNDAzIfHl5WeZuHqhy994ct2fSUd+bO5fWzTnb2tpkrv5N3Wu7ubebk6r9v/XCkxMIRTmBUJQTCEU5gVCUEwhFOYFQsaMUd1WdGxmo7UduFOKOl1THR5ZSyubmpsxrobZ0leKPDHXfmzqS1I2I3HGmtVyd6I7ldNzozX1v9cCTEwhFOYFQlBMIRTmBUJQTCEU5gVCUEwgVO+d0M7Pdu3fLXB0B6bYHdXd3y3xiYkLmtcxg3RV97nM77mhMNcOtdcZay/x3aGhI5g8fPpR5T0+PzN1nqweenEAoygmEopxAKMoJhKKcQCjKCYSinECo2DnnysqKzN0xjGqed/To0S2vLaWUz58/y9wdran2i7q9pG6G+uXLF5nPz8/LXB0h6eaYtcyeS9HX8F27dk2udXNOtwfX/T7VA09OIBTlBEJRTiAU5QRCUU4gFOUEQlFOIFTsnNNd6dbR0SFzde7tyMiIXHvo0CGZu6vs3DV+6+vrlZmbxzlufWdnp8zVflK3H9Pl7ho/NQe9evWqXOu4c2/d71s98OQEQlFOIBTlBEJRTiAU5QRCUU4gFOUEQsXOOd28zt31qOZ1Z8+elWtHR0dl/uTJE5m7M1bX1tYqM7fn0c1Ya51F1nI/58bGxpZ/din6fs6+vj651p1L62bPzDkB/DHKCYSinEAoygmEopxAKMoJhIodpbg/+bsjJJXp6WmZ379/X+b9/f0yX1hYkLn6s737XO7IUDeKccd2qpGDGnWU4rejufHYpUuXZK64MY4aX5VSyuTk5JZfe7vw5ARCUU4gFOUEQlFOIBTlBEJRTiAU5QRCxc45z5w5I/Ph4WGZj4+PV2Zuu5mbx929e1fm+PfdunVL5m67m9tGWA88OYFQlBMIRTmBUJQTCEU5gVCUEwhFOYFQTeoISQD1w5MTCEU5gVCUEwhFOYFQlBMIRTmBUH8DscHqopQEqFAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x7f3d09e23f98>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f3d09e23b70>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f3cec16a828>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f3cec1e0cf8>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04836924, -0.00301779, -0.02960113, ...,  0.01255327,\n",
       "         0.03751411,  0.00318331],\n",
       "       [ 0.01481455,  0.06253971,  0.05794524, ...,  0.03014015,\n",
       "         0.03942043,  0.07341835],\n",
       "       [ 0.01159307,  0.03827588,  0.05438061, ...,  0.04510576,\n",
       "         0.06978773, -0.05883701],\n",
       "       ...,\n",
       "       [ 0.05385295, -0.01222143,  0.06641772, ..., -0.05668993,\n",
       "         0.06249912, -0.03966956],\n",
       "       [ 0.02317949, -0.05119859,  0.03886479, ..., -0.01395891,\n",
       "         0.01342704, -0.06548519],\n",
       "       [-0.00371186, -0.03978826,  0.06928793, ...,  0.01517352,\n",
       "        -0.04981206, -0.02244623]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 20:54:36.428787 139902047606592 deprecation.py:323] From /home/joschi/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available:  True\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.6999 - accuracy: 0.7711 - val_loss: 0.5171 - val_accuracy: 0.8264\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4870 - accuracy: 0.8292 - val_loss: 0.4378 - val_accuracy: 0.8524\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.4426 - accuracy: 0.8448 - val_loss: 0.4192 - val_accuracy: 0.8556\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4134 - accuracy: 0.8556 - val_loss: 0.4038 - val_accuracy: 0.8610\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.3926 - accuracy: 0.8615 - val_loss: 0.4660 - val_accuracy: 0.8276\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.3786 - accuracy: 0.8668 - val_loss: 0.3822 - val_accuracy: 0.8658\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3658 - accuracy: 0.8705 - val_loss: 0.4076 - val_accuracy: 0.8534\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3544 - accuracy: 0.8739 - val_loss: 0.3530 - val_accuracy: 0.8746\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.3424 - accuracy: 0.8773 - val_loss: 0.3584 - val_accuracy: 0.8722\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3338 - accuracy: 0.8804 - val_loss: 0.3639 - val_accuracy: 0.8694\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.3250 - accuracy: 0.8835 - val_loss: 0.3440 - val_accuracy: 0.8766\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.3176 - accuracy: 0.8857 - val_loss: 0.3348 - val_accuracy: 0.8792\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.3105 - accuracy: 0.8882 - val_loss: 0.3371 - val_accuracy: 0.8794\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.3027 - accuracy: 0.8920 - val_loss: 0.3369 - val_accuracy: 0.8818\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.2960 - accuracy: 0.8931 - val_loss: 0.3345 - val_accuracy: 0.8784\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.2906 - accuracy: 0.8951 - val_loss: 0.3189 - val_accuracy: 0.8854\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2850 - accuracy: 0.8976 - val_loss: 0.3396 - val_accuracy: 0.8806\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2793 - accuracy: 0.8997 - val_loss: 0.3088 - val_accuracy: 0.8896\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2740 - accuracy: 0.9010 - val_loss: 0.3087 - val_accuracy: 0.8906\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2691 - accuracy: 0.9027 - val_loss: 0.3249 - val_accuracy: 0.8866\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2639 - accuracy: 0.9043 - val_loss: 0.3096 - val_accuracy: 0.8838\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2589 - accuracy: 0.9068 - val_loss: 0.3104 - val_accuracy: 0.8878\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2546 - accuracy: 0.9072 - val_loss: 0.3210 - val_accuracy: 0.8822\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2494 - accuracy: 0.9106 - val_loss: 0.3288 - val_accuracy: 0.8790\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2454 - accuracy: 0.9109 - val_loss: 0.2966 - val_accuracy: 0.8952\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2422 - accuracy: 0.9123 - val_loss: 0.2936 - val_accuracy: 0.8918\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.2378 - accuracy: 0.9148 - val_loss: 0.2944 - val_accuracy: 0.8914\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.2334 - accuracy: 0.9157 - val_loss: 0.2924 - val_accuracy: 0.8946\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2291 - accuracy: 0.9171 - val_loss: 0.2911 - val_accuracy: 0.8934\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.2250 - accuracy: 0.9196 - val_loss: 0.2976 - val_accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU available: \", tf.test.is_gpu_available())\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.3319 - accuracy: 0.8820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3318539241433144, 0.882]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97],\n",
       "       [0.  , 0.  , 0.98, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 1.2646 - val_loss: 0.6563\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n",
      "5160/5160 [==============================] - 0s 21us/sample - loss: nan\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20,\n",
    "                    validation_data=(X_valid_scaled, y_valid))\n",
    "mse_test = model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test_scaled[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5])\n",
    "input_B = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.8316 - val_loss: 0.5014\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.9013 - val_loss: 0.7760\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.5392 - val_loss: 0.4644\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4477 - val_loss: 0.4353\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4265 - val_loss: 0.4211\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4136 - val_loss: 0.4027\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4031 - val_loss: 0.3959\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3947 - val_loss: 0.3927\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3888 - val_loss: 0.3867\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3818 - val_loss: 0.3799\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3784 - val_loss: 0.3776\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3734 - val_loss: 0.3880\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3674 - val_loss: 0.3685\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3666 - val_loss: 0.3709\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3645 - val_loss: 0.3655\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3615 - val_loss: 0.3638\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3783 - val_loss: 0.3657\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3596 - val_loss: 0.3614\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3603 - val_loss: 0.3604\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3538 - val_loss: 0.3646\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3506 - val_loss: 0.3462\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3538 - val_loss: 0.3495\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3463 - val_loss: 0.3536\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3435 - val_loss: 0.3483\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3412 - val_loss: 0.3449\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3385 - val_loss: 0.3381\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3369 - val_loss: 0.3409\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3387 - val_loss: 0.3378\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3414 - val_loss: 0.3698\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3378 - val_loss: 0.3506\n",
      "5160/5160 [==============================] - 0s 23us/sample - loss: 0.3689\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "\n",
    "X_train_A, X_train_B = X_train_scaled[:, :5], X_train_scaled[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid_scaled[:, :5], X_valid_scaled[:, 2:]\n",
    "X_test_A, X_test_B = X_test_scaled[:, :5], X_test_scaled[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=30,\n",
    "                   validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5])\n",
    "input_B = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "aux_output = keras.layers.Dense(1)(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 1s 79us/sample - loss: 1.4906 - dense_13_loss: 1.3871 - dense_14_loss: 2.4198 - val_loss: 0.7245 - val_dense_13_loss: 0.6358 - val_dense_14_loss: 1.5246\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.7562 - dense_13_loss: 0.6450 - dense_14_loss: 1.7541 - val_loss: 0.6357 - val_dense_13_loss: 0.5640 - val_dense_14_loss: 1.2800\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.6762 - dense_13_loss: 0.6116 - dense_14_loss: 1.2571 - val_loss: 0.5964 - val_dense_13_loss: 0.5382 - val_dense_14_loss: 1.1204\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.7727 - dense_13_loss: 0.7219 - dense_14_loss: 1.2279 - val_loss: 0.6039 - val_dense_13_loss: 0.5553 - val_dense_14_loss: 1.0395\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.5599 - dense_13_loss: 0.5087 - dense_14_loss: 1.0199 - val_loss: 0.5346 - val_dense_13_loss: 0.4918 - val_dense_14_loss: 0.9195\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.5310 - dense_13_loss: 0.4897 - dense_14_loss: 0.9017 - val_loss: 0.5125 - val_dense_13_loss: 0.4765 - val_dense_14_loss: 0.8355\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.5219 - dense_13_loss: 0.4886 - dense_14_loss: 0.8218 - val_loss: 0.4963 - val_dense_13_loss: 0.4649 - val_dense_14_loss: 0.7779\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.4959 - dense_13_loss: 0.4663 - dense_14_loss: 0.7629 - val_loss: 0.4751 - val_dense_13_loss: 0.4460 - val_dense_14_loss: 0.7396\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4702 - dense_13_loss: 0.4418 - dense_14_loss: 0.7259 - val_loss: 0.4574 - val_dense_13_loss: 0.4296 - val_dense_14_loss: 0.7073\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.4605 - dense_13_loss: 0.4342 - dense_14_loss: 0.6960 - val_loss: 0.4513 - val_dense_13_loss: 0.4256 - val_dense_14_loss: 0.6889\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.4588 - dense_13_loss: 0.4346 - dense_14_loss: 0.6763 - val_loss: 0.4362 - val_dense_13_loss: 0.4103 - val_dense_14_loss: 0.6698\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.4377 - dense_13_loss: 0.4130 - dense_14_loss: 0.6602 - val_loss: 0.4321 - val_dense_13_loss: 0.4071 - val_dense_14_loss: 0.6569\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.4316 - dense_13_loss: 0.4082 - dense_14_loss: 0.6410 - val_loss: 0.4228 - val_dense_13_loss: 0.3983 - val_dense_14_loss: 0.6436\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.4172 - dense_13_loss: 0.3941 - dense_14_loss: 0.6275 - val_loss: 0.4131 - val_dense_13_loss: 0.3897 - val_dense_14_loss: 0.6241\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.4085 - dense_13_loss: 0.3862 - dense_14_loss: 0.6093 - val_loss: 0.4290 - val_dense_13_loss: 0.4077 - val_dense_14_loss: 0.6202\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.4011 - dense_13_loss: 0.3792 - dense_14_loss: 0.5983 - val_loss: 0.4024 - val_dense_13_loss: 0.3805 - val_dense_14_loss: 0.5992\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3968 - dense_13_loss: 0.3762 - dense_14_loss: 0.5817 - val_loss: 0.3952 - val_dense_13_loss: 0.3744 - val_dense_14_loss: 0.5811\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3862 - dense_13_loss: 0.3658 - dense_14_loss: 0.5695 - val_loss: 0.3831 - val_dense_13_loss: 0.3622 - val_dense_14_loss: 0.5710\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3811 - dense_13_loss: 0.3615 - dense_14_loss: 0.5581 - val_loss: 0.3812 - val_dense_13_loss: 0.3612 - val_dense_14_loss: 0.5605\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3753 - dense_13_loss: 0.3563 - dense_14_loss: 0.5473 - val_loss: 0.3749 - val_dense_13_loss: 0.3556 - val_dense_14_loss: 0.5484\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3758 - dense_13_loss: 0.3578 - dense_14_loss: 0.5384 - val_loss: 0.4005 - val_dense_13_loss: 0.3840 - val_dense_14_loss: 0.5484\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3719 - dense_13_loss: 0.3542 - dense_14_loss: 0.5321 - val_loss: 0.3810 - val_dense_13_loss: 0.3631 - val_dense_14_loss: 0.5417\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3640 - dense_13_loss: 0.3466 - dense_14_loss: 0.5200 - val_loss: 0.3672 - val_dense_13_loss: 0.3495 - val_dense_14_loss: 0.5256\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3615 - dense_13_loss: 0.3447 - dense_14_loss: 0.5132 - val_loss: 0.3764 - val_dense_13_loss: 0.3603 - val_dense_14_loss: 0.5220\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3620 - dense_13_loss: 0.3458 - dense_14_loss: 0.5078 - val_loss: 0.3702 - val_dense_13_loss: 0.3536 - val_dense_14_loss: 0.5194\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3573 - dense_13_loss: 0.3417 - dense_14_loss: 0.4996 - val_loss: 0.3680 - val_dense_13_loss: 0.3517 - val_dense_14_loss: 0.5145\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3780 - dense_13_loss: 0.3643 - dense_14_loss: 0.5039 - val_loss: 0.3628 - val_dense_13_loss: 0.3466 - val_dense_14_loss: 0.5090\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3602 - dense_13_loss: 0.3454 - dense_14_loss: 0.4936 - val_loss: 0.3759 - val_dense_13_loss: 0.3616 - val_dense_14_loss: 0.5040\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3568 - dense_13_loss: 0.3424 - dense_14_loss: 0.4872 - val_loss: 0.3619 - val_dense_13_loss: 0.3465 - val_dense_14_loss: 0.5001\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3511 - dense_13_loss: 0.3363 - dense_14_loss: 0.4845 - val_loss: 0.3751 - val_dense_13_loss: 0.3613 - val_dense_14_loss: 0.4984\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train], epochs=30,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 37us/sample - loss: 0.3881 - dense_13_loss: 0.3741 - dense_14_loss: 0.5051\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.1936183],\n",
       "       [1.5470233],\n",
       "       [1.9611716]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9853854],\n",
       "       [1.6616596],\n",
       "       [2.006374 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WideAndDeepModel()\n",
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape\n",
    "np.isnan(np.sum(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.7899 - val_loss: 0.4665\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 2.2022 - val_loss: 0.4380\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4279 - val_loss: 0.4235\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3875 - val_loss: 0.4125\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3742 - val_loss: 0.3771\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3607 - val_loss: 0.3651\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3539 - val_loss: 0.3627\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3478 - val_loss: 0.3572\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3422 - val_loss: 0.3523\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3417 - val_loss: 0.3716\n",
      "5160/5160 [==============================] - 0s 20us/sample - loss: 0.4045\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, \n",
    "                    validation_data=(X_valid_scaled, y_valid))\n",
    "mse_test = model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5527186],\n",
       "       [1.4779649],\n",
       "       [1.5871992]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3cec387e48>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3379\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3348\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3316\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3291\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3264\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3249\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3259\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3224\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3203\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3209\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3175 - val_loss: 0.3417\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3149 - val_loss: 0.3340\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3137 - val_loss: 0.3357\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3127 - val_loss: 0.3342\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3111 - val_loss: 0.3352\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3087 - val_loss: 0.3303\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3063 - val_loss: 0.3345\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3037 - val_loss: 0.3267\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3028 - val_loss: 0.3283\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3024 - val_loss: 0.3252\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "                                               save_best_only=True)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, \n",
    "                   validation_data=(X_valid_scaled, y_valid), \n",
    "                   callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")  # rollback to best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3870/3870 [==============================] - 0s 25us/sample - loss: 0.3252\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3002 - val_loss: 0.3263\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3006 - val_loss: 0.3316\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2976 - val_loss: 0.3350\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2961 - val_loss: 0.3216\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2948 - val_loss: 0.3201\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2934 - val_loss: 0.3185\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2987 - val_loss: 0.3200\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2937 - val_loss: 0.3231\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2918 - val_loss: 0.3166\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2894 - val_loss: 0.3187\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2936 - val_loss: 0.3179\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2880 - val_loss: 0.3183\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2902 - val_loss: 0.3181\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2904 - val_loss: 0.3136\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2860 - val_loss: 0.3204\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2863 - val_loss: 0.3146\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2851 - val_loss: 0.3159\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2839 - val_loss: 0.3202\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2835 - val_loss: 0.3105\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2820 - val_loss: 0.3185\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2816 - val_loss: 0.3339\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2840 - val_loss: 0.3126\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2810 - val_loss: 0.3148\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2813 - val_loss: 0.3147\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2802 - val_loss: 0.3099\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2789 - val_loss: 0.3093\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2779 - val_loss: 0.3260\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2779 - val_loss: 0.3282\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2777 - val_loss: 0.3069\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2786 - val_loss: 0.3057\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2773 - val_loss: 0.3077\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2762 - val_loss: 0.3064\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2765 - val_loss: 0.3180\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2752 - val_loss: 0.3086\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2752 - val_loss: 0.3099\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2750 - val_loss: 0.3106\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2731 - val_loss: 0.3129\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2738 - val_loss: 0.3048\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2721 - val_loss: 0.3079\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2736 - val_loss: 0.3014\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2718 - val_loss: 0.3056\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2703 - val_loss: 0.3145\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2713 - val_loss: 0.3042\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2709 - val_loss: 0.3182\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2705 - val_loss: 0.3027\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2702 - val_loss: 0.3015\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2699 - val_loss: 0.3118\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2698 - val_loss: 0.3069\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2707 - val_loss: 0.3036\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2695 - val_loss: 0.3081\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                 restore_best_weights=True)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100,\n",
    "                   validation_data=(X_valid_scaled, y_valid),\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "10496/11610 [==========================>...] - ETA: 0s - loss: 0.2705\n",
      "val/train: 1.11\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2716 - val_loss: 0.3027\n",
      "Epoch 2/100\n",
      "10816/11610 [==========================>...] - ETA: 0s - loss: 0.2727\n",
      "val/train: 1.11\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2723 - val_loss: 0.3031\n",
      "Epoch 3/100\n",
      "10688/11610 [==========================>...] - ETA: 0s - loss: 0.2673\n",
      "val/train: 1.13\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2711 - val_loss: 0.3068\n",
      "Epoch 4/100\n",
      "10976/11610 [===========================>..] - ETA: 0s - loss: 0.2709\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2715 - val_loss: 0.3171\n",
      "Epoch 5/100\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.2716\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2715 - val_loss: 0.3083\n",
      "Epoch 6/100\n",
      "10880/11610 [===========================>..] - ETA: 0s - loss: 0.2693\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2718 - val_loss: 0.3093\n",
      "Epoch 7/100\n",
      "10464/11610 [==========================>...] - ETA: 0s - loss: 0.2699\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2708 - val_loss: 0.3115\n",
      "Epoch 8/100\n",
      "10848/11610 [===========================>..] - ETA: 0s - loss: 0.2689\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2697 - val_loss: 0.3109\n",
      "Epoch 9/100\n",
      "10432/11610 [=========================>....] - ETA: 0s - loss: 0.2709\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2699 - val_loss: 0.3087\n",
      "Epoch 10/100\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.2709\n",
      "val/train: 1.12\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2696 - val_loss: 0.3031\n",
      "Epoch 11/100\n",
      "10656/11610 [==========================>...] - ETA: 0s - loss: 0.2692\n",
      "val/train: 1.13\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2681 - val_loss: 0.3021\n",
      "Epoch 12/100\n",
      "10912/11610 [===========================>..] - ETA: 0s - loss: 0.2703\n",
      "val/train: 1.12\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2683 - val_loss: 0.3001\n",
      "Epoch 13/100\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.2675\n",
      "val/train: 1.12\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2681 - val_loss: 0.2994\n",
      "Epoch 14/100\n",
      "10912/11610 [===========================>..] - ETA: 0s - loss: 0.2673\n",
      "val/train: 1.12\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2678 - val_loss: 0.3006\n",
      "Epoch 15/100\n",
      "10848/11610 [===========================>..] - ETA: 0s - loss: 0.2675\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2677 - val_loss: 0.3129\n",
      "Epoch 16/100\n",
      "11104/11610 [===========================>..] - ETA: 0s - loss: 0.2625\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2653 - val_loss: 0.3116\n",
      "Epoch 17/100\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.2652\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2664 - val_loss: 0.3123\n",
      "Epoch 18/100\n",
      "11488/11610 [============================>.] - ETA: 0s - loss: 0.2650\n",
      "val/train: 1.13\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2654 - val_loss: 0.3011\n",
      "Epoch 19/100\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.2632\n",
      "val/train: 1.23\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2648 - val_loss: 0.3263\n",
      "Epoch 20/100\n",
      "11104/11610 [===========================>..] - ETA: 0s - loss: 0.2670\n",
      "val/train: 1.12\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2662 - val_loss: 0.2988\n",
      "Epoch 21/100\n",
      "10816/11610 [==========================>...] - ETA: 0s - loss: 0.2619\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2651 - val_loss: 0.3022\n",
      "Epoch 22/100\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.2644\n",
      "val/train: 1.12\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2651 - val_loss: 0.2974\n",
      "Epoch 23/100\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.2633\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2645 - val_loss: 0.3003\n",
      "Epoch 24/100\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2663\n",
      "val/train: 1.12\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2646 - val_loss: 0.2957\n",
      "Epoch 25/100\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2659\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2636 - val_loss: 0.2998\n",
      "Epoch 26/100\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.2622\n",
      "val/train: 1.13\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2624 - val_loss: 0.2962\n",
      "Epoch 27/100\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.2633\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2620 - val_loss: 0.3015\n",
      "Epoch 28/100\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.2612\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2620 - val_loss: 0.3011\n",
      "Epoch 29/100\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.2636\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2624 - val_loss: 0.2987\n",
      "Epoch 30/100\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2613\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2610 - val_loss: 0.3036\n",
      "Epoch 31/100\n",
      "11008/11610 [===========================>..] - ETA: 0s - loss: 0.2616\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2605 - val_loss: 0.2985\n",
      "Epoch 32/100\n",
      "10880/11610 [===========================>..] - ETA: 0s - loss: 0.2592\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2610 - val_loss: 0.3018\n",
      "Epoch 33/100\n",
      "10784/11610 [==========================>...] - ETA: 0s - loss: 0.2613\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2611 - val_loss: 0.2970\n",
      "Epoch 34/100\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.2599\n",
      "val/train: 1.12\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2610 - val_loss: 0.2935\n",
      "Epoch 35/100\n",
      "11040/11610 [===========================>..] - ETA: 0s - loss: 0.2586\n",
      "val/train: 1.19\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2602 - val_loss: 0.3084\n",
      "Epoch 36/100\n",
      "11008/11610 [===========================>..] - ETA: 0s - loss: 0.2609\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2603 - val_loss: 0.2957\n",
      "Epoch 37/100\n",
      "10976/11610 [===========================>..] - ETA: 0s - loss: 0.2605\n",
      "val/train: 1.13\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2589 - val_loss: 0.2937\n",
      "Epoch 38/100\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2575\n",
      "val/train: 1.13\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2588 - val_loss: 0.2928\n",
      "Epoch 39/100\n",
      "10816/11610 [==========================>...] - ETA: 0s - loss: 0.2559\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2581 - val_loss: 0.2943\n",
      "Epoch 40/100\n",
      "11456/11610 [============================>.] - ETA: 0s - loss: 0.2583\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2589 - val_loss: 0.2998\n",
      "Epoch 41/100\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2561\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2586 - val_loss: 0.2951\n",
      "Epoch 42/100\n",
      "11456/11610 [============================>.] - ETA: 0s - loss: 0.2570\n",
      "val/train: 1.18\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2567 - val_loss: 0.3032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "11520/11610 [============================>.] - ETA: 0s - loss: 0.2577\n",
      "val/train: 1.13\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2573 - val_loss: 0.2919\n",
      "Epoch 44/100\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.2570\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2570 - val_loss: 0.2931\n",
      "Epoch 45/100\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.2545\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2554 - val_loss: 0.2949\n",
      "Epoch 46/100\n",
      "10816/11610 [==========================>...] - ETA: 0s - loss: 0.2525\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2551 - val_loss: 0.2978\n",
      "Epoch 47/100\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.2584\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2558 - val_loss: 0.2968\n",
      "Epoch 48/100\n",
      "10880/11610 [===========================>..] - ETA: 0s - loss: 0.2588\n",
      "val/train: 1.18\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2565 - val_loss: 0.3015\n",
      "Epoch 49/100\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.2563\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2550 - val_loss: 0.2912\n",
      "Epoch 50/100\n",
      "10400/11610 [=========================>....] - ETA: 0s - loss: 0.2595\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2554 - val_loss: 0.2972\n",
      "Epoch 51/100\n",
      "10496/11610 [==========================>...] - ETA: 0s - loss: 0.2554\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2549 - val_loss: 0.2964\n",
      "Epoch 52/100\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.2565\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2552 - val_loss: 0.2960\n",
      "Epoch 53/100\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.2555\n",
      "val/train: 1.19\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2544 - val_loss: 0.3026\n",
      "Epoch 54/100\n",
      "11008/11610 [===========================>..] - ETA: 0s - loss: 0.2554\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2552 - val_loss: 0.2936\n",
      "Epoch 55/100\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.2528\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2538 - val_loss: 0.2967\n",
      "Epoch 56/100\n",
      "11008/11610 [===========================>..] - ETA: 0s - loss: 0.2538\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2524 - val_loss: 0.2902\n",
      "Epoch 57/100\n",
      "10880/11610 [===========================>..] - ETA: 0s - loss: 0.2540\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2522 - val_loss: 0.2953\n",
      "Epoch 58/100\n",
      "11104/11610 [===========================>..] - ETA: 0s - loss: 0.2529\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2526 - val_loss: 0.2946\n",
      "Epoch 59/100\n",
      "10880/11610 [===========================>..] - ETA: 0s - loss: 0.2538\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2536 - val_loss: 0.2884\n",
      "Epoch 60/100\n",
      "11392/11610 [============================>.] - ETA: 0s - loss: 0.2538\n",
      "val/train: 1.14\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2530 - val_loss: 0.2895\n",
      "Epoch 61/100\n",
      "10848/11610 [===========================>..] - ETA: 0s - loss: 0.2526\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2538 - val_loss: 0.2910\n",
      "Epoch 62/100\n",
      "10624/11610 [==========================>...] - ETA: 0s - loss: 0.2524\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2529 - val_loss: 0.2961\n",
      "Epoch 63/100\n",
      "10592/11610 [==========================>...] - ETA: 0s - loss: 0.2532\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2535 - val_loss: 0.2959\n",
      "Epoch 64/100\n",
      "10272/11610 [=========================>....] - ETA: 0s - loss: 0.2554\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2541 - val_loss: 0.2939\n",
      "Epoch 65/100\n",
      "11552/11610 [============================>.] - ETA: 0s - loss: 0.2539\n",
      "val/train: 1.15\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.2536 - val_loss: 0.2905\n",
      "Epoch 66/100\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.2516 - val_loss: 0.2926\n",
      "Epoch 67/100\n",
      "10240/11610 [=========================>....] - ETA: 0s - loss: 0.2487\n",
      "val/train: 1.22\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2509 - val_loss: 0.3068\n",
      "Epoch 68/100\n",
      "10912/11610 [===========================>..] - ETA: 0s - loss: 0.2500\n",
      "val/train: 1.19\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2506 - val_loss: 0.2978\n",
      "Epoch 69/100\n",
      "10688/11610 [==========================>...] - ETA: 0s - loss: 0.2482\n",
      "val/train: 1.19\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2502 - val_loss: 0.2987\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100,\n",
    "                   validation_data=(X_valid_scaled, y_valid),\n",
    "                   callbacks=[val_train_ratio_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2530 - val_loss: 0.2924\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2525 - val_loss: 0.2928\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2522 - val_loss: 0.2898\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2516 - val_loss: 0.2971\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2515 - val_loss: 0.2997\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2524 - val_loss: 0.2889\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2511 - val_loss: 0.2913\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2513 - val_loss: 0.3000\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2512 - val_loss: 0.2957\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2511 - val_loss: 0.2902\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2511 - val_loss: 0.2989\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2508 - val_loss: 0.2885\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2514 - val_loss: 0.2852\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2503 - val_loss: 0.2887\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2506 - val_loss: 0.2872\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2518 - val_loss: 0.2949\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2512 - val_loss: 0.2880\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2508 - val_loss: 0.2961\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.2495 - val_loss: 0.2951\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2504 - val_loss: 0.2918\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2495 - val_loss: 0.3010\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2474 - val_loss: 0.2934\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2490 - val_loss: 0.2879\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2470 - val_loss: 0.2820\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2478 - val_loss: 0.3038\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.2468 - val_loss: 0.2924\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.2482 - val_loss: 0.2856\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.2469 - val_loss: 0.2879\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2461 - val_loss: 0.2907\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2477 - val_loss: 0.2898\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=30, \n",
    "                   validation_data=(X_valid_scaled, y_valid),\n",
    "                   callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/1000\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 1.5304 - val_loss: 0.6912\n",
      "Epoch 2/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.7550 - val_loss: 0.6328\n",
      "Epoch 3/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.6225 - val_loss: 0.5877\n",
      "Epoch 4/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5766 - val_loss: 0.5597\n",
      "Epoch 5/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.5475 - val_loss: 0.5356\n",
      "Epoch 6/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5276 - val_loss: 0.5175\n",
      "Epoch 7/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5109 - val_loss: 0.5038\n",
      "Epoch 8/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4981 - val_loss: 0.4929\n",
      "Epoch 9/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4888 - val_loss: 0.4843\n",
      "Epoch 10/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4802 - val_loss: 0.4788\n",
      "Epoch 11/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4740 - val_loss: 0.4727\n",
      "Epoch 12/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4682 - val_loss: 0.4675\n",
      "Epoch 13/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4640 - val_loss: 0.4643\n",
      "Epoch 14/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4595 - val_loss: 0.4599\n",
      "Epoch 15/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4571 - val_loss: 0.4586\n",
      "Epoch 16/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4529 - val_loss: 0.4545\n",
      "Epoch 17/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4509 - val_loss: 0.4530\n",
      "Epoch 18/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4483 - val_loss: 0.4511\n",
      "Epoch 19/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4457 - val_loss: 0.4491\n",
      "Epoch 20/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4440 - val_loss: 0.4470\n",
      "Epoch 21/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4417 - val_loss: 0.4456\n",
      "Epoch 22/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4402 - val_loss: 0.4436\n",
      "Epoch 23/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4387 - val_loss: 0.4420\n",
      "Epoch 24/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4366 - val_loss: 0.4401\n",
      "Epoch 25/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4355 - val_loss: 0.4392\n",
      "Epoch 26/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4336 - val_loss: 0.4381\n",
      "Epoch 27/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4323 - val_loss: 0.4367\n",
      "Epoch 28/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4310 - val_loss: 0.4355\n",
      "Epoch 29/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4297 - val_loss: 0.4337\n",
      "Epoch 30/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4285 - val_loss: 0.4334\n",
      "Epoch 31/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4271 - val_loss: 0.4316\n",
      "Epoch 32/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4265 - val_loss: 0.4313\n",
      "Epoch 33/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4249 - val_loss: 0.4295\n",
      "Epoch 34/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4240 - val_loss: 0.4285\n",
      "Epoch 35/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4224 - val_loss: 0.4280\n",
      "Epoch 36/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4220 - val_loss: 0.4266\n",
      "Epoch 37/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4207 - val_loss: 0.4258\n",
      "Epoch 38/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4201 - val_loss: 0.4259\n",
      "Epoch 39/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4189 - val_loss: 0.4236\n",
      "Epoch 40/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4184 - val_loss: 0.4231\n",
      "Epoch 41/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4167 - val_loss: 0.4226\n",
      "Epoch 42/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4161 - val_loss: 0.4216\n",
      "Epoch 43/1000\n",
      "11610/11610 [==============================] - 0s 18us/sample - loss: 0.4147 - val_loss: 0.4209\n",
      "Epoch 44/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4138 - val_loss: 0.4201\n",
      "Epoch 45/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4129 - val_loss: 0.4206\n",
      "Epoch 46/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4120 - val_loss: 0.4183\n",
      "Epoch 47/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4116 - val_loss: 0.4179\n",
      "Epoch 48/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4106 - val_loss: 0.4171\n",
      "Epoch 49/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4119 - val_loss: 0.4169\n",
      "Epoch 50/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4114 - val_loss: 0.4146\n",
      "Epoch 51/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4153 - val_loss: 0.4161\n",
      "Epoch 52/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4172 - val_loss: 0.4133\n",
      "Epoch 53/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4219 - val_loss: 0.4146\n",
      "Epoch 54/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4222 - val_loss: 0.4117\n",
      "Epoch 55/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4342 - val_loss: 0.4142\n",
      "Epoch 56/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4318 - val_loss: 0.4129\n",
      "Epoch 57/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4363 - val_loss: 0.4130\n",
      "Epoch 58/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4357 - val_loss: 0.4098\n",
      "Epoch 59/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4405 - val_loss: 0.4119\n",
      "Epoch 60/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4274 - val_loss: 0.4082\n",
      "Epoch 61/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4223 - val_loss: 0.4098\n",
      "Epoch 62/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4137 - val_loss: 0.4077\n",
      "Epoch 63/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4115 - val_loss: 0.4111\n",
      "Epoch 64/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.4077 - val_loss: 0.4078\n",
      "Epoch 65/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4049 - val_loss: 0.4066\n",
      "Epoch 66/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4002 - val_loss: 0.4056\n",
      "Epoch 67/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3987 - val_loss: 0.4062\n",
      "Epoch 68/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3963 - val_loss: 0.4053\n",
      "Epoch 69/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3959 - val_loss: 0.4027\n",
      "Epoch 70/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3948 - val_loss: 0.4037\n",
      "Epoch 71/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3939 - val_loss: 0.4029\n",
      "Epoch 72/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3931 - val_loss: 0.4012\n",
      "Epoch 73/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3925 - val_loss: 0.4013\n",
      "Epoch 74/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3916 - val_loss: 0.3996\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3911 - val_loss: 0.4014\n",
      "Epoch 76/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3904 - val_loss: 0.3988\n",
      "Epoch 77/1000\n",
      "11610/11610 [==============================] - 0s 18us/sample - loss: 0.3896 - val_loss: 0.3977\n",
      "Epoch 78/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3889 - val_loss: 0.3975\n",
      "Epoch 79/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3882 - val_loss: 0.3973\n",
      "Epoch 80/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3875 - val_loss: 0.3963\n",
      "Epoch 81/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3868 - val_loss: 0.3958\n",
      "Epoch 82/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3868 - val_loss: 0.3952\n",
      "Epoch 83/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3857 - val_loss: 0.3948\n",
      "Epoch 84/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3848 - val_loss: 0.3945\n",
      "Epoch 85/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3840 - val_loss: 0.3954\n",
      "Epoch 86/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3836 - val_loss: 0.3926\n",
      "Epoch 87/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3827 - val_loss: 0.3930\n",
      "Epoch 88/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3821 - val_loss: 0.3917\n",
      "Epoch 89/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3818 - val_loss: 0.3914\n",
      "Epoch 90/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3808 - val_loss: 0.3906\n",
      "Epoch 91/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3804 - val_loss: 0.3906\n",
      "Epoch 92/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3796 - val_loss: 0.3895\n",
      "Epoch 93/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3790 - val_loss: 0.3895\n",
      "Epoch 94/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3783 - val_loss: 0.3884\n",
      "Epoch 95/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3779 - val_loss: 0.3884\n",
      "Epoch 96/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3772 - val_loss: 0.3882\n",
      "Epoch 97/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3771 - val_loss: 0.3875\n",
      "Epoch 98/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3766 - val_loss: 0.3861\n",
      "Epoch 99/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3761 - val_loss: 0.3865\n",
      "Epoch 100/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3754 - val_loss: 0.3846\n",
      "Epoch 101/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3752 - val_loss: 0.3847\n",
      "Epoch 102/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3746 - val_loss: 0.3839\n",
      "Epoch 103/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3751 - val_loss: 0.3857\n",
      "Epoch 104/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3744 - val_loss: 0.3834\n",
      "Epoch 105/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3755 - val_loss: 0.3839\n",
      "Epoch 106/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3750 - val_loss: 0.3824\n",
      "Epoch 107/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3764 - val_loss: 0.3832\n",
      "Epoch 108/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3784 - val_loss: 0.3811\n",
      "Epoch 109/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3803 - val_loss: 0.3803\n",
      "Epoch 110/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3815 - val_loss: 0.3819\n",
      "Epoch 111/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3875 - val_loss: 0.3799\n",
      "Epoch 112/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3918 - val_loss: 0.3799\n",
      "Epoch 113/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4044 - val_loss: 0.3789\n",
      "Epoch 114/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4167 - val_loss: 0.3791\n",
      "Epoch 115/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.4118 - val_loss: 0.3774\n",
      "Epoch 116/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3675 - val_loss: 0.3772\n",
      "Epoch 117/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3660 - val_loss: 0.3762\n",
      "Epoch 118/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3651 - val_loss: 0.3771\n",
      "Epoch 119/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3649 - val_loss: 0.3756\n",
      "Epoch 120/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3640 - val_loss: 0.3760\n",
      "Epoch 121/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3638 - val_loss: 0.3762\n",
      "Epoch 122/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3634 - val_loss: 0.3746\n",
      "Epoch 123/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3628 - val_loss: 0.3750\n",
      "Epoch 124/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3621 - val_loss: 0.3746\n",
      "Epoch 125/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3620 - val_loss: 0.3738\n",
      "Epoch 126/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3618 - val_loss: 0.3733\n",
      "Epoch 127/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3611 - val_loss: 0.3723\n",
      "Epoch 128/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3605 - val_loss: 0.3726\n",
      "Epoch 129/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3599 - val_loss: 0.3727\n",
      "Epoch 130/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3594 - val_loss: 0.3717\n",
      "Epoch 131/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3592 - val_loss: 0.3713\n",
      "Epoch 132/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3589 - val_loss: 0.3710\n",
      "Epoch 133/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3584 - val_loss: 0.3710\n",
      "Epoch 134/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3579 - val_loss: 0.3705\n",
      "Epoch 135/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3578 - val_loss: 0.3697\n",
      "Epoch 136/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3572 - val_loss: 0.3708\n",
      "Epoch 137/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3566 - val_loss: 0.3694\n",
      "Epoch 138/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3563 - val_loss: 0.3696\n",
      "Epoch 139/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3560 - val_loss: 0.3692\n",
      "Epoch 140/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3555 - val_loss: 0.3684\n",
      "Epoch 141/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3549 - val_loss: 0.3671\n",
      "Epoch 142/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3557 - val_loss: 0.3699\n",
      "Epoch 143/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3544 - val_loss: 0.3678\n",
      "Epoch 144/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3542 - val_loss: 0.3674\n",
      "Epoch 145/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3536 - val_loss: 0.3675\n",
      "Epoch 146/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3531 - val_loss: 0.3675\n",
      "Epoch 147/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3530 - val_loss: 0.3657\n",
      "Epoch 148/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3526 - val_loss: 0.3661\n",
      "Epoch 149/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3521 - val_loss: 0.3663\n",
      "Epoch 150/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3518 - val_loss: 0.3651\n",
      "Epoch 151/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3515 - val_loss: 0.3644\n",
      "Epoch 152/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3510 - val_loss: 0.3646\n",
      "Epoch 153/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3509 - val_loss: 0.3651\n",
      "Epoch 154/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3508 - val_loss: 0.3642\n",
      "Epoch 155/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3501 - val_loss: 0.3654\n",
      "Epoch 156/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3497 - val_loss: 0.3642\n",
      "Epoch 157/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3495 - val_loss: 0.3648\n",
      "Epoch 158/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3491 - val_loss: 0.3628\n",
      "Epoch 159/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3489 - val_loss: 0.3619\n",
      "Epoch 160/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3488 - val_loss: 0.3630\n",
      "Epoch 161/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3484 - val_loss: 0.3620\n",
      "Epoch 162/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3479 - val_loss: 0.3628\n",
      "Epoch 163/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3477 - val_loss: 0.3618\n",
      "Epoch 164/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3474 - val_loss: 0.3618\n",
      "Epoch 165/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3472 - val_loss: 0.3611\n",
      "Epoch 166/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3466 - val_loss: 0.3609\n",
      "Epoch 167/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3465 - val_loss: 0.3599\n",
      "Epoch 168/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3459 - val_loss: 0.3596\n",
      "Epoch 169/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3458 - val_loss: 0.3599\n",
      "Epoch 170/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3451 - val_loss: 0.3594\n",
      "Epoch 171/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3454 - val_loss: 0.3591\n",
      "Epoch 172/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3449 - val_loss: 0.3590\n",
      "Epoch 173/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3446 - val_loss: 0.3583\n",
      "Epoch 174/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3439 - val_loss: 0.3603\n",
      "Epoch 175/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3441 - val_loss: 0.3583\n",
      "Epoch 176/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3436 - val_loss: 0.3576\n",
      "Epoch 177/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3436 - val_loss: 0.3576\n",
      "Epoch 178/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3429 - val_loss: 0.3568\n",
      "Epoch 179/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3426 - val_loss: 0.3575\n",
      "Epoch 180/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3426 - val_loss: 0.3580\n",
      "Epoch 181/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3425 - val_loss: 0.3564\n",
      "Epoch 182/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3420 - val_loss: 0.3581\n",
      "Epoch 183/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3417 - val_loss: 0.3564\n",
      "Epoch 184/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3416 - val_loss: 0.3583\n",
      "Epoch 185/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3411 - val_loss: 0.3567\n",
      "Epoch 186/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3411 - val_loss: 0.3566\n",
      "Epoch 187/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3407 - val_loss: 0.3554\n",
      "Epoch 188/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3413 - val_loss: 0.3553\n",
      "Epoch 189/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3400 - val_loss: 0.3552\n",
      "Epoch 190/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3397 - val_loss: 0.3566\n",
      "Epoch 191/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3395 - val_loss: 0.3543\n",
      "Epoch 192/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3393 - val_loss: 0.3551\n",
      "Epoch 193/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3387 - val_loss: 0.3537\n",
      "Epoch 194/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3386 - val_loss: 0.3535\n",
      "Epoch 195/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3380 - val_loss: 0.3552\n",
      "Epoch 196/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3382 - val_loss: 0.3544\n",
      "Epoch 197/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3379 - val_loss: 0.3530\n",
      "Epoch 198/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3375 - val_loss: 0.3528\n",
      "Epoch 199/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3373 - val_loss: 0.3535\n",
      "Epoch 200/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3373 - val_loss: 0.3519\n",
      "Epoch 201/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3364 - val_loss: 0.3527\n",
      "Epoch 202/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3362 - val_loss: 0.3520\n",
      "Epoch 203/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3361 - val_loss: 0.3524\n",
      "Epoch 204/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3361 - val_loss: 0.3531\n",
      "Epoch 205/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3367 - val_loss: 0.3537\n",
      "Epoch 206/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3368 - val_loss: 0.3530\n",
      "Epoch 207/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3375 - val_loss: 0.3511\n",
      "Epoch 208/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3353 - val_loss: 0.3547\n",
      "Epoch 209/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3373 - val_loss: 0.3505\n",
      "Epoch 210/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3359 - val_loss: 0.3517\n",
      "Epoch 211/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3347 - val_loss: 0.3553\n",
      "Epoch 212/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3350 - val_loss: 0.3490\n",
      "Epoch 213/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3338 - val_loss: 0.3490\n",
      "Epoch 214/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3333 - val_loss: 0.3497\n",
      "Epoch 215/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3335 - val_loss: 0.3490\n",
      "Epoch 216/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3334 - val_loss: 0.3481\n",
      "Epoch 217/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3327 - val_loss: 0.3480\n",
      "Epoch 218/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3322 - val_loss: 0.3472\n",
      "Epoch 219/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3324 - val_loss: 0.3473\n",
      "Epoch 220/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3319 - val_loss: 0.3487\n",
      "Epoch 221/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3317 - val_loss: 0.3477\n",
      "Epoch 222/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3319 - val_loss: 0.3475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3314 - val_loss: 0.3463\n",
      "Epoch 224/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3313 - val_loss: 0.3476\n",
      "Epoch 225/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3306 - val_loss: 0.3467\n",
      "Epoch 226/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3305 - val_loss: 0.3515\n",
      "Epoch 227/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3399 - val_loss: 0.3466\n",
      "Epoch 228/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3329 - val_loss: 0.3468\n",
      "Epoch 229/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3310 - val_loss: 0.3461\n",
      "Epoch 230/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3305 - val_loss: 0.3465\n",
      "Epoch 231/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3296 - val_loss: 0.3453\n",
      "Epoch 232/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3302 - val_loss: 0.3445\n",
      "Epoch 233/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3293 - val_loss: 0.3469\n",
      "Epoch 234/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3292 - val_loss: 0.3442\n",
      "Epoch 235/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3287 - val_loss: 0.3445\n",
      "Epoch 236/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3294 - val_loss: 0.3437\n",
      "Epoch 237/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3289 - val_loss: 0.3447\n",
      "Epoch 238/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3283 - val_loss: 0.3448\n",
      "Epoch 239/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3281 - val_loss: 0.3436\n",
      "Epoch 240/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3270 - val_loss: 0.3423\n",
      "Epoch 241/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3278 - val_loss: 0.3419\n",
      "Epoch 242/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3269 - val_loss: 0.3415\n",
      "Epoch 243/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3260 - val_loss: 0.3418\n",
      "Epoch 244/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3262 - val_loss: 0.3429\n",
      "Epoch 245/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3261 - val_loss: 0.3447\n",
      "Epoch 246/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3293 - val_loss: 0.3423\n",
      "Epoch 247/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3259 - val_loss: 0.3416\n",
      "Epoch 248/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3249 - val_loss: 0.3421\n",
      "Epoch 249/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3249 - val_loss: 0.3413\n",
      "Epoch 250/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3246 - val_loss: 0.3404\n",
      "Epoch 251/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3249 - val_loss: 0.3420\n",
      "Epoch 252/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3245 - val_loss: 0.3418\n",
      "Epoch 253/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3246 - val_loss: 0.3386\n",
      "Epoch 254/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3235 - val_loss: 0.3408\n",
      "Epoch 255/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3254 - val_loss: 0.3396\n",
      "Epoch 256/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3234 - val_loss: 0.3406\n",
      "Epoch 257/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3233 - val_loss: 0.3395\n",
      "Epoch 258/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3230 - val_loss: 0.3376\n",
      "Epoch 259/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3223 - val_loss: 0.3383\n",
      "Epoch 260/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3229 - val_loss: 0.3398\n",
      "Epoch 261/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3221 - val_loss: 0.3379\n",
      "Epoch 262/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3221 - val_loss: 0.3384\n",
      "Epoch 263/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3219 - val_loss: 0.3377\n",
      "Epoch 264/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3215 - val_loss: 0.3382\n",
      "Epoch 265/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3215 - val_loss: 0.3380\n",
      "Epoch 266/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3207 - val_loss: 0.3383\n",
      "Epoch 267/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3224 - val_loss: 0.3363\n",
      "Epoch 268/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3202 - val_loss: 0.3362\n",
      "Epoch 269/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3196 - val_loss: 0.3372\n",
      "Epoch 270/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3197 - val_loss: 0.3366\n",
      "Epoch 271/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3197 - val_loss: 0.3410\n",
      "Epoch 272/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3198 - val_loss: 0.3348\n",
      "Epoch 273/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3201 - val_loss: 0.3346\n",
      "Epoch 274/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3193 - val_loss: 0.3343\n",
      "Epoch 275/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3185 - val_loss: 0.3360\n",
      "Epoch 276/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3216 - val_loss: 0.3358\n",
      "Epoch 277/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3234 - val_loss: 0.3342\n",
      "Epoch 278/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3179 - val_loss: 0.3351\n",
      "Epoch 279/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3180 - val_loss: 0.3345\n",
      "Epoch 280/1000\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3188 - val_loss: 0.3343\n",
      "Epoch 281/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3186 - val_loss: 0.3340\n",
      "Epoch 282/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3170 - val_loss: 0.3351\n",
      "Epoch 283/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3170 - val_loss: 0.3337\n",
      "Epoch 284/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3160 - val_loss: 0.3353\n",
      "Epoch 285/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3165 - val_loss: 0.3324\n",
      "Epoch 286/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3157 - val_loss: 0.3320\n",
      "Epoch 287/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3158 - val_loss: 0.3342\n",
      "Epoch 288/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3176 - val_loss: 0.3308\n",
      "Epoch 289/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3154 - val_loss: 0.3336\n",
      "Epoch 290/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3171 - val_loss: 0.3351\n",
      "Epoch 291/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3159 - val_loss: 0.3429\n",
      "Epoch 292/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3249 - val_loss: 0.3339\n",
      "Epoch 293/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3211 - val_loss: 0.3320\n",
      "Epoch 294/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3158 - val_loss: 0.3319\n",
      "Epoch 295/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3149 - val_loss: 0.3414\n",
      "Epoch 296/1000\n",
      "11610/11610 [==============================] - 0s 20us/sample - loss: 0.3157 - val_loss: 0.3317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3146 - val_loss: 0.3337\n",
      "Epoch 298/1000\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3139 - val_loss: 0.3312\n",
      "5160/5160 [==============================] - 0s 22us/sample - loss: 0.3436\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train_scaled, y_train, epochs=1000, batch_size=64,\n",
    "             validation_data=(X_valid_scaled, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test_scaled, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] learning_rate=0.004387096309029169, n_hidden=2, n_neurons=91 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "  32/7740 [..............................] - ETA: 5s - loss: 4.5358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 60us/sample - loss: 1.4145 - val_loss: 0.6180\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 1.2099 - val_loss: 0.5908\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5778 - val_loss: 0.5301\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5179 - val_loss: 0.4945\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4860 - val_loss: 0.4685\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4648 - val_loss: 0.4530\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4518 - val_loss: 0.4407\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4382 - val_loss: 0.4318\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4295 - val_loss: 0.4250\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4213 - val_loss: 0.4213\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4156 - val_loss: 0.4124\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4102 - val_loss: 0.4104\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4054 - val_loss: 0.4055\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4016 - val_loss: 0.4041\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3980 - val_loss: 0.3986\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3948 - val_loss: 0.4006\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3906 - val_loss: 0.3954\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3871 - val_loss: 0.3925\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3841 - val_loss: 0.3927\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3838 - val_loss: 0.3845\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3800 - val_loss: 0.3825\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3761 - val_loss: 0.3835\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3746 - val_loss: 0.3774\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3710 - val_loss: 0.3766\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3688 - val_loss: 0.3743\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3657 - val_loss: 0.3745\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3644 - val_loss: 0.3740\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3615 - val_loss: 0.3679\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3592 - val_loss: 0.3659\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3577 - val_loss: 0.3646\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3555 - val_loss: 0.3664\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3539 - val_loss: 0.3640\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3516 - val_loss: 0.3603\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3506 - val_loss: 0.3589\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3481 - val_loss: 0.3591\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3471 - val_loss: 0.3567\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3445 - val_loss: 0.3544\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3434 - val_loss: 0.3529\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3409 - val_loss: 0.3524\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3401 - val_loss: 0.3548\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3389 - val_loss: 0.3505\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3364 - val_loss: 0.3480\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3382 - val_loss: 0.3469\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3351 - val_loss: 0.3482\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3328 - val_loss: 0.3474\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3315 - val_loss: 0.3462\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3309 - val_loss: 0.3406\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3312 - val_loss: 0.3448\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3314 - val_loss: 0.3407\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3321 - val_loss: 0.3426\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3315 - val_loss: 0.3418\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3300 - val_loss: 0.3419\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3263 - val_loss: 0.3415\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3224 - val_loss: 0.3359\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3200 - val_loss: 0.3358\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3195 - val_loss: 0.3359\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3187 - val_loss: 0.3321\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3171 - val_loss: 0.3326\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3152 - val_loss: 0.3398\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3135 - val_loss: 0.3338\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3134 - val_loss: 0.3309\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3128 - val_loss: 0.3297\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3124 - val_loss: 0.3304\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3115 - val_loss: 0.3267\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3096 - val_loss: 0.3309\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3092 - val_loss: 0.3263\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3077 - val_loss: 0.3274\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3083 - val_loss: 0.3252\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3062 - val_loss: 0.3295\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3051 - val_loss: 0.3315\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3071 - val_loss: 0.3224\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3039 - val_loss: 0.3213\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3024 - val_loss: 0.3212\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3009 - val_loss: 0.3197\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3021 - val_loss: 0.3207\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3001 - val_loss: 0.3255\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2980 - val_loss: 0.3231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2982 - val_loss: 0.3183\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2971 - val_loss: 0.3161\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2970 - val_loss: 0.3242\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2975 - val_loss: 0.3214\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2968 - val_loss: 0.3163\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2996 - val_loss: 0.3172\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2973 - val_loss: 0.3149\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2991 - val_loss: 0.3168\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3054 - val_loss: 0.3149\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3105 - val_loss: 0.3197\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3089 - val_loss: 0.3191\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2940 - val_loss: 0.3149\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2921 - val_loss: 0.3189\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2914 - val_loss: 0.3123\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2904 - val_loss: 0.3168\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2885 - val_loss: 0.3147\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2904 - val_loss: 0.3150\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2893 - val_loss: 0.3185\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2880 - val_loss: 0.3152\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2897 - val_loss: 0.3159\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2884 - val_loss: 0.3108\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2859 - val_loss: 0.3070\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2877 - val_loss: 0.3083\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2864 - val_loss: 0.3067\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2838 - val_loss: 0.3118\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2846 - val_loss: 0.3094\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2836 - val_loss: 0.3182\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2839 - val_loss: 0.3065\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2829 - val_loss: 0.3105\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2822 - val_loss: 0.3072\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2814 - val_loss: 0.3156\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2841 - val_loss: 0.3085\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2816 - val_loss: 0.3081\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2803 - val_loss: 0.3126\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2813 - val_loss: 0.3043\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2804 - val_loss: 0.3083\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2919 - val_loss: 0.3075\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2816 - val_loss: 0.3037\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2797 - val_loss: 0.3158\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2799 - val_loss: 0.3009\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2785 - val_loss: 0.3031\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2785 - val_loss: 0.3045\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2777 - val_loss: 0.3073\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2761 - val_loss: 0.3077\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2766 - val_loss: 0.3058\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2773 - val_loss: 0.3025\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2820 - val_loss: 0.3007\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2740 - val_loss: 0.3010\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2744 - val_loss: 0.3080\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2747 - val_loss: 0.3043\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2747 - val_loss: 0.3010\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2738 - val_loss: 0.3029\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2740 - val_loss: 0.3030\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2733 - val_loss: 0.3027\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2740 - val_loss: 0.3038\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2736 - val_loss: 0.3027\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2729 - val_loss: 0.2996\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2747 - val_loss: 0.3039\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2759 - val_loss: 0.3123\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2785 - val_loss: 0.3131\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2751 - val_loss: 0.3001\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2738 - val_loss: 0.3017\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2712 - val_loss: 0.3000\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2702 - val_loss: 0.3078\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2701 - val_loss: 0.2981\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2697 - val_loss: 0.3041\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2691 - val_loss: 0.2999\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2689 - val_loss: 0.3006\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2667 - val_loss: 0.3112\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2685 - val_loss: 0.2976\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2675 - val_loss: 0.2968\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2666 - val_loss: 0.3015\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2677 - val_loss: 0.2997\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2682 - val_loss: 0.2980\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2665 - val_loss: 0.2985\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2665 - val_loss: 0.3016\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2657 - val_loss: 0.2984\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2660 - val_loss: 0.2933\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2654 - val_loss: 0.2952\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2660 - val_loss: 0.3005\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2650 - val_loss: 0.2947\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2631 - val_loss: 0.3023\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2648 - val_loss: 0.3079\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2637 - val_loss: 0.2954\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2626 - val_loss: 0.2942\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2632 - val_loss: 0.3047\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2628 - val_loss: 0.2989\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2621 - val_loss: 0.2949\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.2702\n",
      "[CV]  learning_rate=0.004387096309029169, n_hidden=2, n_neurons=91, total= 1.0min\n",
      "[CV] learning_rate=0.004387096309029169, n_hidden=2, n_neurons=91 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "  32/7740 [..............................] - ETA: 5s - loss: 5.3279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.9794 - val_loss: 0.6461\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5871 - val_loss: 0.5482\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5197 - val_loss: 0.4952\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4739 - val_loss: 0.4763\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4519 - val_loss: 0.4528\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4378 - val_loss: 0.4453\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4275 - val_loss: 0.4290\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4171 - val_loss: 0.4267\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4144 - val_loss: 0.4192\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4057 - val_loss: 0.4183\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4012 - val_loss: 0.4075\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3962 - val_loss: 0.4079\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3955 - val_loss: 0.4009\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3869 - val_loss: 0.3991\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3836 - val_loss: 0.3926\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3799 - val_loss: 0.3895\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3820 - val_loss: 0.3894\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3738 - val_loss: 0.3853\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3769 - val_loss: 0.3823\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3696 - val_loss: 0.3794\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3647 - val_loss: 0.3790\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3632 - val_loss: 0.3731\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3603 - val_loss: 0.3727\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3575 - val_loss: 0.3730\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3550 - val_loss: 0.3699\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3519 - val_loss: 0.3653\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3497 - val_loss: 0.3665\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3468 - val_loss: 0.3657\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3467 - val_loss: 0.3609\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3445 - val_loss: 0.3601\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3405 - val_loss: 0.3572\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3416 - val_loss: 0.3569\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3370 - val_loss: 0.3564\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3363 - val_loss: 0.3512\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3343 - val_loss: 0.3527\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3352 - val_loss: 0.3524\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3317 - val_loss: 0.3470\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3283 - val_loss: 0.3461\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3256 - val_loss: 0.3504\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3254 - val_loss: 0.3457\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3241 - val_loss: 0.3466\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3233 - val_loss: 0.3385\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3209 - val_loss: 0.3394\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3196 - val_loss: 0.3382\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3182 - val_loss: 0.3368\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3166 - val_loss: 0.3367\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3138 - val_loss: 0.3420\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3133 - val_loss: 0.3363\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3135 - val_loss: 0.3352\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3099 - val_loss: 0.3409\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3107 - val_loss: 0.3303\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3145 - val_loss: 0.3369\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3079 - val_loss: 0.3316\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3064 - val_loss: 0.3311\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3043 - val_loss: 0.3266\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3044 - val_loss: 0.3278\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3019 - val_loss: 0.3273\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3022 - val_loss: 0.3248\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3004 - val_loss: 0.3246\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2997 - val_loss: 0.3245\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2987 - val_loss: 0.3244\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2967 - val_loss: 0.3239\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2983 - val_loss: 0.3221\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2952 - val_loss: 0.3204\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2938 - val_loss: 0.3270\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2938 - val_loss: 0.3203\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2924 - val_loss: 0.3180\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2907 - val_loss: 0.3204\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2923 - val_loss: 0.3153\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2902 - val_loss: 0.3177\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2910 - val_loss: 0.3183\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2895 - val_loss: 0.3189\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2901 - val_loss: 0.3118\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2876 - val_loss: 0.3189\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2860 - val_loss: 0.3135\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2864 - val_loss: 0.3187\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2851 - val_loss: 0.3133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2858 - val_loss: 0.3115\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2831 - val_loss: 0.3163\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2883 - val_loss: 0.3077\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2828 - val_loss: 0.3088\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2818 - val_loss: 0.3084\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2810 - val_loss: 0.3142\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2803 - val_loss: 0.3045\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2807 - val_loss: 0.3057\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2794 - val_loss: 0.3230\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2786 - val_loss: 0.3048\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2782 - val_loss: 0.3075\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2774 - val_loss: 0.3050\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2764 - val_loss: 0.3095\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2769 - val_loss: 0.3055\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2756 - val_loss: 0.3132\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2777 - val_loss: 0.3010\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2749 - val_loss: 0.3260\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2753 - val_loss: 0.3024\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2731 - val_loss: 0.3026\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2734 - val_loss: 0.3065\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2726 - val_loss: 0.3059\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2722 - val_loss: 0.3060\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2730 - val_loss: 0.3080\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2722 - val_loss: 0.2980\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2711 - val_loss: 0.3036\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2731 - val_loss: 0.3033\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2699 - val_loss: 0.2976\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2690 - val_loss: 0.3003\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2690 - val_loss: 0.2986\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2691 - val_loss: 0.2996\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2687 - val_loss: 0.2962\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2682 - val_loss: 0.2972\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2684 - val_loss: 0.2964\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2656 - val_loss: 0.2964\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2669 - val_loss: 0.2961\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2658 - val_loss: 0.2940\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2655 - val_loss: 0.2978\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2662 - val_loss: 0.2968\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2671 - val_loss: 0.2952\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2644 - val_loss: 0.2959\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2654 - val_loss: 0.2940\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2628 - val_loss: 0.3023\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2636 - val_loss: 0.2962\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2624 - val_loss: 0.2929\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2629 - val_loss: 0.2968\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2631 - val_loss: 0.2928\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2603 - val_loss: 0.3007\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2613 - val_loss: 0.3004\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2633 - val_loss: 0.2990\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2618 - val_loss: 0.3054\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2605 - val_loss: 0.2924\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2603 - val_loss: 0.2987\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2592 - val_loss: 0.3072\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2593 - val_loss: 0.2904\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2588 - val_loss: 0.2938\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2583 - val_loss: 0.2963\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2588 - val_loss: 0.3001\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2582 - val_loss: 0.2972\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2587 - val_loss: 0.2946\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2580 - val_loss: 0.2903\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2561 - val_loss: 0.2978\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2575 - val_loss: 0.2918\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2564 - val_loss: 0.2957\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2563 - val_loss: 0.2951\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2564 - val_loss: 0.3053\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2570 - val_loss: 0.2900\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2540 - val_loss: 0.3010\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2555 - val_loss: 0.2888\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2545 - val_loss: 0.2892\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2552 - val_loss: 0.2990\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2535 - val_loss: 0.3033\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2551 - val_loss: 0.2882\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2536 - val_loss: 0.2903\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2528 - val_loss: 0.2926\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2524 - val_loss: 0.2916\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2522 - val_loss: 0.2897\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2518 - val_loss: 0.2945\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2525 - val_loss: 0.3038\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2521 - val_loss: 0.2913\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2516 - val_loss: 0.2914\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2513 - val_loss: 0.2944\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2500 - val_loss: 0.2919\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.6065\n",
      "[CV]  learning_rate=0.004387096309029169, n_hidden=2, n_neurons=91, total= 1.0min\n",
      "[CV] learning_rate=0.004387096309029169, n_hidden=2, n_neurons=91 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 1.0590 - val_loss: 0.6108\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 1.0073 - val_loss: 0.6156\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.9264 - val_loss: 0.5362\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5037 - val_loss: 0.4986\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4726 - val_loss: 0.4744\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4509 - val_loss: 0.4565\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4354 - val_loss: 0.4450\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4230 - val_loss: 0.4359\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4137 - val_loss: 0.4242\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4074 - val_loss: 0.4179\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4003 - val_loss: 0.4116\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3955 - val_loss: 0.4105\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3905 - val_loss: 0.4049\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3864 - val_loss: 0.3985\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3822 - val_loss: 0.3977\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3782 - val_loss: 0.3989\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3758 - val_loss: 0.3936\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3723 - val_loss: 0.3894\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3679 - val_loss: 0.3861\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3665 - val_loss: 0.3814\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3630 - val_loss: 0.3827\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3603 - val_loss: 0.3801\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3581 - val_loss: 0.3747\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3555 - val_loss: 0.3749\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3527 - val_loss: 0.3813\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3508 - val_loss: 0.3711\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3485 - val_loss: 0.3694\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3464 - val_loss: 0.3674\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3442 - val_loss: 0.3665\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3426 - val_loss: 0.3634\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3397 - val_loss: 0.3659\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3367 - val_loss: 0.3657\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3356 - val_loss: 0.3591\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3331 - val_loss: 0.3636\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3326 - val_loss: 0.3546\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3306 - val_loss: 0.3565\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3292 - val_loss: 0.3529\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3270 - val_loss: 0.3526\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3256 - val_loss: 0.3538\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3227 - val_loss: 0.3526\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3227 - val_loss: 0.3489\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3197 - val_loss: 0.3506\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3187 - val_loss: 0.3492\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3178 - val_loss: 0.3461\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3159 - val_loss: 0.3475\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3152 - val_loss: 0.3397\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3133 - val_loss: 0.3436\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3124 - val_loss: 0.3406\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3110 - val_loss: 0.3404\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3088 - val_loss: 0.3434\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3091 - val_loss: 0.3391\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3080 - val_loss: 0.3359\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3062 - val_loss: 0.3456\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3047 - val_loss: 0.3392\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3044 - val_loss: 0.3357\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3027 - val_loss: 0.3374\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3021 - val_loss: 0.3353\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3011 - val_loss: 0.3413\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2996 - val_loss: 0.3296\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2989 - val_loss: 0.3305\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2976 - val_loss: 0.3279\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2971 - val_loss: 0.3276\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2955 - val_loss: 0.3400\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2959 - val_loss: 0.3287\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2938 - val_loss: 0.3238\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2933 - val_loss: 0.3358\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2930 - val_loss: 0.3266\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2913 - val_loss: 0.3523\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2906 - val_loss: 0.3296\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2905 - val_loss: 0.3233\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2908 - val_loss: 0.3208\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2904 - val_loss: 0.3233\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2910 - val_loss: 0.3273\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2906 - val_loss: 0.3272\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2897 - val_loss: 0.3277\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2889 - val_loss: 0.3226\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2887 - val_loss: 0.3217\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2887 - val_loss: 0.3242\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2874 - val_loss: 0.3174\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2849 - val_loss: 0.3238\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2856 - val_loss: 0.3163\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2836 - val_loss: 0.3180\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2827 - val_loss: 0.3325\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2820 - val_loss: 0.3241\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2810 - val_loss: 0.3151\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2791 - val_loss: 0.3202\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2797 - val_loss: 0.3167\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2800 - val_loss: 0.3141\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2788 - val_loss: 0.3154\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2770 - val_loss: 0.3179\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2776 - val_loss: 0.3177\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2763 - val_loss: 0.3239\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2758 - val_loss: 0.3162\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2757 - val_loss: 0.3181\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2767 - val_loss: 0.3124\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2757 - val_loss: 0.3106\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2743 - val_loss: 0.3133\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2744 - val_loss: 0.3143\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2729 - val_loss: 0.3117\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2730 - val_loss: 0.3130\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2736 - val_loss: 0.3100\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2716 - val_loss: 0.3125\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2720 - val_loss: 0.3160\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2704 - val_loss: 0.3101\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2709 - val_loss: 0.3113\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2700 - val_loss: 0.3162\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2702 - val_loss: 0.3076\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2704 - val_loss: 0.3079\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2695 - val_loss: 0.3107\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2705 - val_loss: 0.3121\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2695 - val_loss: 0.3133\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2697 - val_loss: 0.3133\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2699 - val_loss: 0.3237\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2708 - val_loss: 0.3094\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2698 - val_loss: 0.3066\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2694 - val_loss: 0.3110\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2710 - val_loss: 0.3069\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2700 - val_loss: 0.3098\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2699 - val_loss: 0.3050\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2698 - val_loss: 0.3069\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2697 - val_loss: 0.3121\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2686 - val_loss: 0.3082\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2682 - val_loss: 0.3107\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2657 - val_loss: 0.3107\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2651 - val_loss: 0.3127\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2641 - val_loss: 0.3158\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2647 - val_loss: 0.3082\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2632 - val_loss: 0.3054\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2636 - val_loss: 0.3127\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3361\n",
      "[CV]  learning_rate=0.004387096309029169, n_hidden=2, n_neurons=91, total=  47.7s\n",
      "[CV] learning_rate=0.0010450997151351185, n_hidden=2, n_neurons=61 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 99us/sample - loss: 2.2366 - val_loss: 0.9232\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8527 - val_loss: 0.7134\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6983 - val_loss: 0.6551\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6526 - val_loss: 0.6248\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6235 - val_loss: 0.6019\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5996 - val_loss: 0.5830\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5805 - val_loss: 0.5662\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5631 - val_loss: 0.5519\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5496 - val_loss: 0.5396\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5378 - val_loss: 0.5296\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5274 - val_loss: 0.5209\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5181 - val_loss: 0.5125\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5106 - val_loss: 0.5059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5034 - val_loss: 0.5000\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4977 - val_loss: 0.4943\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4922 - val_loss: 0.4891\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4872 - val_loss: 0.4854\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4825 - val_loss: 0.4816\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4784 - val_loss: 0.4770\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4744 - val_loss: 0.4734\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4710 - val_loss: 0.4707\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4676 - val_loss: 0.4664\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4646 - val_loss: 0.4636\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4612 - val_loss: 0.4603\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4585 - val_loss: 0.4576\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4556 - val_loss: 0.4562\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4534 - val_loss: 0.4534\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4508 - val_loss: 0.4518\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4487 - val_loss: 0.4493\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4463 - val_loss: 0.4473\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4444 - val_loss: 0.4449\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4422 - val_loss: 0.4441\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4404 - val_loss: 0.4412\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4385 - val_loss: 0.4389\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4366 - val_loss: 0.4378\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4347 - val_loss: 0.4356\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4334 - val_loss: 0.4355\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4316 - val_loss: 0.4330\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4304 - val_loss: 0.4312\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4285 - val_loss: 0.4312\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4272 - val_loss: 0.4289\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4256 - val_loss: 0.4272\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4241 - val_loss: 0.4258\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4231 - val_loss: 0.4245\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4216 - val_loss: 0.4240\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4206 - val_loss: 0.4227\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4192 - val_loss: 0.4218\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4180 - val_loss: 0.4214\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4170 - val_loss: 0.4197\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4160 - val_loss: 0.4187\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4148 - val_loss: 0.4170\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4136 - val_loss: 0.4162\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4124 - val_loss: 0.4151\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4114 - val_loss: 0.4148\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4104 - val_loss: 0.4137\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4097 - val_loss: 0.4130\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4083 - val_loss: 0.4114\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4075 - val_loss: 0.4104\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4064 - val_loss: 0.4105\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4055 - val_loss: 0.4085\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4044 - val_loss: 0.4092\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4037 - val_loss: 0.4091\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4026 - val_loss: 0.4070\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4017 - val_loss: 0.4076\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4011 - val_loss: 0.4048\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4000 - val_loss: 0.4043\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3993 - val_loss: 0.4030\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3983 - val_loss: 0.4023\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3977 - val_loss: 0.4024\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3968 - val_loss: 0.4033\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3961 - val_loss: 0.4007\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3952 - val_loss: 0.4002\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3941 - val_loss: 0.3997\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3934 - val_loss: 0.3999\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3930 - val_loss: 0.3979\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3920 - val_loss: 0.3980\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3911 - val_loss: 0.3978\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3908 - val_loss: 0.3959\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3899 - val_loss: 0.3959\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3894 - val_loss: 0.3945\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3885 - val_loss: 0.3950\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3875 - val_loss: 0.3939\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3870 - val_loss: 0.3935\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3863 - val_loss: 0.3920\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3859 - val_loss: 0.3925\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3852 - val_loss: 0.3915\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3840 - val_loss: 0.3896\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3837 - val_loss: 0.3895\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3827 - val_loss: 0.3883\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3818 - val_loss: 0.3907\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3811 - val_loss: 0.3888\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3808 - val_loss: 0.3872\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3798 - val_loss: 0.3878\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3791 - val_loss: 0.3859\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3787 - val_loss: 0.3859\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3778 - val_loss: 0.3866\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3776 - val_loss: 0.3848\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3766 - val_loss: 0.3854\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3760 - val_loss: 0.3844\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3754 - val_loss: 0.3835\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3747 - val_loss: 0.3830\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3740 - val_loss: 0.3823\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3735 - val_loss: 0.3809\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3727 - val_loss: 0.3811\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3720 - val_loss: 0.3824\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3718 - val_loss: 0.3800\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3712 - val_loss: 0.3787\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3705 - val_loss: 0.3790\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3699 - val_loss: 0.3779\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3692 - val_loss: 0.3778\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3683 - val_loss: 0.3783\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3679 - val_loss: 0.3775\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3670 - val_loss: 0.3766\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3664 - val_loss: 0.3751\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3658 - val_loss: 0.3745\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3656 - val_loss: 0.3747\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3647 - val_loss: 0.3741\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3640 - val_loss: 0.3734\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3634 - val_loss: 0.3740\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3629 - val_loss: 0.3765\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3634 - val_loss: 0.3716\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3621 - val_loss: 0.3709\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3613 - val_loss: 0.3714\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3606 - val_loss: 0.3713\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.357 - 0s 52us/sample - loss: 0.3600 - val_loss: 0.3722\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3592 - val_loss: 0.3699\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3591 - val_loss: 0.3690\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3584 - val_loss: 0.3698\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3582 - val_loss: 0.3680\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3572 - val_loss: 0.3688\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3565 - val_loss: 0.3677\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3561 - val_loss: 0.3673\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3557 - val_loss: 0.3684\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3548 - val_loss: 0.3676\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3542 - val_loss: 0.3656\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3550 - val_loss: 0.3667\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3535 - val_loss: 0.3647\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3531 - val_loss: 0.3651\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3527 - val_loss: 0.3648\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3520 - val_loss: 0.3642\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3515 - val_loss: 0.3666\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3508 - val_loss: 0.3630\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3502 - val_loss: 0.3636\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3496 - val_loss: 0.3638\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3493 - val_loss: 0.3628\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3486 - val_loss: 0.3616\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3485 - val_loss: 0.3612\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3475 - val_loss: 0.3610\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3472 - val_loss: 0.3620\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3473 - val_loss: 0.3603\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3462 - val_loss: 0.3597\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3458 - val_loss: 0.3600\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3452 - val_loss: 0.3609\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3450 - val_loss: 0.3590\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3452 - val_loss: 0.3586\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3436 - val_loss: 0.3608\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3439 - val_loss: 0.3585\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3431 - val_loss: 0.3576\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3424 - val_loss: 0.3574\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3421 - val_loss: 0.3570\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3424 - val_loss: 0.3570\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3417 - val_loss: 0.3585\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3416 - val_loss: 0.3564\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3406 - val_loss: 0.3549\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3411 - val_loss: 0.3548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3409 - val_loss: 0.3547\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3424 - val_loss: 0.3548\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3403 - val_loss: 0.3550\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3401 - val_loss: 0.3539\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3400 - val_loss: 0.3556\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3406 - val_loss: 0.3543\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3401 - val_loss: 0.3517\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3386 - val_loss: 0.3518\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3364 - val_loss: 0.3528\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3357 - val_loss: 0.3529\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3352 - val_loss: 0.3529\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3372 - val_loss: 0.3508\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3345 - val_loss: 0.3509\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3345 - val_loss: 0.3501\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3335 - val_loss: 0.3512\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3330 - val_loss: 0.3520\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3322 - val_loss: 0.3482\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3324 - val_loss: 0.3488\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3317 - val_loss: 0.3490\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3316 - val_loss: 0.3490\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3318 - val_loss: 0.3488\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3306 - val_loss: 0.3492\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3298 - val_loss: 0.3471\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3294 - val_loss: 0.3470\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3287 - val_loss: 0.3477\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3285 - val_loss: 0.3464\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3283 - val_loss: 0.3461\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3284 - val_loss: 0.3456\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3272 - val_loss: 0.3461\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3274 - val_loss: 0.3462\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3270 - val_loss: 0.3444\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3268 - val_loss: 0.3456\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3262 - val_loss: 0.3456\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3257 - val_loss: 0.3440\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3248 - val_loss: 0.3449\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3246 - val_loss: 0.3437\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3246 - val_loss: 0.3435\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3249 - val_loss: 0.3451\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3243 - val_loss: 0.3423\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3236 - val_loss: 0.3416\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3224 - val_loss: 0.3434\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3228 - val_loss: 0.3415\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3223 - val_loss: 0.3408\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3219 - val_loss: 0.3425\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3213 - val_loss: 0.3400\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3215 - val_loss: 0.3413\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3206 - val_loss: 0.3429\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3206 - val_loss: 0.3421\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3206 - val_loss: 0.3394\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3205 - val_loss: 0.3401\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3211 - val_loss: 0.3397\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3220 - val_loss: 0.3399\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3224 - val_loss: 0.3402\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3211 - val_loss: 0.3401\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3209 - val_loss: 0.3392\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3203 - val_loss: 0.3401\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3194 - val_loss: 0.3387\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3190 - val_loss: 0.3385\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3197 - val_loss: 0.3429\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3201 - val_loss: 0.3378\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3216 - val_loss: 0.3373\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3170 - val_loss: 0.3373\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3158 - val_loss: 0.3368\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3152 - val_loss: 0.3359\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3149 - val_loss: 0.3361\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3153 - val_loss: 0.3376\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3144 - val_loss: 0.3352\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3143 - val_loss: 0.3365\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3139 - val_loss: 0.3366\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3134 - val_loss: 0.3354\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3132 - val_loss: 0.3364\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3127 - val_loss: 0.3344\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3149 - val_loss: 0.3356\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3118 - val_loss: 0.3361\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3120 - val_loss: 0.3347\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3120 - val_loss: 0.3381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3114 - val_loss: 0.3333\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3113 - val_loss: 0.3369\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3135 - val_loss: 0.3335\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3110 - val_loss: 0.3317\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3102 - val_loss: 0.3330\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3108 - val_loss: 0.3331\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3102 - val_loss: 0.3336\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3095 - val_loss: 0.3327\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3095 - val_loss: 0.3320\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3098 - val_loss: 0.3333\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3091 - val_loss: 0.3311\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3085 - val_loss: 0.3308\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3083 - val_loss: 0.3312\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3081 - val_loss: 0.3311\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3084 - val_loss: 0.3317\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3133 - val_loss: 0.3322\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3100 - val_loss: 0.3303\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3090 - val_loss: 0.3307\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3077 - val_loss: 0.3298\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3074 - val_loss: 0.3292\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3070 - val_loss: 0.3302\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3059 - val_loss: 0.3334\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3060 - val_loss: 0.3298\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3065 - val_loss: 0.3308\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3051 - val_loss: 0.3305\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3062 - val_loss: 0.3301\n",
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3047 - val_loss: 0.3281\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3047 - val_loss: 0.3284\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3051 - val_loss: 0.3287\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3045 - val_loss: 0.3283\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3038 - val_loss: 0.3287\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3042 - val_loss: 0.3277\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3035 - val_loss: 0.3292\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3033 - val_loss: 0.3280\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3032 - val_loss: 0.3266\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3029 - val_loss: 0.3296\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3025 - val_loss: 0.3268\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3027 - val_loss: 0.3311\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3027 - val_loss: 0.3274\n",
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3032 - val_loss: 0.3275\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3015 - val_loss: 0.3265\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3016 - val_loss: 0.3277\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3013 - val_loss: 0.3293\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3012 - val_loss: 0.3256\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3006 - val_loss: 0.3258\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3007 - val_loss: 0.3252\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3001 - val_loss: 0.3269\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3000 - val_loss: 0.3259\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3001 - val_loss: 0.3248\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3003 - val_loss: 0.3272\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2995 - val_loss: 0.3262\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3000 - val_loss: 0.3265\n",
      "Epoch 294/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2992 - val_loss: 0.3258\n",
      "Epoch 295/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2991 - val_loss: 0.3253\n",
      "Epoch 296/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2990 - val_loss: 0.3248\n",
      "Epoch 297/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2987 - val_loss: 0.3253\n",
      "Epoch 298/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3013 - val_loss: 0.3250\n",
      "Epoch 299/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2991 - val_loss: 0.3247\n",
      "Epoch 300/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2979 - val_loss: 0.3248\n",
      "Epoch 301/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2982 - val_loss: 0.3278\n",
      "Epoch 302/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2977 - val_loss: 0.3233\n",
      "Epoch 303/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2983 - val_loss: 0.3248\n",
      "Epoch 304/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2975 - val_loss: 0.3247\n",
      "Epoch 305/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2977 - val_loss: 0.3235\n",
      "Epoch 306/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2971 - val_loss: 0.3246\n",
      "Epoch 307/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2971 - val_loss: 0.3228\n",
      "Epoch 308/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2965 - val_loss: 0.3220\n",
      "Epoch 309/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2969 - val_loss: 0.3223\n",
      "Epoch 310/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2960 - val_loss: 0.3223\n",
      "Epoch 311/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2969 - val_loss: 0.3216\n",
      "Epoch 312/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2964 - val_loss: 0.3225\n",
      "Epoch 313/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2967 - val_loss: 0.3223\n",
      "Epoch 314/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2954 - val_loss: 0.3209\n",
      "Epoch 315/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2953 - val_loss: 0.3219\n",
      "Epoch 316/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2953 - val_loss: 0.3212\n",
      "Epoch 317/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2953 - val_loss: 0.3242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2952 - val_loss: 0.3228\n",
      "Epoch 319/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2946 - val_loss: 0.3209\n",
      "Epoch 320/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2945 - val_loss: 0.3209\n",
      "Epoch 321/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2944 - val_loss: 0.3213\n",
      "Epoch 322/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2941 - val_loss: 0.3221\n",
      "Epoch 323/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2933 - val_loss: 0.3226\n",
      "Epoch 324/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2941 - val_loss: 0.3208\n",
      "Epoch 325/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2934 - val_loss: 0.3233\n",
      "Epoch 326/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2937 - val_loss: 0.3198\n",
      "Epoch 327/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2934 - val_loss: 0.3222\n",
      "Epoch 328/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2941 - val_loss: 0.3234\n",
      "Epoch 329/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2931 - val_loss: 0.3208\n",
      "Epoch 330/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2928 - val_loss: 0.3203\n",
      "Epoch 331/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2923 - val_loss: 0.3198\n",
      "Epoch 332/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2922 - val_loss: 0.3202\n",
      "Epoch 333/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2923 - val_loss: 0.3196\n",
      "Epoch 334/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2920 - val_loss: 0.3201\n",
      "Epoch 335/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2917 - val_loss: 0.3223\n",
      "Epoch 336/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2918 - val_loss: 0.3198\n",
      "Epoch 337/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2916 - val_loss: 0.3205\n",
      "Epoch 338/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2912 - val_loss: 0.3189\n",
      "Epoch 339/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2913 - val_loss: 0.3197\n",
      "Epoch 340/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2912 - val_loss: 0.3203\n",
      "Epoch 341/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2918 - val_loss: 0.3197\n",
      "Epoch 342/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2906 - val_loss: 0.3185\n",
      "Epoch 343/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2907 - val_loss: 0.3193\n",
      "Epoch 344/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2906 - val_loss: 0.3183\n",
      "Epoch 345/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2916 - val_loss: 0.3203\n",
      "Epoch 346/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2903 - val_loss: 0.3190\n",
      "Epoch 347/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2900 - val_loss: 0.3177\n",
      "Epoch 348/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2896 - val_loss: 0.3188\n",
      "Epoch 349/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2894 - val_loss: 0.3220\n",
      "Epoch 350/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2895 - val_loss: 0.3187\n",
      "Epoch 351/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2892 - val_loss: 0.3199\n",
      "Epoch 352/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2894 - val_loss: 0.3189\n",
      "Epoch 353/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2898 - val_loss: 0.3236\n",
      "Epoch 354/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2897 - val_loss: 0.3178\n",
      "Epoch 355/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2886 - val_loss: 0.3227\n",
      "Epoch 356/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2886 - val_loss: 0.3180\n",
      "Epoch 357/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2888 - val_loss: 0.3177\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.2951\n",
      "[CV]  learning_rate=0.0010450997151351185, n_hidden=2, n_neurons=61, total= 2.3min\n",
      "[CV] learning_rate=0.0010450997151351185, n_hidden=2, n_neurons=61 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 2.2048 - val_loss: 0.9726\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.8318 - val_loss: 0.7202\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6850 - val_loss: 0.6599\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6414 - val_loss: 0.6291\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6119 - val_loss: 0.6032\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5878 - val_loss: 0.5823\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5673 - val_loss: 0.5637\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5489 - val_loss: 0.5474\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5330 - val_loss: 0.5330\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5190 - val_loss: 0.5206\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5064 - val_loss: 0.5089\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4951 - val_loss: 0.4989\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4854 - val_loss: 0.4900\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4773 - val_loss: 0.4831\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4694 - val_loss: 0.4759\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4632 - val_loss: 0.4703\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4573 - val_loss: 0.4641\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4516 - val_loss: 0.4601\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4473 - val_loss: 0.4550\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4422 - val_loss: 0.4504\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4390 - val_loss: 0.4471\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4353 - val_loss: 0.4431\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4333 - val_loss: 0.4411\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4290 - val_loss: 0.4376\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4267 - val_loss: 0.4360\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4240 - val_loss: 0.4326\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4217 - val_loss: 0.4310\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4191 - val_loss: 0.4284\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4170 - val_loss: 0.4259\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4150 - val_loss: 0.4250\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4127 - val_loss: 0.4224\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4113 - val_loss: 0.4216\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4096 - val_loss: 0.4190\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4077 - val_loss: 0.4168\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4056 - val_loss: 0.4158\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4042 - val_loss: 0.4165\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4030 - val_loss: 0.4130\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4010 - val_loss: 0.4118\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4003 - val_loss: 0.4115\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3986 - val_loss: 0.4101\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3973 - val_loss: 0.4075\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3959 - val_loss: 0.4063\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3947 - val_loss: 0.4050\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3936 - val_loss: 0.4055\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3921 - val_loss: 0.4028\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3909 - val_loss: 0.4019\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3893 - val_loss: 0.4008\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3887 - val_loss: 0.4002\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3875 - val_loss: 0.3998\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3869 - val_loss: 0.3992\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3854 - val_loss: 0.3975\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3843 - val_loss: 0.3957\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3833 - val_loss: 0.3957\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3821 - val_loss: 0.3955\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3815 - val_loss: 0.3947\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3801 - val_loss: 0.3928\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3794 - val_loss: 0.3914\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3784 - val_loss: 0.3907\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3774 - val_loss: 0.3908\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3758 - val_loss: 0.3915\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3760 - val_loss: 0.3881\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3745 - val_loss: 0.3881\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3737 - val_loss: 0.3863\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3728 - val_loss: 0.3871\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3720 - val_loss: 0.3853\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3712 - val_loss: 0.3847\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3701 - val_loss: 0.3843\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3692 - val_loss: 0.3834\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3683 - val_loss: 0.3831\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3677 - val_loss: 0.3811\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3670 - val_loss: 0.3818\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3658 - val_loss: 0.3796\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3658 - val_loss: 0.3799\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3646 - val_loss: 0.3782\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3636 - val_loss: 0.3780\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3628 - val_loss: 0.3775\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3623 - val_loss: 0.3767\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3612 - val_loss: 0.3759\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3605 - val_loss: 0.3771\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3600 - val_loss: 0.3751\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3591 - val_loss: 0.3746\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3580 - val_loss: 0.3745\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3577 - val_loss: 0.3741\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3567 - val_loss: 0.3732\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3561 - val_loss: 0.3722\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3559 - val_loss: 0.3733\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3553 - val_loss: 0.3707\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3543 - val_loss: 0.3712\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3537 - val_loss: 0.3700\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3529 - val_loss: 0.3694\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3521 - val_loss: 0.3682\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3511 - val_loss: 0.3689\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3510 - val_loss: 0.3676\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3502 - val_loss: 0.3689\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3497 - val_loss: 0.3669\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3490 - val_loss: 0.3668\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3484 - val_loss: 0.3668\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3479 - val_loss: 0.3652\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3472 - val_loss: 0.3648\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3465 - val_loss: 0.3644\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3458 - val_loss: 0.3639\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3454 - val_loss: 0.3647\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3450 - val_loss: 0.3626\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3445 - val_loss: 0.3623\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3436 - val_loss: 0.3634\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3433 - val_loss: 0.3617\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3426 - val_loss: 0.3613\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3417 - val_loss: 0.3613\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3413 - val_loss: 0.3606\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3410 - val_loss: 0.3598\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3399 - val_loss: 0.3591\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3403 - val_loss: 0.3591\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3391 - val_loss: 0.3593\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3388 - val_loss: 0.3584\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3385 - val_loss: 0.3575\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3378 - val_loss: 0.3573\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3371 - val_loss: 0.3584\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3368 - val_loss: 0.3568\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3360 - val_loss: 0.3559\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3357 - val_loss: 0.3556\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3349 - val_loss: 0.3569\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3347 - val_loss: 0.3563\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3343 - val_loss: 0.3545\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3333 - val_loss: 0.3565\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3334 - val_loss: 0.3550\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3330 - val_loss: 0.3538\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3321 - val_loss: 0.3548\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3317 - val_loss: 0.3527\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3314 - val_loss: 0.3531\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3305 - val_loss: 0.3527\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3308 - val_loss: 0.3533\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3302 - val_loss: 0.3510\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3292 - val_loss: 0.3512\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3290 - val_loss: 0.3504\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3281 - val_loss: 0.3513\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3279 - val_loss: 0.3500\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3275 - val_loss: 0.3516\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3272 - val_loss: 0.3499\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3266 - val_loss: 0.3489\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3261 - val_loss: 0.3486\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3260 - val_loss: 0.3501\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3252 - val_loss: 0.3485\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3248 - val_loss: 0.3480\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3246 - val_loss: 0.3495\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3238 - val_loss: 0.3468\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3235 - val_loss: 0.3464\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3232 - val_loss: 0.3474\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3228 - val_loss: 0.3464\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3224 - val_loss: 0.3471\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3220 - val_loss: 0.3457\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3213 - val_loss: 0.3454\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3211 - val_loss: 0.3453\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3207 - val_loss: 0.3445\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3204 - val_loss: 0.3445\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3202 - val_loss: 0.3453\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3198 - val_loss: 0.3444\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3194 - val_loss: 0.3444\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3192 - val_loss: 0.3437\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3184 - val_loss: 0.3444\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3183 - val_loss: 0.3435\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3172 - val_loss: 0.3451\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3174 - val_loss: 0.3423\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3169 - val_loss: 0.3426\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3164 - val_loss: 0.3423\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3163 - val_loss: 0.3423\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3153 - val_loss: 0.3416\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3158 - val_loss: 0.3413\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3149 - val_loss: 0.3412\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3145 - val_loss: 0.3416\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3143 - val_loss: 0.3446\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3142 - val_loss: 0.3417\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3133 - val_loss: 0.3402\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3131 - val_loss: 0.3408\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3131 - val_loss: 0.3389\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3124 - val_loss: 0.3389\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3119 - val_loss: 0.3400\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3121 - val_loss: 0.3387\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3116 - val_loss: 0.3388\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3110 - val_loss: 0.3385\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3107 - val_loss: 0.3388\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3114 - val_loss: 0.3376\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3098 - val_loss: 0.3376\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3096 - val_loss: 0.3384\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3095 - val_loss: 0.3374\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3087 - val_loss: 0.3373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3097 - val_loss: 0.3377\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3082 - val_loss: 0.3362\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3074 - val_loss: 0.3357\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3076 - val_loss: 0.3358\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3070 - val_loss: 0.3371\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3071 - val_loss: 0.3354\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3064 - val_loss: 0.3344\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3060 - val_loss: 0.3349\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3056 - val_loss: 0.3371\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3058 - val_loss: 0.3340\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3054 - val_loss: 0.3347\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3044 - val_loss: 0.3361\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3045 - val_loss: 0.3363\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3043 - val_loss: 0.3340\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3039 - val_loss: 0.3337\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3032 - val_loss: 0.3324\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3032 - val_loss: 0.3340\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3020 - val_loss: 0.3320\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3030 - val_loss: 0.3314\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3019 - val_loss: 0.3311\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3020 - val_loss: 0.3314\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3012 - val_loss: 0.3336\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3009 - val_loss: 0.3319\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3010 - val_loss: 0.3304\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3001 - val_loss: 0.3305\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2997 - val_loss: 0.3302\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2998 - val_loss: 0.3301\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2991 - val_loss: 0.3311\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2991 - val_loss: 0.3301\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2984 - val_loss: 0.3311\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2981 - val_loss: 0.3298\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2978 - val_loss: 0.3290\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2972 - val_loss: 0.3293\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2972 - val_loss: 0.3281\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2968 - val_loss: 0.3298\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2971 - val_loss: 0.3308\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2963 - val_loss: 0.3285\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2964 - val_loss: 0.3288\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2954 - val_loss: 0.3273\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2953 - val_loss: 0.3270\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2957 - val_loss: 0.3269\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2945 - val_loss: 0.3285\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2946 - val_loss: 0.3277\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2938 - val_loss: 0.3278\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2939 - val_loss: 0.3271\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2942 - val_loss: 0.3273\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2936 - val_loss: 0.3270\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2931 - val_loss: 0.3264\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2927 - val_loss: 0.3262\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2927 - val_loss: 0.3251\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2920 - val_loss: 0.3256\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2924 - val_loss: 0.3250\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2916 - val_loss: 0.3263\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2913 - val_loss: 0.3251\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2911 - val_loss: 0.3268\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2911 - val_loss: 0.3258\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2905 - val_loss: 0.3263\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2908 - val_loss: 0.3249\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2898 - val_loss: 0.3245\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2905 - val_loss: 0.3246\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2894 - val_loss: 0.3265\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2899 - val_loss: 0.3237\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2898 - val_loss: 0.3236\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2890 - val_loss: 0.3236\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2893 - val_loss: 0.3235\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2883 - val_loss: 0.3242\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2883 - val_loss: 0.3244\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2878 - val_loss: 0.3234\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2878 - val_loss: 0.3223\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2875 - val_loss: 0.3216\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2877 - val_loss: 0.3240\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2870 - val_loss: 0.3226\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2873 - val_loss: 0.3223\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2866 - val_loss: 0.3258\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2865 - val_loss: 0.3234\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2875 - val_loss: 0.3245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2859 - val_loss: 0.3222\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2882 - val_loss: 0.3221\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2855 - val_loss: 0.3234\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2857 - val_loss: 0.3222\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.3341\n",
      "[CV]  learning_rate=0.0010450997151351185, n_hidden=2, n_neurons=61, total= 1.7min\n",
      "[CV] learning_rate=0.0010450997151351185, n_hidden=2, n_neurons=61 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 2.2975 - val_loss: 0.9087\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.8298 - val_loss: 0.7630\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7193 - val_loss: 0.7099\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6798 - val_loss: 0.6786\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6494 - val_loss: 0.6542\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6254 - val_loss: 0.6321\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6047 - val_loss: 0.6137\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5855 - val_loss: 0.5976\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5690 - val_loss: 0.5821\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5534 - val_loss: 0.5680\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5398 - val_loss: 0.5554\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5275 - val_loss: 0.5436\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5163 - val_loss: 0.5344\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5064 - val_loss: 0.5234\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4976 - val_loss: 0.5145\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4894 - val_loss: 0.5068\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4819 - val_loss: 0.4997\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4753 - val_loss: 0.4926\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4690 - val_loss: 0.4868\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4635 - val_loss: 0.4807\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4586 - val_loss: 0.4767\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4541 - val_loss: 0.4715\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4500 - val_loss: 0.4674\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4463 - val_loss: 0.4628\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4426 - val_loss: 0.4597\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4393 - val_loss: 0.4566\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4362 - val_loss: 0.4528\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4339 - val_loss: 0.4497\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4304 - val_loss: 0.4465\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4289 - val_loss: 0.4446\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4255 - val_loss: 0.4417\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4241 - val_loss: 0.4417\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4210 - val_loss: 0.4370\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4194 - val_loss: 0.4360\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4175 - val_loss: 0.4339\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4163 - val_loss: 0.4317\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4144 - val_loss: 0.4299\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4137 - val_loss: 0.4292\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4135 - val_loss: 0.4269\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4160 - val_loss: 0.4314\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4146 - val_loss: 0.4224\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4120 - val_loss: 0.4228\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4081 - val_loss: 0.4201\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4092 - val_loss: 0.4193\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4037 - val_loss: 0.4180\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4016 - val_loss: 0.4163\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3988 - val_loss: 0.4144\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3981 - val_loss: 0.4147\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3963 - val_loss: 0.4131\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3949 - val_loss: 0.4118\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3924 - val_loss: 0.4102\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3925 - val_loss: 0.4104\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3909 - val_loss: 0.4079\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3898 - val_loss: 0.4080\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3880 - val_loss: 0.4069\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3880 - val_loss: 0.4052\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3858 - val_loss: 0.4056\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3852 - val_loss: 0.4036\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3833 - val_loss: 0.4047\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3825 - val_loss: 0.4028\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3817 - val_loss: 0.4008\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3808 - val_loss: 0.4001\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3800 - val_loss: 0.3992\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3800 - val_loss: 0.3983\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3784 - val_loss: 0.3977\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3779 - val_loss: 0.3982\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3772 - val_loss: 0.3965\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3771 - val_loss: 0.3971\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3765 - val_loss: 0.3954\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3764 - val_loss: 0.3943\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3750 - val_loss: 0.3935\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3745 - val_loss: 0.3930\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3726 - val_loss: 0.3936\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3730 - val_loss: 0.3925\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3712 - val_loss: 0.3907\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3718 - val_loss: 0.3908\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3692 - val_loss: 0.3893\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3695 - val_loss: 0.3883\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3687 - val_loss: 0.3902\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3696 - val_loss: 0.3868\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3665 - val_loss: 0.3869\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3649 - val_loss: 0.3860\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3633 - val_loss: 0.3864\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3627 - val_loss: 0.3852\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3617 - val_loss: 0.3843\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3610 - val_loss: 0.3842\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3601 - val_loss: 0.3836\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3593 - val_loss: 0.3822\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3589 - val_loss: 0.3827\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3580 - val_loss: 0.3813\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3571 - val_loss: 0.3827\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3566 - val_loss: 0.3801\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3560 - val_loss: 0.3804\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3553 - val_loss: 0.3806\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3546 - val_loss: 0.3791\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3539 - val_loss: 0.3787\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3534 - val_loss: 0.3784\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3527 - val_loss: 0.3775\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3519 - val_loss: 0.3769\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3517 - val_loss: 0.3767\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3506 - val_loss: 0.3777\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3505 - val_loss: 0.3766\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3496 - val_loss: 0.3763\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3493 - val_loss: 0.3745\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3486 - val_loss: 0.3745\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3477 - val_loss: 0.3736\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3472 - val_loss: 0.3733\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3468 - val_loss: 0.3743\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3461 - val_loss: 0.3728\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3459 - val_loss: 0.3720\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3452 - val_loss: 0.3726\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3447 - val_loss: 0.3709\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3440 - val_loss: 0.3703\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3436 - val_loss: 0.3719\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3428 - val_loss: 0.3700\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3425 - val_loss: 0.3698\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3421 - val_loss: 0.3705\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3417 - val_loss: 0.3693\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3411 - val_loss: 0.3698\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3408 - val_loss: 0.3681\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3398 - val_loss: 0.3671\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3396 - val_loss: 0.3666\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3389 - val_loss: 0.3670\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3384 - val_loss: 0.3667\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3380 - val_loss: 0.3687\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3379 - val_loss: 0.3659\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3373 - val_loss: 0.3665\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3369 - val_loss: 0.3655\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3364 - val_loss: 0.3651\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3366 - val_loss: 0.3643\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3352 - val_loss: 0.3640\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3351 - val_loss: 0.3655\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3349 - val_loss: 0.3634\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3346 - val_loss: 0.3633\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3345 - val_loss: 0.3631\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3351 - val_loss: 0.3634\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3345 - val_loss: 0.3643\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3343 - val_loss: 0.3620\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3342 - val_loss: 0.3630\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3347 - val_loss: 0.3608\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3347 - val_loss: 0.3621\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3362 - val_loss: 0.3611\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3369 - val_loss: 0.3658\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3399 - val_loss: 0.3612\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3417 - val_loss: 0.3682\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3447 - val_loss: 0.3668\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3475 - val_loss: 0.3604\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3494 - val_loss: 0.3606\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3486 - val_loss: 0.3627\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3491 - val_loss: 0.3577\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3445 - val_loss: 0.3605\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3405 - val_loss: 0.3604\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3366 - val_loss: 0.3579\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3330 - val_loss: 0.3569\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3300 - val_loss: 0.3576\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3287 - val_loss: 0.3569\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3274 - val_loss: 0.3585\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3262 - val_loss: 0.3586\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3254 - val_loss: 0.3568\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3252 - val_loss: 0.3562\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3243 - val_loss: 0.3555\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3237 - val_loss: 0.3544\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3233 - val_loss: 0.3544\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3227 - val_loss: 0.3543\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3225 - val_loss: 0.3542\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3218 - val_loss: 0.3537\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3218 - val_loss: 0.3546\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3214 - val_loss: 0.3536\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3209 - val_loss: 0.3534\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3205 - val_loss: 0.3547\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3201 - val_loss: 0.3525\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3198 - val_loss: 0.3546\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3193 - val_loss: 0.3522\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3192 - val_loss: 0.3534\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3186 - val_loss: 0.3527\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3184 - val_loss: 0.3517\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3180 - val_loss: 0.3519\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3177 - val_loss: 0.3509\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3173 - val_loss: 0.3507\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3170 - val_loss: 0.3512\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3166 - val_loss: 0.3508\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3162 - val_loss: 0.3511\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3164 - val_loss: 0.3512\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3158 - val_loss: 0.3509\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3156 - val_loss: 0.3503\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3150 - val_loss: 0.3496\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3152 - val_loss: 0.3505\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3146 - val_loss: 0.3489\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3145 - val_loss: 0.3489\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3141 - val_loss: 0.3503\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3138 - val_loss: 0.3499\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3137 - val_loss: 0.3489\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3134 - val_loss: 0.3477\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3131 - val_loss: 0.3475\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3133 - val_loss: 0.3476\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3133 - val_loss: 0.3470\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3127 - val_loss: 0.3477\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3135 - val_loss: 0.3461\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3137 - val_loss: 0.3472\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3139 - val_loss: 0.3470\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3143 - val_loss: 0.3466\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3152 - val_loss: 0.3453\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3167 - val_loss: 0.3463\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3169 - val_loss: 0.3449\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3183 - val_loss: 0.3470\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3190 - val_loss: 0.3440\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3204 - val_loss: 0.3476\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3218 - val_loss: 0.3448\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3221 - val_loss: 0.3458\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3224 - val_loss: 0.3441\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3206 - val_loss: 0.3452\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3202 - val_loss: 0.3432\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3185 - val_loss: 0.3451\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3168 - val_loss: 0.3427\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3145 - val_loss: 0.3450\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3128 - val_loss: 0.3420\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3119 - val_loss: 0.3450\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3097 - val_loss: 0.3443\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3087 - val_loss: 0.3442\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3085 - val_loss: 0.3464\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3077 - val_loss: 0.3423\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3067 - val_loss: 0.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3062 - val_loss: 0.3424\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3059 - val_loss: 0.3410\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3052 - val_loss: 0.3410\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3050 - val_loss: 0.3420\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3048 - val_loss: 0.3419\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3042 - val_loss: 0.3425\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3041 - val_loss: 0.3405\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3038 - val_loss: 0.3403\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3037 - val_loss: 0.3400\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3031 - val_loss: 0.3401\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3029 - val_loss: 0.3423\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3027 - val_loss: 0.3423\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3028 - val_loss: 0.3404\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3021 - val_loss: 0.3419\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3021 - val_loss: 0.3393\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3016 - val_loss: 0.3394\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3016 - val_loss: 0.3401\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3015 - val_loss: 0.3386\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3009 - val_loss: 0.3388\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3009 - val_loss: 0.3380\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3005 - val_loss: 0.3381\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3005 - val_loss: 0.3379\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3000 - val_loss: 0.3377\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3002 - val_loss: 0.3365\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2995 - val_loss: 0.3379\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2994 - val_loss: 0.3367\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2994 - val_loss: 0.3381\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2988 - val_loss: 0.3371\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2986 - val_loss: 0.3371\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2985 - val_loss: 0.3378\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2980 - val_loss: 0.3360\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2981 - val_loss: 0.3355\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2979 - val_loss: 0.3356\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2974 - val_loss: 0.3356\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2974 - val_loss: 0.3376\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2972 - val_loss: 0.3356\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2970 - val_loss: 0.3358\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2969 - val_loss: 0.3351\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2968 - val_loss: 0.3345\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2969 - val_loss: 0.3356\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2961 - val_loss: 0.3341\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2965 - val_loss: 0.3348\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2963 - val_loss: 0.3345\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2964 - val_loss: 0.3337\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2973 - val_loss: 0.3344\n",
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2981 - val_loss: 0.3342\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2984 - val_loss: 0.3341\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2993 - val_loss: 0.3332\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3006 - val_loss: 0.3342\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3027 - val_loss: 0.3320\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3054 - val_loss: 0.3374\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3081 - val_loss: 0.3330\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3097 - val_loss: 0.3348\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3091 - val_loss: 0.3325\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3080 - val_loss: 0.3342\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3047 - val_loss: 0.3389\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3035 - val_loss: 0.3328\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3020 - val_loss: 0.3319\n",
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2993 - val_loss: 0.3324\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2969 - val_loss: 0.3323\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2954 - val_loss: 0.3324\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2942 - val_loss: 0.3314\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2937 - val_loss: 0.3326\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2930 - val_loss: 0.3316\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2930 - val_loss: 0.3315\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2921 - val_loss: 0.3330\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2923 - val_loss: 0.3315\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2914 - val_loss: 0.3307\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2912 - val_loss: 0.3320\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2909 - val_loss: 0.3324\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2904 - val_loss: 0.3304\n",
      "Epoch 294/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2904 - val_loss: 0.3302\n",
      "Epoch 295/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2899 - val_loss: 0.3302\n",
      "Epoch 296/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2900 - val_loss: 0.3305\n",
      "Epoch 297/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2895 - val_loss: 0.3321\n",
      "Epoch 298/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2895 - val_loss: 0.3302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2892 - val_loss: 0.3311\n",
      "Epoch 300/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2889 - val_loss: 0.3293\n",
      "Epoch 301/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2889 - val_loss: 0.3301\n",
      "Epoch 302/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2887 - val_loss: 0.3299\n",
      "Epoch 303/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2885 - val_loss: 0.3289\n",
      "Epoch 304/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2883 - val_loss: 0.3302\n",
      "Epoch 305/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2884 - val_loss: 0.3304\n",
      "Epoch 306/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2882 - val_loss: 0.3298\n",
      "Epoch 307/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2880 - val_loss: 0.3284\n",
      "Epoch 308/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2879 - val_loss: 0.3289\n",
      "Epoch 309/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2872 - val_loss: 0.3300\n",
      "Epoch 310/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2874 - val_loss: 0.3291\n",
      "Epoch 311/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2874 - val_loss: 0.3305\n",
      "Epoch 312/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2870 - val_loss: 0.3286\n",
      "Epoch 313/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2867 - val_loss: 0.3287\n",
      "Epoch 314/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2866 - val_loss: 0.3272\n",
      "Epoch 315/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2866 - val_loss: 0.3282\n",
      "Epoch 316/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2861 - val_loss: 0.3273\n",
      "Epoch 317/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2858 - val_loss: 0.3301\n",
      "Epoch 318/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2859 - val_loss: 0.3319\n",
      "Epoch 319/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2858 - val_loss: 0.3284\n",
      "Epoch 320/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2861 - val_loss: 0.3266\n",
      "Epoch 321/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2856 - val_loss: 0.3274\n",
      "Epoch 322/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2855 - val_loss: 0.3273\n",
      "Epoch 323/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2857 - val_loss: 0.3298\n",
      "Epoch 324/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2854 - val_loss: 0.3268\n",
      "Epoch 325/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2849 - val_loss: 0.3296\n",
      "Epoch 326/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2852 - val_loss: 0.3265\n",
      "Epoch 327/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2848 - val_loss: 0.3294\n",
      "Epoch 328/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2843 - val_loss: 0.3293\n",
      "Epoch 329/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2843 - val_loss: 0.3271\n",
      "Epoch 330/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2840 - val_loss: 0.3267\n",
      "Epoch 331/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2841 - val_loss: 0.3254\n",
      "Epoch 332/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2839 - val_loss: 0.3260\n",
      "Epoch 333/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2838 - val_loss: 0.3256\n",
      "Epoch 334/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2835 - val_loss: 0.3260\n",
      "Epoch 335/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2832 - val_loss: 0.3270\n",
      "Epoch 336/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2831 - val_loss: 0.3267\n",
      "Epoch 337/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2829 - val_loss: 0.3261\n",
      "Epoch 338/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2828 - val_loss: 0.3267\n",
      "Epoch 339/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2833 - val_loss: 0.3266\n",
      "Epoch 340/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2830 - val_loss: 0.3251\n",
      "Epoch 341/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2825 - val_loss: 0.3243\n",
      "Epoch 342/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2830 - val_loss: 0.3260\n",
      "Epoch 343/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2823 - val_loss: 0.3269\n",
      "Epoch 344/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2822 - val_loss: 0.3266\n",
      "Epoch 345/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2820 - val_loss: 0.3269\n",
      "Epoch 346/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2819 - val_loss: 0.3256\n",
      "Epoch 347/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2823 - val_loss: 0.3239\n",
      "Epoch 348/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2821 - val_loss: 0.3241\n",
      "Epoch 349/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2817 - val_loss: 0.3275\n",
      "Epoch 350/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2814 - val_loss: 0.3255\n",
      "Epoch 351/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2815 - val_loss: 0.3242\n",
      "Epoch 352/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2817 - val_loss: 0.3252\n",
      "Epoch 353/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2817 - val_loss: 0.3246\n",
      "Epoch 354/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2829 - val_loss: 0.3249\n",
      "Epoch 355/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2836 - val_loss: 0.3230\n",
      "Epoch 356/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2843 - val_loss: 0.3244\n",
      "Epoch 357/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2848 - val_loss: 0.3248\n",
      "Epoch 358/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2862 - val_loss: 0.3248\n",
      "Epoch 359/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2873 - val_loss: 0.3244\n",
      "Epoch 360/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2893 - val_loss: 0.3263\n",
      "Epoch 361/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2907 - val_loss: 0.3236\n",
      "Epoch 362/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2907 - val_loss: 0.3252\n",
      "Epoch 363/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2912 - val_loss: 0.3243\n",
      "Epoch 364/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2912 - val_loss: 0.3273\n",
      "Epoch 365/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2917 - val_loss: 0.3236\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.3399\n",
      "[CV]  learning_rate=0.0010450997151351185, n_hidden=2, n_neurons=61, total= 2.3min\n",
      "[CV] learning_rate=0.005053370463007658, n_hidden=1, n_neurons=41 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.6285 - val_loss: 0.5682\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.8874 - val_loss: 0.6024\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5878 - val_loss: 0.6201\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5472 - val_loss: 0.4834\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4837 - val_loss: 0.4631\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4681 - val_loss: 0.4497\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4491 - val_loss: 0.4375\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4396 - val_loss: 0.4288\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4269 - val_loss: 0.4192\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4186 - val_loss: 0.4146\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4126 - val_loss: 0.4108\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4097 - val_loss: 0.4089\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4087 - val_loss: 0.4065\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4037 - val_loss: 0.4004\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4030 - val_loss: 0.3986\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4010 - val_loss: 0.4000\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3987 - val_loss: 0.3984\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4020 - val_loss: 0.3951\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3966 - val_loss: 0.3957\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3938 - val_loss: 0.3924\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3912 - val_loss: 0.3892\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3889 - val_loss: 0.3881\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3883 - val_loss: 0.4082\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3887 - val_loss: 0.3875\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3884 - val_loss: 0.3892\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3848 - val_loss: 0.3851\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3837 - val_loss: 0.3822\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3827 - val_loss: 0.3855\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3895 - val_loss: 0.3806\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3801 - val_loss: 0.3808\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3817 - val_loss: 0.3793\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3782 - val_loss: 0.3779\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3764 - val_loss: 0.3768\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3771 - val_loss: 0.3839\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3774 - val_loss: 0.3788\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3737 - val_loss: 0.3909\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3736 - val_loss: 0.3795\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3754 - val_loss: 0.3745\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3778 - val_loss: 0.3725\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3688 - val_loss: 0.3732\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3687 - val_loss: 0.3729\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3677 - val_loss: 0.3708\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3662 - val_loss: 0.3719\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3667 - val_loss: 0.3687\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3647 - val_loss: 0.3668\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3654 - val_loss: 0.3679\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3643 - val_loss: 0.3681\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3618 - val_loss: 0.3674\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3622 - val_loss: 0.3697\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3613 - val_loss: 0.3644\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3587 - val_loss: 0.3624\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3575 - val_loss: 0.3639\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3578 - val_loss: 0.3609\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3576 - val_loss: 0.3650\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3596 - val_loss: 0.3623\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3592 - val_loss: 0.3618\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3543 - val_loss: 0.3628\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3560 - val_loss: 0.3602\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3528 - val_loss: 0.3574\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3516 - val_loss: 0.3604\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3515 - val_loss: 0.3582\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3578 - val_loss: 0.3567\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3571 - val_loss: 0.5238\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3756 - val_loss: 0.3639\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3693 - val_loss: 0.3567\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3477 - val_loss: 0.3610\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3522 - val_loss: 0.3546\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3487 - val_loss: 0.3600\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3462 - val_loss: 0.3536\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3461 - val_loss: 0.3734\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3453 - val_loss: 0.3527\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3455 - val_loss: 0.3513\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3444 - val_loss: 0.3503\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3429 - val_loss: 0.3814\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3638 - val_loss: 0.3502\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3513 - val_loss: 0.3513\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3408 - val_loss: 0.3571\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3441 - val_loss: 0.3571\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3550 - val_loss: 0.3532\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3437 - val_loss: 0.3496\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3393 - val_loss: 0.3500\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3380 - val_loss: 0.3469\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3373 - val_loss: 0.3460\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3365 - val_loss: 0.3457\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3371 - val_loss: 0.4469\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3500 - val_loss: 0.3438\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3521 - val_loss: 0.3529\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3360 - val_loss: 0.3439\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3349 - val_loss: 0.3460\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3411 - val_loss: 0.3453\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3352 - val_loss: 0.3723\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3349 - val_loss: 0.3467\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3365 - val_loss: 0.3483\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3337 - val_loss: 0.3429\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3320 - val_loss: 0.3431\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3312 - val_loss: 0.3461\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3332 - val_loss: 0.3455\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3318 - val_loss: 0.3428\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3302 - val_loss: 0.3428\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3294 - val_loss: 0.3431\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3276 - val_loss: 0.3559\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3339 - val_loss: 0.3422\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3289 - val_loss: 0.3429\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3283 - val_loss: 0.3411\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3280 - val_loss: 0.3384\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3280 - val_loss: 0.3420\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3308 - val_loss: 0.3492\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3269 - val_loss: 0.3392\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3268 - val_loss: 0.3395\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3300 - val_loss: 0.3368\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3262 - val_loss: 0.3392\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3269 - val_loss: 0.3415\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3347 - val_loss: 0.3378\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3254 - val_loss: 0.3401\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3243 - val_loss: 0.3411\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3240 - val_loss: 0.3362\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3237 - val_loss: 0.3398\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3230 - val_loss: 0.3436\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3232 - val_loss: 0.3353\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3262 - val_loss: 0.3354\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3242 - val_loss: 0.3407\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3223 - val_loss: 0.3395\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3223 - val_loss: 0.3343\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3237 - val_loss: 0.3378\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3216 - val_loss: 0.3392\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3209 - val_loss: 0.3357\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3207 - val_loss: 0.3380\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3216 - val_loss: 0.3355\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3200 - val_loss: 0.3376\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3195 - val_loss: 0.3349\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3189 - val_loss: 0.3395\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3223 - val_loss: 0.3389\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3208 - val_loss: 0.3352\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3072\n",
      "[CV]  learning_rate=0.005053370463007658, n_hidden=1, n_neurons=41, total=  46.3s\n",
      "[CV] learning_rate=0.005053370463007658, n_hidden=1, n_neurons=41 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 1.1538 - val_loss: 0.6258\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5752 - val_loss: 0.5443\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5180 - val_loss: 0.5054\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4886 - val_loss: 0.4825\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4710 - val_loss: 0.4701\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4602 - val_loss: 0.4630\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4513 - val_loss: 0.4541\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4452 - val_loss: 0.4490\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4386 - val_loss: 0.4463\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4345 - val_loss: 0.4387\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4293 - val_loss: 0.4390\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4273 - val_loss: 0.4301\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4225 - val_loss: 0.4301\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4184 - val_loss: 0.4246\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4162 - val_loss: 0.4232\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4129 - val_loss: 0.4188\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4096 - val_loss: 0.4195\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4100 - val_loss: 0.4377\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5047 - val_loss: 0.4150\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4065 - val_loss: 0.4122\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4044 - val_loss: 0.4116\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4047 - val_loss: 0.4124\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3996 - val_loss: 0.4065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4054 - val_loss: 0.4065\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3974 - val_loss: 0.4028\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3934 - val_loss: 0.4027\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3968 - val_loss: 0.4018\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3900 - val_loss: 0.4004\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3903 - val_loss: 0.3987\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3870 - val_loss: 0.3972\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3877 - val_loss: 0.4054\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3868 - val_loss: 0.4052\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3946 - val_loss: 0.3928\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3877 - val_loss: 0.3964\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3811 - val_loss: 0.3900\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3847 - val_loss: 0.3913\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3842 - val_loss: 0.3893\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3818 - val_loss: 0.3894\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3769 - val_loss: 0.3877\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3806 - val_loss: 0.3881\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3792 - val_loss: 0.3862\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3753 - val_loss: 0.3877\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3781 - val_loss: 0.3851\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3753 - val_loss: 0.3857\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3732 - val_loss: 0.4245\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3750 - val_loss: 0.3886\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3694 - val_loss: 0.3828\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3703 - val_loss: 0.3809\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3680 - val_loss: 0.4096\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4478 - val_loss: 0.3849\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3694 - val_loss: 0.3837\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3713 - val_loss: 0.3817\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3706 - val_loss: 0.3838\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3655 - val_loss: 0.3799\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3639 - val_loss: 0.3804\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3642 - val_loss: 0.3793\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3634 - val_loss: 0.3795\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3606 - val_loss: 0.3777\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3632 - val_loss: 0.3798\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3595 - val_loss: 0.3749\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3584 - val_loss: 0.3768\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3618 - val_loss: 0.3739\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3575 - val_loss: 0.3753\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3562 - val_loss: 0.3761\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3598 - val_loss: 0.3716\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3539 - val_loss: 0.3730\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3567 - val_loss: 0.3712\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3535 - val_loss: 0.3722\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3555 - val_loss: 0.3755\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3526 - val_loss: 0.3690\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3511 - val_loss: 0.3692\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3554 - val_loss: 0.3742\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3558 - val_loss: 0.3681\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3493 - val_loss: 0.3727\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3616 - val_loss: 0.3661\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3481 - val_loss: 0.3653\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3491 - val_loss: 0.3651\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3468 - val_loss: 0.3650\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3465 - val_loss: 0.3652\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3453 - val_loss: 0.3628\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3461 - val_loss: 0.3888\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3476 - val_loss: 0.3792\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3454 - val_loss: 0.3613\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3452 - val_loss: 0.3607\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3433 - val_loss: 0.3622\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3454 - val_loss: 0.3649\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3424 - val_loss: 0.3745\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4151 - val_loss: 0.3644\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3477 - val_loss: 0.3636\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3469 - val_loss: 0.3732\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3432 - val_loss: 0.3601\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3476 - val_loss: 0.3618\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3413 - val_loss: 0.3586\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3414 - val_loss: 0.3608\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3397 - val_loss: 0.3576\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3414 - val_loss: 0.3571\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3380 - val_loss: 0.3558\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3372 - val_loss: 0.3645\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3378 - val_loss: 0.3569\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3355 - val_loss: 0.3571\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3360 - val_loss: 0.3557\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3352 - val_loss: 0.3550\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3383 - val_loss: 0.3590\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3565 - val_loss: 0.3524\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3432 - val_loss: 0.3508\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3355 - val_loss: 0.3507\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3331 - val_loss: 0.3537\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3318 - val_loss: 0.3649\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3542 - val_loss: 0.3594\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3321 - val_loss: 0.3531\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3349 - val_loss: 0.3534\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3314 - val_loss: 0.3487\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3308 - val_loss: 0.3480\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3295 - val_loss: 0.3507\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3287 - val_loss: 0.3495\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3283 - val_loss: 0.3503\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3294 - val_loss: 0.3464\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3282 - val_loss: 0.3450\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3262 - val_loss: 0.3450\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3274 - val_loss: 0.3436\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3256 - val_loss: 0.3451\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3294 - val_loss: 0.3468\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3268 - val_loss: 0.3450\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3246 - val_loss: 0.3445\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3247 - val_loss: 0.3433\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3273 - val_loss: 0.3463\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3269 - val_loss: 0.3428\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3222 - val_loss: 0.3416\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3240 - val_loss: 0.3427\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3208 - val_loss: 0.3411\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3240 - val_loss: 0.3455\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3222 - val_loss: 0.3428\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3200 - val_loss: 0.3405\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3251 - val_loss: 0.3397\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3212 - val_loss: 0.3407\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3202 - val_loss: 0.3381\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3185 - val_loss: 0.3385\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3236 - val_loss: 0.3466\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3179 - val_loss: 0.3382\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3177 - val_loss: 0.3365\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3167 - val_loss: 0.3355\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3171 - val_loss: 0.3376\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3161 - val_loss: 0.3367\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3166 - val_loss: 0.3364\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3170 - val_loss: 0.3396\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3199 - val_loss: 0.3371\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3183 - val_loss: 0.3350\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3139 - val_loss: 0.3347\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3171 - val_loss: 0.3435\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3186 - val_loss: 0.3341\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3134 - val_loss: 0.3350\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3147 - val_loss: 0.3349\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3119 - val_loss: 0.3332\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3161 - val_loss: 0.3332\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3115 - val_loss: 0.3370\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3117 - val_loss: 0.3330\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3141 - val_loss: 0.3358\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3166 - val_loss: 0.3389\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3115 - val_loss: 0.3332\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3102 - val_loss: 0.3328\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3117 - val_loss: 0.3329\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3099 - val_loss: 0.3413\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3098 - val_loss: 0.3311\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3092 - val_loss: 0.3327\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3095 - val_loss: 0.3298\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3094 - val_loss: 0.3299\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3087 - val_loss: 0.3292\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3088 - val_loss: 0.3509\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3103 - val_loss: 0.3293\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3079 - val_loss: 0.3303\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3082 - val_loss: 0.3312\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3153 - val_loss: 0.3286\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3080 - val_loss: 0.3295\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3092 - val_loss: 0.3272\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3066 - val_loss: 0.3280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3066 - val_loss: 0.3274\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3065 - val_loss: 0.3273\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3082 - val_loss: 0.3299\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3072 - val_loss: 0.3315\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3056 - val_loss: 0.3281\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3044 - val_loss: 0.3275\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3043 - val_loss: 0.3260\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3041 - val_loss: 0.3297\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3036 - val_loss: 0.3279\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3052 - val_loss: 0.3269\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3034 - val_loss: 0.3254\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3051 - val_loss: 0.3245\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3046 - val_loss: 0.3362\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3057 - val_loss: 0.3328\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3030 - val_loss: 0.3252\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3031 - val_loss: 0.3275\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3030 - val_loss: 0.3253\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3044 - val_loss: 0.3233\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3100 - val_loss: 0.3294\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3050 - val_loss: 0.3333\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3176 - val_loss: 0.3266\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3043 - val_loss: 0.3291\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3103 - val_loss: 0.3299\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3050 - val_loss: 0.3277\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3085 - val_loss: 0.3262\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3072 - val_loss: 0.3277\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3004 - val_loss: 0.3223\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3018 - val_loss: 0.3277\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3040 - val_loss: 0.3244\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3020 - val_loss: 0.3333\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3003 - val_loss: 0.3350\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3001 - val_loss: 0.3253\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3046 - val_loss: 0.3343\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3191 - val_loss: 0.3251\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3001 - val_loss: 0.3225\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3017 - val_loss: 0.3250\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2988 - val_loss: 0.3270\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.8001\n",
      "[CV]  learning_rate=0.005053370463007658, n_hidden=1, n_neurons=41, total= 1.2min\n",
      "[CV] learning_rate=0.005053370463007658, n_hidden=1, n_neurons=41 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.2689 - val_loss: 0.7385\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.7553 - val_loss: 0.5899\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5311 - val_loss: 0.5007\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4727 - val_loss: 0.4616\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4390 - val_loss: 0.4359\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4227 - val_loss: 0.4292\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4138 - val_loss: 0.4209\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4072 - val_loss: 0.4152\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4018 - val_loss: 0.4105\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3967 - val_loss: 0.4072\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3933 - val_loss: 0.4039\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3896 - val_loss: 0.4059\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3867 - val_loss: 0.4005\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3838 - val_loss: 0.3985\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3825 - val_loss: 0.3952\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3790 - val_loss: 0.3968\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3772 - val_loss: 0.3930\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3754 - val_loss: 0.3921\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3730 - val_loss: 0.3914\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3720 - val_loss: 0.3904\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3707 - val_loss: 0.3879\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3685 - val_loss: 0.3884\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3678 - val_loss: 0.3844\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3663 - val_loss: 0.3858\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3653 - val_loss: 0.3813\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3637 - val_loss: 0.3832\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3627 - val_loss: 0.3807\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3611 - val_loss: 0.3831\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3608 - val_loss: 0.3786\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3596 - val_loss: 0.3803\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3593 - val_loss: 0.3811\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3577 - val_loss: 0.3801\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3564 - val_loss: 0.3799\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3560 - val_loss: 0.3748\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3554 - val_loss: 0.3770\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3542 - val_loss: 0.3754\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3525 - val_loss: 0.3751\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3509 - val_loss: 0.3712\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3517 - val_loss: 0.3743\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3503 - val_loss: 0.3726\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3489 - val_loss: 0.3745\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3482 - val_loss: 0.3700\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3480 - val_loss: 0.3686\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3469 - val_loss: 0.3703\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3455 - val_loss: 0.3682\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3454 - val_loss: 0.3656\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3438 - val_loss: 0.3657\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3436 - val_loss: 0.3641\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3424 - val_loss: 0.3661\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3419 - val_loss: 0.3627\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3397 - val_loss: 0.3633\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3384 - val_loss: 0.3638\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3379 - val_loss: 0.3627\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3366 - val_loss: 0.3583\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3364 - val_loss: 0.3606\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3358 - val_loss: 0.3579\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3349 - val_loss: 0.3627\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3342 - val_loss: 0.3594\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3327 - val_loss: 0.3647\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3330 - val_loss: 0.3594\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3315 - val_loss: 0.3584\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3302 - val_loss: 0.3644\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3289 - val_loss: 0.3599\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3298 - val_loss: 0.3592\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3288 - val_loss: 0.3609\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3282 - val_loss: 0.3579\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3703\n",
      "[CV]  learning_rate=0.005053370463007658, n_hidden=1, n_neurons=41, total=  23.0s\n",
      "[CV] learning_rate=0.019725264547024998, n_hidden=3, n_neurons=81 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.7886 - val_loss: 1.2048\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 3.2734 - val_loss: 0.6121\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5972 - val_loss: 0.8076\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: nan - val_loss: nan\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: nan - val_loss: nan\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: nan\n",
      "[CV]  learning_rate=0.019725264547024998, n_hidden=3, n_neurons=81, total=   5.1s\n",
      "[CV] learning_rate=0.019725264547024998, n_hidden=3, n_neurons=81 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6938 - val_loss: 0.5132\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4512 - val_loss: 0.4346\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4229 - val_loss: 0.3922\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3938 - val_loss: 0.3789\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3772 - val_loss: 0.3711\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3689 - val_loss: 0.3628\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3622 - val_loss: 0.3482\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3431 - val_loss: 0.3420\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3407 - val_loss: 0.3556\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3378 - val_loss: 0.3315\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3321 - val_loss: 0.3444\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3254 - val_loss: 0.4029\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3155 - val_loss: 0.3650\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3149 - val_loss: 0.3225\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3108 - val_loss: 0.3271\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3070 - val_loss: 0.3191\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3044 - val_loss: 0.3219\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3040 - val_loss: 0.3112\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2958 - val_loss: 0.3046\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2934 - val_loss: 0.3168\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2946 - val_loss: 0.3162\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2943 - val_loss: 0.3031\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2860 - val_loss: 0.3050\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2861 - val_loss: 0.3072\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2843 - val_loss: 0.3102\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2806 - val_loss: 0.3030\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2810 - val_loss: 0.2947\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2770 - val_loss: 0.3034\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2786 - val_loss: 0.2963\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2762 - val_loss: 0.2930\n",
      "Epoch 31/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2746 - val_loss: 0.3039\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2730 - val_loss: 0.3095\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2694 - val_loss: 0.2995\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2708 - val_loss: 0.3346\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2717 - val_loss: 0.3077\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2686 - val_loss: 0.2987\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2676 - val_loss: 0.2946\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2655 - val_loss: 0.3273\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2654 - val_loss: 0.3128\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2671 - val_loss: 0.2981\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.5282\n",
      "[CV]  learning_rate=0.019725264547024998, n_hidden=3, n_neurons=81, total=  16.6s\n",
      "[CV] learning_rate=0.019725264547024998, n_hidden=3, n_neurons=81 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6560 - val_loss: 0.4974\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.3061 - val_loss: 0.6804\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5763 - val_loss: 1.1302\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: nan - val_loss: nan\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: nan\n",
      "[CV]  learning_rate=0.019725264547024998, n_hidden=3, n_neurons=81, total=   5.0s\n",
      "[CV] learning_rate=0.008028615716552038, n_hidden=0, n_neurons=65 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.5107 - val_loss: 0.5686\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1.4090 - val_loss: 0.8309\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 20.6021 - val_loss: 2.9996\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 395.0309 - val_loss: 60.0141\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 8237.8608 - val_loss: 1222.1750\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 161035.4752 - val_loss: 23588.1543\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 3382959.2136 - val_loss: 458597.8927\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 66872827.1031 - val_loss: 9206706.1932\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1204021564.6465 - val_loss: 187560853.7902\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 25437410084.0517 - val_loss: 3768831813.6227\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 541091471414.5074 - val_loss: 73528825908.9199\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 42519840887.5990\n",
      "[CV]  learning_rate=0.008028615716552038, n_hidden=0, n_neurons=65, total=   4.0s\n",
      "[CV] learning_rate=0.008028615716552038, n_hidden=0, n_neurons=65 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.3799 - val_loss: 0.5548\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5415 - val_loss: 0.5343\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5381 - val_loss: 0.5244\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5400 - val_loss: 0.5184\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5130 - val_loss: 0.5112\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5337 - val_loss: 0.5093\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5476 - val_loss: 0.5086\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5173 - val_loss: 0.5514\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5277 - val_loss: 0.5063\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5380 - val_loss: 0.5059\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5238 - val_loss: 0.5057\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5086 - val_loss: 0.5060\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5326 - val_loss: 0.5053\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5202 - val_loss: 0.5043\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5268 - val_loss: 0.5040\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5133 - val_loss: 0.5029\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5385 - val_loss: 0.5039\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5304 - val_loss: 0.5040\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5142 - val_loss: 0.6300\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5198 - val_loss: 0.5029\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5061 - val_loss: 0.5169\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5015 - val_loss: 0.5020\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5208 - val_loss: 0.5017\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5096 - val_loss: 0.5019\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5134 - val_loss: 0.5783\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5174 - val_loss: 0.5167\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5305 - val_loss: 0.5572\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5134 - val_loss: 0.5022\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5118 - val_loss: 0.5657\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5096 - val_loss: 0.5011\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5177 - val_loss: 0.5015\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5255 - val_loss: 0.5027\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5101 - val_loss: 0.5458\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5331 - val_loss: 0.5028\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5318 - val_loss: 0.5238\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5277 - val_loss: 0.5035\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5316 - val_loss: 0.5048\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5079 - val_loss: 0.5043\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5348 - val_loss: 0.5055\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5311 - val_loss: 0.5064\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 3.5771\n",
      "[CV]  learning_rate=0.008028615716552038, n_hidden=0, n_neurons=65, total=  13.8s\n",
      "[CV] learning_rate=0.008028615716552038, n_hidden=0, n_neurons=65 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.2826 - val_loss: 0.5996\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7921 - val_loss: 0.6543\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 4.5908 - val_loss: 1.1080\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 85.0745 - val_loss: 20.6400\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1778.7459 - val_loss: 464.6008\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 43042.3831 - val_loss: 7178.0280\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 859383.4299 - val_loss: 168156.9593\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 19053734.9054 - val_loss: 3418774.1787\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 389200648.1920 - val_loss: 76839173.8367\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 8823088109.1183 - val_loss: 1542926824.6987\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 200515934567.3261 - val_loss: 32577062056.8145\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 65920212880.3390\n",
      "[CV]  learning_rate=0.008028615716552038, n_hidden=0, n_neurons=65, total=   3.9s\n",
      "[CV] learning_rate=0.0012666688421923112, n_hidden=0, n_neurons=8 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 4.2151 - val_loss: 2.2777\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1.6243 - val_loss: 1.1344\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.9547 - val_loss: 0.8015\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7454 - val_loss: 0.6933\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6706 - val_loss: 0.6518\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6388 - val_loss: 0.6307\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6209 - val_loss: 0.6173\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6097 - val_loss: 0.6074\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6001 - val_loss: 0.5986\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5922 - val_loss: 0.5909\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5856 - val_loss: 0.5844\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5793 - val_loss: 0.5780\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5741 - val_loss: 0.5726\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5692 - val_loss: 0.5675\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5648 - val_loss: 0.5628\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5611 - val_loss: 0.5585\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5576 - val_loss: 0.5548\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5546 - val_loss: 0.5517\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5518 - val_loss: 0.5487\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5494 - val_loss: 0.5457\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5471 - val_loss: 0.5435\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5452 - val_loss: 0.5409\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5436 - val_loss: 0.5388\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5421 - val_loss: 0.5375\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5405 - val_loss: 0.5358\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5393 - val_loss: 0.5336\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5382 - val_loss: 0.5319\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5375 - val_loss: 0.5319\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5363 - val_loss: 0.5297\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5357 - val_loss: 0.5286\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5348 - val_loss: 0.5274\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5347 - val_loss: 0.5269\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5338 - val_loss: 0.5260\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5332 - val_loss: 0.5249\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5332 - val_loss: 0.5249\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5325 - val_loss: 0.5240\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5323 - val_loss: 0.5244\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5313 - val_loss: 0.5227\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5316 - val_loss: 0.5222\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5318 - val_loss: 0.5223\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5311 - val_loss: 0.5221\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5303 - val_loss: 0.5207\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5309 - val_loss: 0.5216\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5306 - val_loss: 0.5207\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5307 - val_loss: 0.5208\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5298 - val_loss: 0.5198\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5304 - val_loss: 0.5215\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5301 - val_loss: 0.5205\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5297 - val_loss: 0.5193\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5299 - val_loss: 0.5189\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5299 - val_loss: 0.5203\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5291 - val_loss: 0.5185\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5300 - val_loss: 0.5208\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5297 - val_loss: 0.5192\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5299 - val_loss: 0.5197\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5295 - val_loss: 0.5187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5297 - val_loss: 0.5204\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5298 - val_loss: 0.5199\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5298 - val_loss: 0.5200\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5296 - val_loss: 0.5190\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5291 - val_loss: 0.5179\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5299 - val_loss: 0.5182\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5288 - val_loss: 0.5174\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5293 - val_loss: 0.5174\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5299 - val_loss: 0.5184\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5296 - val_loss: 0.5183\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5285 - val_loss: 0.5168\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5301 - val_loss: 0.5186\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5293 - val_loss: 0.5179\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5294 - val_loss: 0.5190\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5294 - val_loss: 0.5194\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5295 - val_loss: 0.5183\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5293 - val_loss: 0.5174\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5285 - val_loss: 0.5164\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5296 - val_loss: 0.5195\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5283 - val_loss: 0.5169\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5297 - val_loss: 0.5182\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5300 - val_loss: 0.5201\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5296 - val_loss: 0.5184\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5295 - val_loss: 0.5180\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5292 - val_loss: 0.5171\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5294 - val_loss: 0.5176\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5294 - val_loss: 0.5174\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5295 - val_loss: 0.5190\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.5045\n",
      "[CV]  learning_rate=0.0012666688421923112, n_hidden=0, n_neurons=8, total=  28.7s\n",
      "[CV] learning_rate=0.0012666688421923112, n_hidden=0, n_neurons=8 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 3.8264 - val_loss: 2.1259\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1.5264 - val_loss: 1.0569\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.8889 - val_loss: 0.7515\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7011 - val_loss: 0.6590\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6414 - val_loss: 0.6271\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6187 - val_loss: 0.6131\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6078 - val_loss: 0.6044\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6003 - val_loss: 0.5976\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5941 - val_loss: 0.5915\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5888 - val_loss: 0.5863\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5839 - val_loss: 0.5816\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5794 - val_loss: 0.5764\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5755 - val_loss: 0.5723\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5715 - val_loss: 0.5682\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5686 - val_loss: 0.5648\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5650 - val_loss: 0.5611\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5620 - val_loss: 0.5580\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5598 - val_loss: 0.5558\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5571 - val_loss: 0.5530\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5541 - val_loss: 0.5497\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5526 - val_loss: 0.5485\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5506 - val_loss: 0.5456\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5488 - val_loss: 0.5444\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5455 - val_loss: 0.5411\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5456 - val_loss: 0.5399\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5438 - val_loss: 0.5383\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5422 - val_loss: 0.5366\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5406 - val_loss: 0.5348\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5399 - val_loss: 0.5336\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5386 - val_loss: 0.5326\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5367 - val_loss: 0.5309\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5357 - val_loss: 0.5298\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5345 - val_loss: 0.5311\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5343 - val_loss: 0.5296\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5318 - val_loss: 0.5271\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5324 - val_loss: 0.5263\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5313 - val_loss: 0.5288\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5289 - val_loss: 0.5245\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5304 - val_loss: 0.5249\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5291 - val_loss: 0.5247\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5282 - val_loss: 0.5252\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5279 - val_loss: 0.5233\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5269 - val_loss: 0.5228\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5252 - val_loss: 0.5223\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5256 - val_loss: 0.5225\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5254 - val_loss: 0.5205\n",
      "Epoch 47/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5239 - val_loss: 0.5191\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5240 - val_loss: 0.5189\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5239 - val_loss: 0.5187\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5229 - val_loss: 0.5179\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5228 - val_loss: 0.5179\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5220 - val_loss: 0.5195\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5216 - val_loss: 0.5195\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5212 - val_loss: 0.5177\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5207 - val_loss: 0.5165\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5200 - val_loss: 0.5156\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5200 - val_loss: 0.5152\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5197 - val_loss: 0.5150\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5192 - val_loss: 0.5148\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5191 - val_loss: 0.5155\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5184 - val_loss: 0.5152\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5183 - val_loss: 0.5156\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5165 - val_loss: 0.5132\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5179 - val_loss: 0.5135\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5160 - val_loss: 0.5122\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5174 - val_loss: 0.5137\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5158 - val_loss: 0.5122\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5163 - val_loss: 0.5127\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5160 - val_loss: 0.5124\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5160 - val_loss: 0.5131\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5139 - val_loss: 0.5110\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5154 - val_loss: 0.5115\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5153 - val_loss: 0.5121\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5140 - val_loss: 0.5130\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5144 - val_loss: 0.5127\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5143 - val_loss: 0.5123\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5126 - val_loss: 0.5101\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5135 - val_loss: 0.5100\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5138 - val_loss: 0.5115\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5133 - val_loss: 0.5116\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5127 - val_loss: 0.5104\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5124 - val_loss: 0.5119\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5127 - val_loss: 0.5107\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5124 - val_loss: 0.5109\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5117 - val_loss: 0.5096\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5119 - val_loss: 0.5107\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5115 - val_loss: 0.5106\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5117 - val_loss: 0.5112\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5113 - val_loss: 0.5103\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5097 - val_loss: 0.5083\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5109 - val_loss: 0.5080\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5112 - val_loss: 0.5097\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5109 - val_loss: 0.5095\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5103 - val_loss: 0.5087\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5104 - val_loss: 0.5088\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5099 - val_loss: 0.5098\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5100 - val_loss: 0.5099\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5095 - val_loss: 0.5083\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5098 - val_loss: 0.5093\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5096 - val_loss: 0.5102\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5087 - val_loss: 0.5075\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5088 - val_loss: 0.5069\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5096 - val_loss: 0.5081\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5077 - val_loss: 0.5065\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5094 - val_loss: 0.5068\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5087 - val_loss: 0.5085\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5087 - val_loss: 0.5087\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5086 - val_loss: 0.5086\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5085 - val_loss: 0.5086\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5083 - val_loss: 0.5074\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5082 - val_loss: 0.5088\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5075 - val_loss: 0.5065\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5077 - val_loss: 0.5062\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5083 - val_loss: 0.5070\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5077 - val_loss: 0.5064\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5072 - val_loss: 0.5057\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5081 - val_loss: 0.5059\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5070 - val_loss: 0.5055\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5079 - val_loss: 0.5058\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5074 - val_loss: 0.5061\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5074 - val_loss: 0.5075\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5072 - val_loss: 0.5083\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5074 - val_loss: 0.5068\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5055 - val_loss: 0.5058\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5065 - val_loss: 0.5052\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5073 - val_loss: 0.5055\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5062 - val_loss: 0.5052\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5060 - val_loss: 0.5082\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5053 - val_loss: 0.5054\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5065 - val_loss: 0.5062\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5059 - val_loss: 0.5052\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5067 - val_loss: 0.5057\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5065 - val_loss: 0.5064\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5052 - val_loss: 0.5049\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5053 - val_loss: 0.5044\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5064 - val_loss: 0.5073\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5061 - val_loss: 0.5068\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5047 - val_loss: 0.5046\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5058 - val_loss: 0.5045\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5057 - val_loss: 0.5043\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5062 - val_loss: 0.5045\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5063 - val_loss: 0.5050\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5058 - val_loss: 0.5055\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5055 - val_loss: 0.5053\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5048 - val_loss: 0.5044\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5060 - val_loss: 0.5060\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5056 - val_loss: 0.5061\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5049 - val_loss: 0.5045\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5054 - val_loss: 0.5053\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5048 - val_loss: 0.5069\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 1.8489\n",
      "[CV]  learning_rate=0.0012666688421923112, n_hidden=0, n_neurons=8, total=  49.1s\n",
      "[CV] learning_rate=0.0012666688421923112, n_hidden=0, n_neurons=8 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 4.3709 - val_loss: 2.1189\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 1.4844 - val_loss: 0.9917\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.8027 - val_loss: 0.6653\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6033 - val_loss: 0.5699\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5435 - val_loss: 0.5408\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5250 - val_loss: 0.5312\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5187 - val_loss: 0.5281\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5163 - val_loss: 0.5265\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5151 - val_loss: 0.5255\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5142 - val_loss: 0.5246\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5137 - val_loss: 0.5240\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5132 - val_loss: 0.5235\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5127 - val_loss: 0.5231\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5122 - val_loss: 0.5224\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5118 - val_loss: 0.5219\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5114 - val_loss: 0.5214\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5110 - val_loss: 0.5210\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5106 - val_loss: 0.5206\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5102 - val_loss: 0.5202\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5100 - val_loss: 0.5200\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5097 - val_loss: 0.5196\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5093 - val_loss: 0.5194\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5091 - val_loss: 0.5190\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5088 - val_loss: 0.5187\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5086 - val_loss: 0.5186\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5083 - val_loss: 0.5185\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5081 - val_loss: 0.5183\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5079 - val_loss: 0.5180\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5076 - val_loss: 0.5178\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5076 - val_loss: 0.5176\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5074 - val_loss: 0.5175\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5072 - val_loss: 0.5174\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5069 - val_loss: 0.5172\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5069 - val_loss: 0.5171\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5068 - val_loss: 0.5171\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5066 - val_loss: 0.5170\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5065 - val_loss: 0.5166\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5064 - val_loss: 0.5168\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5063 - val_loss: 0.5168\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5061 - val_loss: 0.5164\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5061 - val_loss: 0.5163\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5060 - val_loss: 0.5164\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5059 - val_loss: 0.5162\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5058 - val_loss: 0.5161\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5057 - val_loss: 0.5161\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5056 - val_loss: 0.5158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5056 - val_loss: 0.5159\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5055 - val_loss: 0.5159\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5055 - val_loss: 0.5158\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5053 - val_loss: 0.5158\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5053 - val_loss: 0.5155\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5052 - val_loss: 0.5156\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5053 - val_loss: 0.5157\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5052 - val_loss: 0.5155\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5051 - val_loss: 0.5154\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5051 - val_loss: 0.5156\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5050 - val_loss: 0.5154\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5049 - val_loss: 0.5152\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5050 - val_loss: 0.5154\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5050 - val_loss: 0.5153\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5049 - val_loss: 0.5151\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5048 - val_loss: 0.5153\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5048 - val_loss: 0.5153\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5048 - val_loss: 0.5152\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5047 - val_loss: 0.5149\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5048 - val_loss: 0.5151\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5047 - val_loss: 0.5150\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5048 - val_loss: 0.5150\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5047 - val_loss: 0.5149\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5046 - val_loss: 0.5151\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5047 - val_loss: 0.5150\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5046 - val_loss: 0.5149\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5046 - val_loss: 0.5147\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5047 - val_loss: 0.5149\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5045 - val_loss: 0.5149\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5046 - val_loss: 0.5149\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5045 - val_loss: 0.5148\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5046 - val_loss: 0.5149\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5045 - val_loss: 0.5147\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5045 - val_loss: 0.5149\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5044 - val_loss: 0.5147\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5044 - val_loss: 0.5148\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5045 - val_loss: 0.5149\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5043 - val_loss: 0.5148\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5045 - val_loss: 0.5151\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5044 - val_loss: 0.5148\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5044 - val_loss: 0.5150\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5044 - val_loss: 0.5149\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5045 - val_loss: 0.5149\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5043 - val_loss: 0.5148\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5045 - val_loss: 0.5149\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.5801\n",
      "[CV]  learning_rate=0.0012666688421923112, n_hidden=0, n_neurons=8, total=  30.2s\n",
      "[CV] learning_rate=0.011361095649993104, n_hidden=1, n_neurons=7 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 2.5904 - val_loss: 1.0565\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: nan - val_loss: nan\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: nan\n",
      "[CV]  learning_rate=0.011361095649993104, n_hidden=1, n_neurons=7, total=   4.1s\n",
      "[CV] learning_rate=0.011361095649993104, n_hidden=1, n_neurons=7 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.1173 - val_loss: 0.5639\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5359 - val_loss: 0.5139\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5030 - val_loss: 0.4938\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4860 - val_loss: 0.4805\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4730 - val_loss: 0.4830\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4654 - val_loss: 0.4655\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4600 - val_loss: 0.4811\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4629 - val_loss: 0.4600\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4461 - val_loss: 0.4505\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4383 - val_loss: 0.4441\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4473 - val_loss: 0.4450\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4337 - val_loss: 0.4355\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4274 - val_loss: 0.4340\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4258 - val_loss: 0.4367\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4239 - val_loss: 0.4287\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4209 - val_loss: 0.4272\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4176 - val_loss: 0.4286\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4161 - val_loss: 0.4270\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4142 - val_loss: 0.4231\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4212 - val_loss: 0.4281\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4157 - val_loss: 0.4237\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4103 - val_loss: 0.4214\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4056 - val_loss: 0.4165\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4104 - val_loss: 0.4187\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4077 - val_loss: 0.4185\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4028 - val_loss: 0.4126\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4016 - val_loss: 0.4120\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4069 - val_loss: 0.4240\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4077 - val_loss: 0.4152\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4001 - val_loss: 0.4132\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3975 - val_loss: 0.4104\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3955 - val_loss: 0.4027\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3972 - val_loss: 0.4032\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3924 - val_loss: 0.4072\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3938 - val_loss: 0.4025\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3916 - val_loss: 0.4017\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3965 - val_loss: 0.4159\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3981 - val_loss: 0.4059\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3910 - val_loss: 0.4005\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3869 - val_loss: 0.3952\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4083 - val_loss: 0.4149\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3954 - val_loss: 0.4082\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3885 - val_loss: 0.4000\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3853 - val_loss: 0.3991\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3809 - val_loss: 0.3945\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3813 - val_loss: 0.3933\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3795 - val_loss: 0.3911\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3831 - val_loss: 0.3971\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3784 - val_loss: 0.3980\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3782 - val_loss: 0.3880\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3777 - val_loss: 0.3889\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3775 - val_loss: 0.3911\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3746 - val_loss: 0.3889\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3804 - val_loss: 0.3970\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3791 - val_loss: 0.3957\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3749 - val_loss: 0.3887\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3714 - val_loss: 0.3845\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3714 - val_loss: 0.3910\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4601 - val_loss: 0.4361\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4087 - val_loss: 0.4144\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4207 - val_loss: 0.4039\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3884 - val_loss: 0.4082\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3888 - val_loss: 0.4067\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3920 - val_loss: 0.3958\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3776 - val_loss: 0.3963\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3748 - val_loss: 0.3881\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3717 - val_loss: 0.3865\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.4140\n",
      "[CV]  learning_rate=0.011361095649993104, n_hidden=1, n_neurons=7, total=  23.5s\n",
      "[CV] learning_rate=0.011361095649993104, n_hidden=1, n_neurons=7 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.1505 - val_loss: 0.6563\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7821 - val_loss: 0.5562\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5156 - val_loss: 0.5083\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4845 - val_loss: 0.4880\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4683 - val_loss: 0.4719\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4581 - val_loss: 0.4617\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4507 - val_loss: 0.4617\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4438 - val_loss: 0.4551\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4386 - val_loss: 0.4517\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4339 - val_loss: 0.4434\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4283 - val_loss: 0.4361\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4250 - val_loss: 0.4353\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4205 - val_loss: 0.4384\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4167 - val_loss: 0.4312\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4139 - val_loss: 0.4271\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4108 - val_loss: 0.4272\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4085 - val_loss: 0.4234\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4065 - val_loss: 0.4192\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4028 - val_loss: 0.4172\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4013 - val_loss: 0.4189\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3978 - val_loss: 0.4187\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3967 - val_loss: 0.4171\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3939 - val_loss: 0.4247\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3940 - val_loss: 0.4091\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3913 - val_loss: 0.4106\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3905 - val_loss: 0.4045\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3892 - val_loss: 0.4042\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3872 - val_loss: 0.4040\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3858 - val_loss: 0.4078\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3857 - val_loss: 0.4021\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3829 - val_loss: 0.4111\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3823 - val_loss: 0.3993\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3811 - val_loss: 0.3979\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3807 - val_loss: 0.4078\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3798 - val_loss: 0.4027\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3787 - val_loss: 0.4010\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3774 - val_loss: 0.4006\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3746 - val_loss: 0.4086\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3746 - val_loss: 0.4046\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3740 - val_loss: 0.3989\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3728 - val_loss: 0.3927\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3703 - val_loss: 0.3910\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3707 - val_loss: 0.3911\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3695 - val_loss: 0.3879\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3670 - val_loss: 0.3870\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3667 - val_loss: 0.3892\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3663 - val_loss: 0.3865\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3655 - val_loss: 0.3849\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3649 - val_loss: 0.3877\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3635 - val_loss: 0.3855\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3637 - val_loss: 0.3823\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3630 - val_loss: 0.3829\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3620 - val_loss: 0.3781\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3603 - val_loss: 0.3802\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3626 - val_loss: 0.3854\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3594 - val_loss: 0.3795\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3572 - val_loss: 0.3783\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3582 - val_loss: 0.3787\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3560 - val_loss: 0.3886\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3574 - val_loss: 0.3814\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3571 - val_loss: 0.3751\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3561 - val_loss: 0.3758\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3561 - val_loss: 0.3768\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3551 - val_loss: 0.3706\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3535 - val_loss: 0.3732\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3552 - val_loss: 0.3789\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3540 - val_loss: 0.3722\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3535 - val_loss: 0.3729\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3528 - val_loss: 0.3796\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3519 - val_loss: 0.3734\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3521 - val_loss: 0.3709\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3505 - val_loss: 0.3721\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3512 - val_loss: 0.3863\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3516 - val_loss: 0.3669\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3510 - val_loss: 0.3711\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3532 - val_loss: 0.3685\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3493 - val_loss: 0.3650\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3510 - val_loss: 0.3707\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3493 - val_loss: 0.3651\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3503 - val_loss: 0.3701\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3475 - val_loss: 0.3831\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3491 - val_loss: 0.3726\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3480 - val_loss: 0.3714\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3481 - val_loss: 0.3666\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3493 - val_loss: 0.3670\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3470 - val_loss: 0.3787\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3462 - val_loss: 0.3655\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.3774\n",
      "[CV]  learning_rate=0.011361095649993104, n_hidden=1, n_neurons=7, total=  29.7s\n",
      "[CV] learning_rate=0.0010811218976198044, n_hidden=1, n_neurons=28 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 2.4345 - val_loss: 1.0338\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.9362 - val_loss: 0.7999\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.8298 - val_loss: 0.7479\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7932 - val_loss: 0.7247\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7522 - val_loss: 0.6944\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7251 - val_loss: 0.6762\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6933 - val_loss: 0.6539\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6757 - val_loss: 0.6427\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6548 - val_loss: 0.6262\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6380 - val_loss: 0.6141\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6197 - val_loss: 0.6030\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6072 - val_loss: 0.5915\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5958 - val_loss: 0.5790\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5867 - val_loss: 0.5756\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5747 - val_loss: 0.5613\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5688 - val_loss: 0.5559\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5591 - val_loss: 0.5471\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5573 - val_loss: 0.5457\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5463 - val_loss: 0.5357\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5412 - val_loss: 0.5326\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5367 - val_loss: 0.5268\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5366 - val_loss: 0.5257\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5371 - val_loss: 0.5183\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5395 - val_loss: 0.5186\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5293 - val_loss: 0.5103\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5343 - val_loss: 0.5107\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5260 - val_loss: 0.5046\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5284 - val_loss: 0.5079\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5165 - val_loss: 0.5014\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5171 - val_loss: 0.5006\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5138 - val_loss: 0.4982\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5199 - val_loss: 0.4960\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5133 - val_loss: 0.4918\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5188 - val_loss: 0.4922\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5113 - val_loss: 0.4864\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5241 - val_loss: 0.4893\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5082 - val_loss: 0.4863\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5132 - val_loss: 0.4880\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5083 - val_loss: 0.4802\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5133 - val_loss: 0.4835\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4993 - val_loss: 0.4798\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4897 - val_loss: 0.4782\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4800 - val_loss: 0.4772\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4790 - val_loss: 0.4753\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4743 - val_loss: 0.4726\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4729 - val_loss: 0.4730\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4698 - val_loss: 0.4702\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4695 - val_loss: 0.4697\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4673 - val_loss: 0.4702\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4667 - val_loss: 0.4671\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4643 - val_loss: 0.4660\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4640 - val_loss: 0.4660\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4619 - val_loss: 0.4641\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4611 - val_loss: 0.4643\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4594 - val_loss: 0.4616\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4585 - val_loss: 0.4614\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4568 - val_loss: 0.4592\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4563 - val_loss: 0.4585\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4551 - val_loss: 0.4572\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4546 - val_loss: 0.4565\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4531 - val_loss: 0.4557\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4519 - val_loss: 0.4547\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4510 - val_loss: 0.4542\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4500 - val_loss: 0.4525\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4495 - val_loss: 0.4519\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4482 - val_loss: 0.4515\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4475 - val_loss: 0.4506\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4463 - val_loss: 0.4495\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4459 - val_loss: 0.4487\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4449 - val_loss: 0.4475\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4444 - val_loss: 0.4475\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4432 - val_loss: 0.4462\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4432 - val_loss: 0.4459\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4419 - val_loss: 0.4446\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4417 - val_loss: 0.4451\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4399 - val_loss: 0.4435\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4400 - val_loss: 0.4433\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4386 - val_loss: 0.4420\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4400 - val_loss: 0.4417\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4383 - val_loss: 0.4403\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4399 - val_loss: 0.4413\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4390 - val_loss: 0.4393\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4403 - val_loss: 0.4397\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4369 - val_loss: 0.4379\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4366 - val_loss: 0.4382\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4348 - val_loss: 0.4370\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4354 - val_loss: 0.4372\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4335 - val_loss: 0.4361\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4342 - val_loss: 0.4365\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4318 - val_loss: 0.4351\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4312 - val_loss: 0.4364\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4308 - val_loss: 0.4340\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4318 - val_loss: 0.4342\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4306 - val_loss: 0.4330\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4323 - val_loss: 0.4344\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4304 - val_loss: 0.4321\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4329 - val_loss: 0.4325\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4308 - val_loss: 0.4309\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4328 - val_loss: 0.4312\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4308 - val_loss: 0.4305\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4340 - val_loss: 0.4311\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4321 - val_loss: 0.4289\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4262 - val_loss: 0.4299\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4233 - val_loss: 0.4281\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4218 - val_loss: 0.4280\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4210 - val_loss: 0.4280\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4204 - val_loss: 0.4269\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4200 - val_loss: 0.4271\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4194 - val_loss: 0.4259\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4191 - val_loss: 0.4261\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4185 - val_loss: 0.4258\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4179 - val_loss: 0.4254\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4178 - val_loss: 0.4248\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4170 - val_loss: 0.4243\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4165 - val_loss: 0.4240\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4163 - val_loss: 0.4240\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4156 - val_loss: 0.4231\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4154 - val_loss: 0.4233\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4149 - val_loss: 0.4228\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4143 - val_loss: 0.4220\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4140 - val_loss: 0.4219\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4135 - val_loss: 0.4216\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4129 - val_loss: 0.4218\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4129 - val_loss: 0.4207\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4122 - val_loss: 0.4206\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4120 - val_loss: 0.4205\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4115 - val_loss: 0.4204\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4112 - val_loss: 0.4197\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4108 - val_loss: 0.4194\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4104 - val_loss: 0.4190\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4100 - val_loss: 0.4183\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4094 - val_loss: 0.4179\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4090 - val_loss: 0.4180\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4088 - val_loss: 0.4176\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4084 - val_loss: 0.4169\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4079 - val_loss: 0.4169\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4075 - val_loss: 0.4165\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4072 - val_loss: 0.4167\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4069 - val_loss: 0.4160\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4063 - val_loss: 0.4157\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4061 - val_loss: 0.4156\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4056 - val_loss: 0.4154\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4052 - val_loss: 0.4147\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4049 - val_loss: 0.4142\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4046 - val_loss: 0.4140\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4042 - val_loss: 0.4142\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4038 - val_loss: 0.4141\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4035 - val_loss: 0.4130\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4031 - val_loss: 0.4128\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4029 - val_loss: 0.4126\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4024 - val_loss: 0.4126\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4020 - val_loss: 0.4118\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4018 - val_loss: 0.4118\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4012 - val_loss: 0.4113\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4014 - val_loss: 0.4116\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4006 - val_loss: 0.4108\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4000 - val_loss: 0.4110\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4001 - val_loss: 0.4105\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3995 - val_loss: 0.4098\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3992 - val_loss: 0.4098\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3990 - val_loss: 0.4097\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3986 - val_loss: 0.4096\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3978 - val_loss: 0.4097\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3983 - val_loss: 0.4092\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3975 - val_loss: 0.4083\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3972 - val_loss: 0.4082\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3973 - val_loss: 0.4077\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3964 - val_loss: 0.4072\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3964 - val_loss: 0.4072\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3960 - val_loss: 0.4069\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3956 - val_loss: 0.4063\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3954 - val_loss: 0.4064\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3950 - val_loss: 0.4061\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3947 - val_loss: 0.4061\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3943 - val_loss: 0.4064\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3942 - val_loss: 0.4062\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3939 - val_loss: 0.4055\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3936 - val_loss: 0.4054\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3933 - val_loss: 0.4047\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3929 - val_loss: 0.4043\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3926 - val_loss: 0.4042\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3921 - val_loss: 0.4038\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3920 - val_loss: 0.4041\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3919 - val_loss: 0.4028\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3913 - val_loss: 0.4030\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3913 - val_loss: 0.4028\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3907 - val_loss: 0.4031\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3905 - val_loss: 0.4024\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3907 - val_loss: 0.4018\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3901 - val_loss: 0.4017\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3898 - val_loss: 0.4017\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3897 - val_loss: 0.4016\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3894 - val_loss: 0.4011\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3890 - val_loss: 0.4015\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3886 - val_loss: 0.4005\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3884 - val_loss: 0.4002\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3883 - val_loss: 0.3999\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3880 - val_loss: 0.3998\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3878 - val_loss: 0.3997\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3874 - val_loss: 0.3991\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3872 - val_loss: 0.3992\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3869 - val_loss: 0.3986\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3864 - val_loss: 0.3994\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3870 - val_loss: 0.3983\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3864 - val_loss: 0.3982\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3857 - val_loss: 0.3983\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3853 - val_loss: 0.3979\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3854 - val_loss: 0.3979\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3850 - val_loss: 0.3981\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3852 - val_loss: 0.3970\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3847 - val_loss: 0.3969\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3844 - val_loss: 0.3970\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3840 - val_loss: 0.3967\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3839 - val_loss: 0.3960\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3836 - val_loss: 0.3960\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3834 - val_loss: 0.3959\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3830 - val_loss: 0.3957\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3828 - val_loss: 0.3961\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3827 - val_loss: 0.3949\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3824 - val_loss: 0.3951\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3821 - val_loss: 0.3948\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3820 - val_loss: 0.3947\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3817 - val_loss: 0.3946\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3815 - val_loss: 0.3954\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3815 - val_loss: 0.3939\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3808 - val_loss: 0.3937\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3809 - val_loss: 0.3933\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3802 - val_loss: 0.3937\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3805 - val_loss: 0.3939\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3801 - val_loss: 0.3928\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3796 - val_loss: 0.3928\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3799 - val_loss: 0.3921\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3797 - val_loss: 0.3926\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3796 - val_loss: 0.3924\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3789 - val_loss: 0.3923\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3788 - val_loss: 0.3918\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3786 - val_loss: 0.3914\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3784 - val_loss: 0.3917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3782 - val_loss: 0.3917\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3782 - val_loss: 0.3913\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3779 - val_loss: 0.3907\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3775 - val_loss: 0.3907\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3771 - val_loss: 0.3901\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3773 - val_loss: 0.3903\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3767 - val_loss: 0.3905\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3766 - val_loss: 0.3899\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3768 - val_loss: 0.3899\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3765 - val_loss: 0.3900\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3763 - val_loss: 0.3891\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3761 - val_loss: 0.3889\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3757 - val_loss: 0.3894\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3756 - val_loss: 0.3894\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3753 - val_loss: 0.3881\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3749 - val_loss: 0.3885\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3745 - val_loss: 0.3881\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3749 - val_loss: 0.3874\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3743 - val_loss: 0.3879\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3738 - val_loss: 0.3872\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3738 - val_loss: 0.3868\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3737 - val_loss: 0.3868\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3730 - val_loss: 0.3882\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3732 - val_loss: 0.3867\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3729 - val_loss: 0.3860\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3727 - val_loss: 0.3865\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3727 - val_loss: 0.3858\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3723 - val_loss: 0.3862\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3717 - val_loss: 0.3858\n",
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3724 - val_loss: 0.3853\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3715 - val_loss: 0.3855\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3714 - val_loss: 0.3854\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3712 - val_loss: 0.3855\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3710 - val_loss: 0.3851\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3708 - val_loss: 0.3847\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3705 - val_loss: 0.3854\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3702 - val_loss: 0.3847\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3699 - val_loss: 0.3855\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3697 - val_loss: 0.3842\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3700 - val_loss: 0.3841\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3695 - val_loss: 0.3838\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3696 - val_loss: 0.3843\n",
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3693 - val_loss: 0.3844\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3689 - val_loss: 0.3839\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3691 - val_loss: 0.3832\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3687 - val_loss: 0.3837\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3683 - val_loss: 0.3841\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3681 - val_loss: 0.3830\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3681 - val_loss: 0.3834\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3678 - val_loss: 0.3833\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3677 - val_loss: 0.3828\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3676 - val_loss: 0.3821\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3674 - val_loss: 0.3822\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3677 - val_loss: 0.3821\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3667 - val_loss: 0.3819\n",
      "Epoch 294/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3668 - val_loss: 0.3819\n",
      "Epoch 295/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3664 - val_loss: 0.3818\n",
      "Epoch 296/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3664 - val_loss: 0.3814\n",
      "Epoch 297/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3659 - val_loss: 0.3821\n",
      "Epoch 298/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3659 - val_loss: 0.3820\n",
      "Epoch 299/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3661 - val_loss: 0.3821\n",
      "Epoch 300/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3660 - val_loss: 0.3816\n",
      "Epoch 301/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3655 - val_loss: 0.3817\n",
      "Epoch 302/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3656 - val_loss: 0.3813\n",
      "Epoch 303/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3654 - val_loss: 0.3813\n",
      "Epoch 304/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3653 - val_loss: 0.3814\n",
      "Epoch 305/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3649 - val_loss: 0.3805\n",
      "Epoch 306/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3659 - val_loss: 0.3804\n",
      "Epoch 307/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3645 - val_loss: 0.3797\n",
      "Epoch 308/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3642 - val_loss: 0.3803\n",
      "Epoch 309/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3641 - val_loss: 0.3801\n",
      "Epoch 310/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3643 - val_loss: 0.3800\n",
      "Epoch 311/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3644 - val_loss: 0.3799\n",
      "Epoch 312/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3640 - val_loss: 0.3805\n",
      "Epoch 313/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3639 - val_loss: 0.3794\n",
      "Epoch 314/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3635 - val_loss: 0.3794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3633 - val_loss: 0.3805\n",
      "Epoch 316/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3633 - val_loss: 0.3786\n",
      "Epoch 317/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3627 - val_loss: 0.3790\n",
      "Epoch 318/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3628 - val_loss: 0.3788\n",
      "Epoch 319/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3627 - val_loss: 0.3786\n",
      "Epoch 320/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3627 - val_loss: 0.3787\n",
      "Epoch 321/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3626 - val_loss: 0.3797\n",
      "Epoch 322/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3626 - val_loss: 0.3794\n",
      "Epoch 323/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3623 - val_loss: 0.3786\n",
      "Epoch 324/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3618 - val_loss: 0.3780\n",
      "Epoch 325/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3617 - val_loss: 0.3789\n",
      "Epoch 326/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3616 - val_loss: 0.3778\n",
      "Epoch 327/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3618 - val_loss: 0.3775\n",
      "Epoch 328/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3613 - val_loss: 0.3774\n",
      "Epoch 329/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3613 - val_loss: 0.3772\n",
      "Epoch 330/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3617 - val_loss: 0.3776\n",
      "Epoch 331/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3610 - val_loss: 0.3777\n",
      "Epoch 332/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3606 - val_loss: 0.3768\n",
      "Epoch 333/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3607 - val_loss: 0.3776\n",
      "Epoch 334/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3605 - val_loss: 0.3774\n",
      "Epoch 335/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3600 - val_loss: 0.3770\n",
      "Epoch 336/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3603 - val_loss: 0.3766\n",
      "Epoch 337/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3597 - val_loss: 0.3769\n",
      "Epoch 338/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3600 - val_loss: 0.3764\n",
      "Epoch 339/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3597 - val_loss: 0.3772\n",
      "Epoch 340/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3597 - val_loss: 0.3766\n",
      "Epoch 341/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3600 - val_loss: 0.3765\n",
      "Epoch 342/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3592 - val_loss: 0.3761\n",
      "Epoch 343/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3592 - val_loss: 0.3760\n",
      "Epoch 344/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3586 - val_loss: 0.3768\n",
      "Epoch 345/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3589 - val_loss: 0.3757\n",
      "Epoch 346/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3586 - val_loss: 0.3754\n",
      "Epoch 347/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3587 - val_loss: 0.3760\n",
      "Epoch 348/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3591 - val_loss: 0.3758\n",
      "Epoch 349/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3584 - val_loss: 0.3750\n",
      "Epoch 350/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3583 - val_loss: 0.3750\n",
      "Epoch 351/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3577 - val_loss: 0.3748\n",
      "Epoch 352/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3577 - val_loss: 0.3756\n",
      "Epoch 353/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3575 - val_loss: 0.3748\n",
      "Epoch 354/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3583 - val_loss: 0.3747\n",
      "Epoch 355/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3573 - val_loss: 0.3743\n",
      "Epoch 356/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3573 - val_loss: 0.3739\n",
      "Epoch 357/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3573 - val_loss: 0.3749\n",
      "Epoch 358/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3568 - val_loss: 0.3749\n",
      "Epoch 359/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3568 - val_loss: 0.3735\n",
      "Epoch 360/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3565 - val_loss: 0.3740\n",
      "Epoch 361/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3563 - val_loss: 0.3742\n",
      "Epoch 362/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3567 - val_loss: 0.3734\n",
      "Epoch 363/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3562 - val_loss: 0.3735\n",
      "Epoch 364/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3562 - val_loss: 0.3741\n",
      "Epoch 365/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3559 - val_loss: 0.3735\n",
      "Epoch 366/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3562 - val_loss: 0.3739\n",
      "Epoch 367/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3559 - val_loss: 0.3739\n",
      "Epoch 368/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3553 - val_loss: 0.3737\n",
      "Epoch 369/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3556 - val_loss: 0.3729\n",
      "Epoch 370/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3556 - val_loss: 0.3733\n",
      "Epoch 371/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3553 - val_loss: 0.3731\n",
      "Epoch 372/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3555 - val_loss: 0.3725\n",
      "Epoch 373/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3549 - val_loss: 0.3722\n",
      "Epoch 374/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3550 - val_loss: 0.3722\n",
      "Epoch 375/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3546 - val_loss: 0.3722\n",
      "Epoch 376/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3547 - val_loss: 0.3721\n",
      "Epoch 377/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3546 - val_loss: 0.3721\n",
      "Epoch 378/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3547 - val_loss: 0.3734\n",
      "Epoch 379/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3544 - val_loss: 0.3728\n",
      "Epoch 380/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3543 - val_loss: 0.3722\n",
      "Epoch 381/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3538 - val_loss: 0.3707\n",
      "Epoch 382/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3537 - val_loss: 0.3721\n",
      "Epoch 383/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3535 - val_loss: 0.3715\n",
      "Epoch 384/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3539 - val_loss: 0.3719\n",
      "Epoch 385/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3544 - val_loss: 0.3715\n",
      "Epoch 386/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3533 - val_loss: 0.3709\n",
      "Epoch 387/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3534 - val_loss: 0.3708\n",
      "Epoch 388/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3536 - val_loss: 0.3713\n",
      "Epoch 389/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3530 - val_loss: 0.3700\n",
      "Epoch 390/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3537 - val_loss: 0.3710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3530 - val_loss: 0.3708\n",
      "Epoch 392/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3529 - val_loss: 0.3707\n",
      "Epoch 393/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3525 - val_loss: 0.3698\n",
      "Epoch 394/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3523 - val_loss: 0.3708\n",
      "Epoch 395/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3524 - val_loss: 0.3717\n",
      "Epoch 396/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3540 - val_loss: 0.3704\n",
      "Epoch 397/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3527 - val_loss: 0.3696\n",
      "Epoch 398/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3518 - val_loss: 0.3700\n",
      "Epoch 399/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3518 - val_loss: 0.3698\n",
      "Epoch 400/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3515 - val_loss: 0.3695\n",
      "Epoch 401/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3518 - val_loss: 0.3692\n",
      "Epoch 402/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3515 - val_loss: 0.3696\n",
      "Epoch 403/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3512 - val_loss: 0.3699\n",
      "Epoch 404/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3512 - val_loss: 0.3699\n",
      "Epoch 405/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3513 - val_loss: 0.3692\n",
      "Epoch 406/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3512 - val_loss: 0.3690\n",
      "Epoch 407/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3509 - val_loss: 0.3689\n",
      "Epoch 408/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3509 - val_loss: 0.3688\n",
      "Epoch 409/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3508 - val_loss: 0.3686\n",
      "Epoch 410/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3508 - val_loss: 0.3680\n",
      "Epoch 411/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3503 - val_loss: 0.3678\n",
      "Epoch 412/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3504 - val_loss: 0.3673\n",
      "Epoch 413/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3505 - val_loss: 0.3677\n",
      "Epoch 414/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3503 - val_loss: 0.3681\n",
      "Epoch 415/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3503 - val_loss: 0.3684\n",
      "Epoch 416/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3497 - val_loss: 0.3682\n",
      "Epoch 417/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3498 - val_loss: 0.3677\n",
      "Epoch 418/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3496 - val_loss: 0.3683\n",
      "Epoch 419/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3496 - val_loss: 0.3668\n",
      "Epoch 420/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3494 - val_loss: 0.3671\n",
      "Epoch 421/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3495 - val_loss: 0.3680\n",
      "Epoch 422/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3492 - val_loss: 0.3672\n",
      "Epoch 423/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3493 - val_loss: 0.3669\n",
      "Epoch 424/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3491 - val_loss: 0.3665\n",
      "Epoch 425/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3488 - val_loss: 0.3664\n",
      "Epoch 426/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3487 - val_loss: 0.3668\n",
      "Epoch 427/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3487 - val_loss: 0.3664\n",
      "Epoch 428/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3484 - val_loss: 0.3670\n",
      "Epoch 429/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3484 - val_loss: 0.3665\n",
      "Epoch 430/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3484 - val_loss: 0.3661\n",
      "Epoch 431/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3480 - val_loss: 0.3657\n",
      "Epoch 432/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3482 - val_loss: 0.3658\n",
      "Epoch 433/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3480 - val_loss: 0.3655\n",
      "Epoch 434/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3479 - val_loss: 0.3666\n",
      "Epoch 435/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3480 - val_loss: 0.3651\n",
      "Epoch 436/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3475 - val_loss: 0.3660\n",
      "Epoch 437/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3476 - val_loss: 0.3649\n",
      "Epoch 438/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3475 - val_loss: 0.3654\n",
      "Epoch 439/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3472 - val_loss: 0.3653\n",
      "Epoch 440/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3471 - val_loss: 0.3651\n",
      "Epoch 441/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3475 - val_loss: 0.3644\n",
      "Epoch 442/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3468 - val_loss: 0.3646\n",
      "Epoch 443/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3469 - val_loss: 0.3642\n",
      "Epoch 444/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3469 - val_loss: 0.3648\n",
      "Epoch 445/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3466 - val_loss: 0.3642\n",
      "Epoch 446/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3463 - val_loss: 0.3633\n",
      "Epoch 447/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3466 - val_loss: 0.3636\n",
      "Epoch 448/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3463 - val_loss: 0.3649\n",
      "Epoch 449/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3463 - val_loss: 0.3636\n",
      "Epoch 450/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3461 - val_loss: 0.3635\n",
      "Epoch 451/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3458 - val_loss: 0.3641\n",
      "Epoch 452/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3461 - val_loss: 0.3637\n",
      "Epoch 453/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3457 - val_loss: 0.3642\n",
      "Epoch 454/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3457 - val_loss: 0.3630\n",
      "Epoch 455/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3464 - val_loss: 0.3628\n",
      "Epoch 456/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3456 - val_loss: 0.3622\n",
      "Epoch 457/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3454 - val_loss: 0.3631\n",
      "Epoch 458/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3452 - val_loss: 0.3622\n",
      "Epoch 459/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3449 - val_loss: 0.3644\n",
      "Epoch 460/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3454 - val_loss: 0.3627\n",
      "Epoch 461/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3448 - val_loss: 0.3633\n",
      "Epoch 462/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3445 - val_loss: 0.3629\n",
      "Epoch 463/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3445 - val_loss: 0.3628\n",
      "Epoch 464/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3444 - val_loss: 0.3630\n",
      "Epoch 465/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3444 - val_loss: 0.3640\n",
      "Epoch 466/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3443 - val_loss: 0.3620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3441 - val_loss: 0.3624\n",
      "Epoch 468/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3448 - val_loss: 0.3618\n",
      "Epoch 469/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3440 - val_loss: 0.3624\n",
      "Epoch 470/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3441 - val_loss: 0.3625\n",
      "Epoch 471/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3438 - val_loss: 0.3618\n",
      "Epoch 472/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3445 - val_loss: 0.3613\n",
      "Epoch 473/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3434 - val_loss: 0.3613\n",
      "Epoch 474/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3434 - val_loss: 0.3616\n",
      "Epoch 475/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3433 - val_loss: 0.3609\n",
      "Epoch 476/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3438 - val_loss: 0.3603\n",
      "Epoch 477/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3434 - val_loss: 0.3603\n",
      "Epoch 478/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3430 - val_loss: 0.3602\n",
      "Epoch 479/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3432 - val_loss: 0.3616\n",
      "Epoch 480/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3431 - val_loss: 0.3605\n",
      "Epoch 481/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3428 - val_loss: 0.3600\n",
      "Epoch 482/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3427 - val_loss: 0.3599\n",
      "Epoch 483/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3424 - val_loss: 0.3617\n",
      "Epoch 484/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3434 - val_loss: 0.3615\n",
      "Epoch 485/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3425 - val_loss: 0.3593\n",
      "Epoch 486/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3424 - val_loss: 0.3605\n",
      "Epoch 487/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3423 - val_loss: 0.3598\n",
      "Epoch 488/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3423 - val_loss: 0.3599\n",
      "Epoch 489/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3420 - val_loss: 0.3593\n",
      "Epoch 490/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3419 - val_loss: 0.3604\n",
      "Epoch 491/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3437 - val_loss: 0.3593\n",
      "Epoch 492/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3420 - val_loss: 0.3586\n",
      "Epoch 493/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3417 - val_loss: 0.3596\n",
      "Epoch 494/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3419 - val_loss: 0.3590\n",
      "Epoch 495/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3416 - val_loss: 0.3595\n",
      "Epoch 496/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3415 - val_loss: 0.3588\n",
      "Epoch 497/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3413 - val_loss: 0.3589\n",
      "Epoch 498/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3414 - val_loss: 0.3592\n",
      "Epoch 499/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3411 - val_loss: 0.3587\n",
      "Epoch 500/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3411 - val_loss: 0.3583\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.3315\n",
      "[CV]  learning_rate=0.0010811218976198044, n_hidden=1, n_neurons=28, total= 2.9min\n",
      "[CV] learning_rate=0.0010811218976198044, n_hidden=1, n_neurons=28 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 2.5440 - val_loss: 1.0093\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.8170 - val_loss: 0.7132\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6752 - val_loss: 0.6533\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6298 - val_loss: 0.6236\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6035 - val_loss: 0.6025\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5835 - val_loss: 0.5843\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5666 - val_loss: 0.5682\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5523 - val_loss: 0.5556\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5396 - val_loss: 0.5431\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5283 - val_loss: 0.5326\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5183 - val_loss: 0.5231\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5098 - val_loss: 0.5152\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5017 - val_loss: 0.5079\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4948 - val_loss: 0.5011\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4885 - val_loss: 0.4953\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4833 - val_loss: 0.4902\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4783 - val_loss: 0.4852\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4737 - val_loss: 0.4806\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4702 - val_loss: 0.4772\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4662 - val_loss: 0.4744\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4634 - val_loss: 0.4715\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4597 - val_loss: 0.4684\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4575 - val_loss: 0.4662\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4546 - val_loss: 0.4639\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4524 - val_loss: 0.4619\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4501 - val_loss: 0.4593\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4487 - val_loss: 0.4579\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4462 - val_loss: 0.4563\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4447 - val_loss: 0.4539\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4436 - val_loss: 0.4526\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4415 - val_loss: 0.4511\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4403 - val_loss: 0.4491\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4389 - val_loss: 0.4483\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4372 - val_loss: 0.4459\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4365 - val_loss: 0.4452\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4350 - val_loss: 0.4442\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4339 - val_loss: 0.4434\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4329 - val_loss: 0.4418\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4322 - val_loss: 0.4409\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4315 - val_loss: 0.4404\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4304 - val_loss: 0.4392\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4296 - val_loss: 0.4388\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4285 - val_loss: 0.4377\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4284 - val_loss: 0.4373\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4271 - val_loss: 0.4364\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4264 - val_loss: 0.4358\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4256 - val_loss: 0.4347\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4247 - val_loss: 0.4342\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4244 - val_loss: 0.4339\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4235 - val_loss: 0.4332\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4229 - val_loss: 0.4317\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4223 - val_loss: 0.4312\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4217 - val_loss: 0.4308\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4208 - val_loss: 0.4309\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4205 - val_loss: 0.4297\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4198 - val_loss: 0.4296\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4193 - val_loss: 0.4283\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4187 - val_loss: 0.4284\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4182 - val_loss: 0.4277\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4176 - val_loss: 0.4276\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4170 - val_loss: 0.4266\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4168 - val_loss: 0.4269\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4161 - val_loss: 0.4257\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4157 - val_loss: 0.4255\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4149 - val_loss: 0.4252\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4146 - val_loss: 0.4245\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4142 - val_loss: 0.4239\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4139 - val_loss: 0.4237\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4131 - val_loss: 0.4230\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4129 - val_loss: 0.4224\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4122 - val_loss: 0.4228\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4118 - val_loss: 0.4219\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4117 - val_loss: 0.4213\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4110 - val_loss: 0.4204\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4106 - val_loss: 0.4203\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4102 - val_loss: 0.4197\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4093 - val_loss: 0.4212\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4094 - val_loss: 0.4193\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4087 - val_loss: 0.4181\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4086 - val_loss: 0.4184\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4080 - val_loss: 0.4180\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4079 - val_loss: 0.4175\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4073 - val_loss: 0.4170\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4071 - val_loss: 0.4169\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4065 - val_loss: 0.4174\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4061 - val_loss: 0.4158\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4054 - val_loss: 0.4177\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4055 - val_loss: 0.4154\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4049 - val_loss: 0.4153\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4047 - val_loss: 0.4151\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4043 - val_loss: 0.4144\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4038 - val_loss: 0.4138\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4036 - val_loss: 0.4135\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4032 - val_loss: 0.4130\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4027 - val_loss: 0.4133\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4026 - val_loss: 0.4129\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4020 - val_loss: 0.4123\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4018 - val_loss: 0.4115\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4014 - val_loss: 0.4113\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4010 - val_loss: 0.4110\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4008 - val_loss: 0.4106\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4003 - val_loss: 0.4109\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3998 - val_loss: 0.4118\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3996 - val_loss: 0.4106\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3993 - val_loss: 0.4093\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3989 - val_loss: 0.4099\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3987 - val_loss: 0.4089\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3983 - val_loss: 0.4087\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3978 - val_loss: 0.4089\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3977 - val_loss: 0.4085\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3971 - val_loss: 0.4071\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3971 - val_loss: 0.4069\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3965 - val_loss: 0.4071\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3961 - val_loss: 0.4084\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3960 - val_loss: 0.4075\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3956 - val_loss: 0.4063\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3954 - val_loss: 0.4059\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3949 - val_loss: 0.4059\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3948 - val_loss: 0.4052\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3944 - val_loss: 0.4047\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3942 - val_loss: 0.4043\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3937 - val_loss: 0.4050\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3932 - val_loss: 0.4041\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3929 - val_loss: 0.4034\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3927 - val_loss: 0.4037\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3923 - val_loss: 0.4034\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3922 - val_loss: 0.4028\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3918 - val_loss: 0.4029\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3915 - val_loss: 0.4032\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3912 - val_loss: 0.4021\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3909 - val_loss: 0.4016\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3906 - val_loss: 0.4016\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3903 - val_loss: 0.4011\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3899 - val_loss: 0.4006\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3898 - val_loss: 0.4008\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3894 - val_loss: 0.4005\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3891 - val_loss: 0.4001\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3887 - val_loss: 0.3999\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3886 - val_loss: 0.4002\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3884 - val_loss: 0.3993\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3880 - val_loss: 0.3994\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3877 - val_loss: 0.3987\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3873 - val_loss: 0.3989\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3871 - val_loss: 0.3987\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3869 - val_loss: 0.3986\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3869 - val_loss: 0.3979\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3865 - val_loss: 0.3972\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3860 - val_loss: 0.3978\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3857 - val_loss: 0.3973\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3853 - val_loss: 0.3973\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3849 - val_loss: 0.3977\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3848 - val_loss: 0.3964\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3844 - val_loss: 0.3957\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3842 - val_loss: 0.3959\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3839 - val_loss: 0.3957\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3836 - val_loss: 0.3953\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3834 - val_loss: 0.3953\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3832 - val_loss: 0.3950\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3830 - val_loss: 0.3962\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3826 - val_loss: 0.3952\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3823 - val_loss: 0.3939\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3820 - val_loss: 0.3947\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3821 - val_loss: 0.3942\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3817 - val_loss: 0.3946\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3812 - val_loss: 0.3936\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3811 - val_loss: 0.3925\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3806 - val_loss: 0.3926\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3802 - val_loss: 0.3930\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3801 - val_loss: 0.3936\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3797 - val_loss: 0.3920\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3793 - val_loss: 0.3928\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3793 - val_loss: 0.3923\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3790 - val_loss: 0.3919\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3787 - val_loss: 0.3911\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3784 - val_loss: 0.3913\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3782 - val_loss: 0.3911\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3781 - val_loss: 0.3923\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3788 - val_loss: 0.3908\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3775 - val_loss: 0.3907\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3772 - val_loss: 0.3898\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3769 - val_loss: 0.3905\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3767 - val_loss: 0.3895\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3764 - val_loss: 0.3891\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3762 - val_loss: 0.3891\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3758 - val_loss: 0.3887\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3759 - val_loss: 0.3890\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3756 - val_loss: 0.3885\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3753 - val_loss: 0.3882\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3751 - val_loss: 0.3882\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3749 - val_loss: 0.3877\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3743 - val_loss: 0.3885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3745 - val_loss: 0.3878\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3742 - val_loss: 0.3880\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3739 - val_loss: 0.3876\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3739 - val_loss: 0.3872\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3737 - val_loss: 0.3864\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3734 - val_loss: 0.3865\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3732 - val_loss: 0.3874\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3729 - val_loss: 0.3862\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3727 - val_loss: 0.3865\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3727 - val_loss: 0.3860\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3721 - val_loss: 0.3867\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3723 - val_loss: 0.3856\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3718 - val_loss: 0.3855\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3718 - val_loss: 0.3857\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3717 - val_loss: 0.3854\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3714 - val_loss: 0.3852\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3712 - val_loss: 0.3860\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3710 - val_loss: 0.3853\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3710 - val_loss: 0.3849\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3706 - val_loss: 0.3845\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3705 - val_loss: 0.3839\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3701 - val_loss: 0.3839\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3700 - val_loss: 0.3837\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3698 - val_loss: 0.3838\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3696 - val_loss: 0.3837\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3692 - val_loss: 0.3844\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3694 - val_loss: 0.3832\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3689 - val_loss: 0.3840\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3688 - val_loss: 0.3823\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3688 - val_loss: 0.3830\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3684 - val_loss: 0.3828\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3682 - val_loss: 0.3825\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3679 - val_loss: 0.3832\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3679 - val_loss: 0.3820\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3677 - val_loss: 0.3821\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3675 - val_loss: 0.3822\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3675 - val_loss: 0.3819\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3671 - val_loss: 0.3818\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3668 - val_loss: 0.3829\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3669 - val_loss: 0.3809\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3668 - val_loss: 0.3808\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3664 - val_loss: 0.3809\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3662 - val_loss: 0.3806\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3662 - val_loss: 0.3808\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3657 - val_loss: 0.3816\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3657 - val_loss: 0.3806\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3659 - val_loss: 0.3808\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3655 - val_loss: 0.3808\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3652 - val_loss: 0.3802\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3650 - val_loss: 0.3799\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3649 - val_loss: 0.3795\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3646 - val_loss: 0.3794\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3649 - val_loss: 0.3799\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3642 - val_loss: 0.3793\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3646 - val_loss: 0.3791\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3642 - val_loss: 0.3786\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3642 - val_loss: 0.3790\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3636 - val_loss: 0.3791\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3635 - val_loss: 0.3783\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3632 - val_loss: 0.3779\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3633 - val_loss: 0.3783\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3629 - val_loss: 0.3778\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3633 - val_loss: 0.3778\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3626 - val_loss: 0.3777\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3636 - val_loss: 0.3770\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3627 - val_loss: 0.3779\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3624 - val_loss: 0.3774\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3622 - val_loss: 0.3778\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3618 - val_loss: 0.3765\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3614 - val_loss: 0.3761\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3615 - val_loss: 0.3763\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3614 - val_loss: 0.3775\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3610 - val_loss: 0.3778\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3617 - val_loss: 0.3767\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3610 - val_loss: 0.3768\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3607 - val_loss: 0.3756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3611 - val_loss: 0.3758\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3604 - val_loss: 0.3770\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3603 - val_loss: 0.3751\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3602 - val_loss: 0.3753\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3601 - val_loss: 0.3748\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3601 - val_loss: 0.3753\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3600 - val_loss: 0.3751\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3594 - val_loss: 0.3755\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3596 - val_loss: 0.3749\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3594 - val_loss: 0.3747\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3592 - val_loss: 0.3738\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3592 - val_loss: 0.3747\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3589 - val_loss: 0.3741\n",
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3588 - val_loss: 0.3742\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3586 - val_loss: 0.3748\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3585 - val_loss: 0.3738\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3590 - val_loss: 0.3737\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3582 - val_loss: 0.3734\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3582 - val_loss: 0.3739\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3580 - val_loss: 0.3742\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3583 - val_loss: 0.3739\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3578 - val_loss: 0.3733\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3575 - val_loss: 0.3731\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3574 - val_loss: 0.3733\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3574 - val_loss: 0.3731\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3571 - val_loss: 0.3736\n",
      "Epoch 294/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3571 - val_loss: 0.3726\n",
      "Epoch 295/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3567 - val_loss: 0.3726\n",
      "Epoch 296/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3568 - val_loss: 0.3724\n",
      "Epoch 297/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3562 - val_loss: 0.3721\n",
      "Epoch 298/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3564 - val_loss: 0.3717\n",
      "Epoch 299/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3564 - val_loss: 0.3720\n",
      "Epoch 300/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3559 - val_loss: 0.3717\n",
      "Epoch 301/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3560 - val_loss: 0.3725\n",
      "Epoch 302/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3555 - val_loss: 0.3717\n",
      "Epoch 303/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3562 - val_loss: 0.3715\n",
      "Epoch 304/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3556 - val_loss: 0.3732\n",
      "Epoch 305/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3557 - val_loss: 0.3713\n",
      "Epoch 306/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3553 - val_loss: 0.3718\n",
      "Epoch 307/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3550 - val_loss: 0.3724\n",
      "Epoch 308/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3552 - val_loss: 0.3708\n",
      "Epoch 309/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3548 - val_loss: 0.3713\n",
      "Epoch 310/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3547 - val_loss: 0.3715\n",
      "Epoch 311/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3546 - val_loss: 0.3716\n",
      "Epoch 312/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3560 - val_loss: 0.3702\n",
      "Epoch 313/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3544 - val_loss: 0.3712\n",
      "Epoch 314/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3543 - val_loss: 0.3708\n",
      "Epoch 315/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3546 - val_loss: 0.3699\n",
      "Epoch 316/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3539 - val_loss: 0.3695\n",
      "Epoch 317/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3542 - val_loss: 0.3705\n",
      "Epoch 318/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3542 - val_loss: 0.3702\n",
      "Epoch 319/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3537 - val_loss: 0.3704\n",
      "Epoch 320/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3537 - val_loss: 0.3698\n",
      "Epoch 321/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3545 - val_loss: 0.3694\n",
      "Epoch 322/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3534 - val_loss: 0.3698\n",
      "Epoch 323/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3536 - val_loss: 0.3720\n",
      "Epoch 324/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3540 - val_loss: 0.3695\n",
      "Epoch 325/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3529 - val_loss: 0.3691\n",
      "Epoch 326/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3532 - val_loss: 0.3691\n",
      "Epoch 327/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3527 - val_loss: 0.3697\n",
      "Epoch 328/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3527 - val_loss: 0.3690\n",
      "Epoch 329/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3526 - val_loss: 0.3688\n",
      "Epoch 330/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3532 - val_loss: 0.3687\n",
      "Epoch 331/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3523 - val_loss: 0.3685\n",
      "Epoch 332/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3531 - val_loss: 0.3681\n",
      "Epoch 333/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3519 - val_loss: 0.3696\n",
      "Epoch 334/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3522 - val_loss: 0.3689\n",
      "Epoch 335/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3517 - val_loss: 0.3700\n",
      "Epoch 336/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3520 - val_loss: 0.3680\n",
      "Epoch 337/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3517 - val_loss: 0.3674\n",
      "Epoch 338/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3518 - val_loss: 0.3690\n",
      "Epoch 339/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3523 - val_loss: 0.3671\n",
      "Epoch 340/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3516 - val_loss: 0.3688\n",
      "Epoch 341/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3541 - val_loss: 0.3683\n",
      "Epoch 342/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3537 - val_loss: 0.3673\n",
      "Epoch 343/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3522 - val_loss: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3505 - val_loss: 0.3672\n",
      "Epoch 345/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3518 - val_loss: 0.3676\n",
      "Epoch 346/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3506 - val_loss: 0.3667\n",
      "Epoch 347/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3522 - val_loss: 0.3667\n",
      "Epoch 348/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3508 - val_loss: 0.3668\n",
      "Epoch 349/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3508 - val_loss: 0.3659\n",
      "Epoch 350/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3502 - val_loss: 0.3669\n",
      "Epoch 351/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3501 - val_loss: 0.3671\n",
      "Epoch 352/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3503 - val_loss: 0.3671\n",
      "Epoch 353/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3511 - val_loss: 0.3664\n",
      "Epoch 354/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3509 - val_loss: 0.3661\n",
      "Epoch 355/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3497 - val_loss: 0.3660\n",
      "Epoch 356/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3499 - val_loss: 0.3665\n",
      "Epoch 357/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3498 - val_loss: 0.3661\n",
      "Epoch 358/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3495 - val_loss: 0.3667\n",
      "Epoch 359/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3490 - val_loss: 0.3651\n",
      "Epoch 360/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3494 - val_loss: 0.3657\n",
      "Epoch 361/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3493 - val_loss: 0.3654\n",
      "Epoch 362/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3489 - val_loss: 0.3665\n",
      "Epoch 363/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3489 - val_loss: 0.3651\n",
      "Epoch 364/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3494 - val_loss: 0.3655\n",
      "Epoch 365/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3486 - val_loss: 0.3657\n",
      "Epoch 366/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3484 - val_loss: 0.3644\n",
      "Epoch 367/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3485 - val_loss: 0.3645\n",
      "Epoch 368/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3481 - val_loss: 0.3650\n",
      "Epoch 369/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3486 - val_loss: 0.3648\n",
      "Epoch 370/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3480 - val_loss: 0.3645\n",
      "Epoch 371/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3484 - val_loss: 0.3636\n",
      "Epoch 372/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3477 - val_loss: 0.3644\n",
      "Epoch 373/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3480 - val_loss: 0.3643\n",
      "Epoch 374/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3474 - val_loss: 0.3641\n",
      "Epoch 375/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3477 - val_loss: 0.3645\n",
      "Epoch 376/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3473 - val_loss: 0.3638\n",
      "Epoch 377/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3470 - val_loss: 0.3640\n",
      "Epoch 378/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3484 - val_loss: 0.3635\n",
      "Epoch 379/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3469 - val_loss: 0.3641\n",
      "Epoch 380/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3472 - val_loss: 0.3635\n",
      "Epoch 381/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3469 - val_loss: 0.3630\n",
      "Epoch 382/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3467 - val_loss: 0.3628\n",
      "Epoch 383/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3473 - val_loss: 0.3628\n",
      "Epoch 384/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3465 - val_loss: 0.3627\n",
      "Epoch 385/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3464 - val_loss: 0.3625\n",
      "Epoch 386/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3463 - val_loss: 0.3631\n",
      "Epoch 387/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3459 - val_loss: 0.3634\n",
      "Epoch 388/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3459 - val_loss: 0.3623\n",
      "Epoch 389/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3466 - val_loss: 0.3637\n",
      "Epoch 390/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3457 - val_loss: 0.3615\n",
      "Epoch 391/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3453 - val_loss: 0.3624\n",
      "Epoch 392/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3451 - val_loss: 0.3631\n",
      "Epoch 393/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3456 - val_loss: 0.3617\n",
      "Epoch 394/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3452 - val_loss: 0.3613\n",
      "Epoch 395/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3457 - val_loss: 0.3614\n",
      "Epoch 396/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3461 - val_loss: 0.3620\n",
      "Epoch 397/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3445 - val_loss: 0.3614\n",
      "Epoch 398/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3454 - val_loss: 0.3606\n",
      "Epoch 399/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3445 - val_loss: 0.3622\n",
      "Epoch 400/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3442 - val_loss: 0.3608\n",
      "Epoch 401/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3446 - val_loss: 0.3616\n",
      "Epoch 402/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3439 - val_loss: 0.3611\n",
      "Epoch 403/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3445 - val_loss: 0.3607\n",
      "Epoch 404/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3444 - val_loss: 0.3605\n",
      "Epoch 405/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3434 - val_loss: 0.3617\n",
      "Epoch 406/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3439 - val_loss: 0.3609\n",
      "Epoch 407/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3435 - val_loss: 0.3602\n",
      "Epoch 408/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3435 - val_loss: 0.3600\n",
      "Epoch 409/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3432 - val_loss: 0.3588\n",
      "Epoch 410/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3430 - val_loss: 0.3592\n",
      "Epoch 411/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3436 - val_loss: 0.3604\n",
      "Epoch 412/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3435 - val_loss: 0.3593\n",
      "Epoch 413/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3428 - val_loss: 0.3604\n",
      "Epoch 414/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3449 - val_loss: 0.3595\n",
      "Epoch 415/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3430 - val_loss: 0.3583\n",
      "Epoch 416/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3429 - val_loss: 0.3584\n",
      "Epoch 417/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3423 - val_loss: 0.3588\n",
      "Epoch 418/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3421 - val_loss: 0.3581\n",
      "Epoch 419/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3417 - val_loss: 0.3580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3426 - val_loss: 0.3583\n",
      "Epoch 421/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3416 - val_loss: 0.3589\n",
      "Epoch 422/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3413 - val_loss: 0.3590\n",
      "Epoch 423/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3412 - val_loss: 0.3578\n",
      "Epoch 424/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3411 - val_loss: 0.3578\n",
      "Epoch 425/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3417 - val_loss: 0.3571\n",
      "Epoch 426/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3412 - val_loss: 0.3575\n",
      "Epoch 427/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3416 - val_loss: 0.3585\n",
      "Epoch 428/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3405 - val_loss: 0.3571\n",
      "Epoch 429/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3408 - val_loss: 0.3569\n",
      "Epoch 430/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3411 - val_loss: 0.3571\n",
      "Epoch 431/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3405 - val_loss: 0.3567\n",
      "Epoch 432/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3403 - val_loss: 0.3568\n",
      "Epoch 433/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3404 - val_loss: 0.3566\n",
      "Epoch 434/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3402 - val_loss: 0.3590\n",
      "Epoch 435/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3421 - val_loss: 0.3571\n",
      "Epoch 436/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3412 - val_loss: 0.3567\n",
      "Epoch 437/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3414 - val_loss: 0.3563\n",
      "Epoch 438/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3398 - val_loss: 0.3562\n",
      "Epoch 439/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3393 - val_loss: 0.3581\n",
      "Epoch 440/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3401 - val_loss: 0.3558\n",
      "Epoch 441/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3393 - val_loss: 0.3557\n",
      "Epoch 442/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3398 - val_loss: 0.3562\n",
      "Epoch 443/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3395 - val_loss: 0.3548\n",
      "Epoch 444/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3394 - val_loss: 0.3561\n",
      "Epoch 445/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3421 - val_loss: 0.3560\n",
      "Epoch 446/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3386 - val_loss: 0.3559\n",
      "Epoch 447/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3387 - val_loss: 0.3561\n",
      "Epoch 448/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3387 - val_loss: 0.3566\n",
      "Epoch 449/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3387 - val_loss: 0.3584\n",
      "Epoch 450/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3397 - val_loss: 0.3542\n",
      "Epoch 451/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3387 - val_loss: 0.3560\n",
      "Epoch 452/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3388 - val_loss: 0.3561\n",
      "Epoch 453/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3382 - val_loss: 0.3550\n",
      "Epoch 454/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3392 - val_loss: 0.3551\n",
      "Epoch 455/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3397 - val_loss: 0.3538\n",
      "Epoch 456/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3384 - val_loss: 0.3551\n",
      "Epoch 457/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3375 - val_loss: 0.3557\n",
      "Epoch 458/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3385 - val_loss: 0.3549\n",
      "Epoch 459/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3395 - val_loss: 0.3558\n",
      "Epoch 460/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3375 - val_loss: 0.3544\n",
      "Epoch 461/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3373 - val_loss: 0.3539\n",
      "Epoch 462/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3376 - val_loss: 0.3539\n",
      "Epoch 463/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3370 - val_loss: 0.3550\n",
      "Epoch 464/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3388 - val_loss: 0.3532\n",
      "Epoch 465/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3371 - val_loss: 0.3540\n",
      "Epoch 466/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3370 - val_loss: 0.3545\n",
      "Epoch 467/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3367 - val_loss: 0.3543\n",
      "Epoch 468/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3368 - val_loss: 0.3542\n",
      "Epoch 469/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3370 - val_loss: 0.3544\n",
      "Epoch 470/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3388 - val_loss: 0.3534\n",
      "Epoch 471/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3364 - val_loss: 0.3532\n",
      "Epoch 472/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3375 - val_loss: 0.3552\n",
      "Epoch 473/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3382 - val_loss: 0.3533\n",
      "Epoch 474/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3369 - val_loss: 0.3521\n",
      "Epoch 475/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3361 - val_loss: 0.3529\n",
      "Epoch 476/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3379 - val_loss: 0.3543\n",
      "Epoch 477/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3404 - val_loss: 0.3542\n",
      "Epoch 478/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3426 - val_loss: 0.3539\n",
      "Epoch 479/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3374 - val_loss: 0.3526\n",
      "Epoch 480/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3365 - val_loss: 0.3525\n",
      "Epoch 481/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3362 - val_loss: 0.3522\n",
      "Epoch 482/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3360 - val_loss: 0.3522\n",
      "Epoch 483/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3364 - val_loss: 0.3522\n",
      "Epoch 484/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3356 - val_loss: 0.3535\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3726\n",
      "[CV]  learning_rate=0.0010811218976198044, n_hidden=1, n_neurons=28, total= 2.9min\n",
      "[CV] learning_rate=0.0010811218976198044, n_hidden=1, n_neurons=28 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 3.0327 - val_loss: 1.1346\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.9224 - val_loss: 0.7453\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6738 - val_loss: 0.6669\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6255 - val_loss: 0.6307\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5977 - val_loss: 0.6056\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5812 - val_loss: 0.5899\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5648 - val_loss: 0.5744\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5529 - val_loss: 0.5643\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5417 - val_loss: 0.5523\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5315 - val_loss: 0.5426\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5235 - val_loss: 0.5354\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5154 - val_loss: 0.5279\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5084 - val_loss: 0.5210\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5023 - val_loss: 0.5151\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4965 - val_loss: 0.5097\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4914 - val_loss: 0.5047\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4868 - val_loss: 0.5010\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4826 - val_loss: 0.4967\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4789 - val_loss: 0.4931\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4754 - val_loss: 0.4904\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4723 - val_loss: 0.4873\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4696 - val_loss: 0.4850\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4667 - val_loss: 0.4822\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4649 - val_loss: 0.4805\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4624 - val_loss: 0.4788\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4607 - val_loss: 0.4758\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4589 - val_loss: 0.4741\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4572 - val_loss: 0.4730\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4556 - val_loss: 0.4715\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4542 - val_loss: 0.4700\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4528 - val_loss: 0.4688\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4514 - val_loss: 0.4673\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4500 - val_loss: 0.4657\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4489 - val_loss: 0.4646\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4476 - val_loss: 0.4632\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4467 - val_loss: 0.4623\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4454 - val_loss: 0.4609\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4444 - val_loss: 0.4608\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4434 - val_loss: 0.4592\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4423 - val_loss: 0.4585\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4415 - val_loss: 0.4572\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4403 - val_loss: 0.4562\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4395 - val_loss: 0.4552\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4385 - val_loss: 0.4542\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4376 - val_loss: 0.4536\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4368 - val_loss: 0.4526\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4359 - val_loss: 0.4521\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4349 - val_loss: 0.4519\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4341 - val_loss: 0.4502\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4333 - val_loss: 0.4500\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4326 - val_loss: 0.4493\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4318 - val_loss: 0.4483\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4309 - val_loss: 0.4474\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4302 - val_loss: 0.4469\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4290 - val_loss: 0.4459\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4287 - val_loss: 0.4453\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4277 - val_loss: 0.4457\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4271 - val_loss: 0.4436\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4261 - val_loss: 0.4436\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4255 - val_loss: 0.4429\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4249 - val_loss: 0.4421\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4241 - val_loss: 0.4408\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4233 - val_loss: 0.4407\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4227 - val_loss: 0.4400\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4219 - val_loss: 0.4395\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4214 - val_loss: 0.4387\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4205 - val_loss: 0.4383\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4200 - val_loss: 0.4369\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4193 - val_loss: 0.4361\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4185 - val_loss: 0.4367\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4179 - val_loss: 0.4355\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4174 - val_loss: 0.4349\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4166 - val_loss: 0.4338\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4160 - val_loss: 0.4336\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4154 - val_loss: 0.4326\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4145 - val_loss: 0.4327\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4141 - val_loss: 0.4317\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4135 - val_loss: 0.4314\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4127 - val_loss: 0.4306\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4122 - val_loss: 0.4303\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4116 - val_loss: 0.4297\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4108 - val_loss: 0.4297\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4104 - val_loss: 0.4281\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4098 - val_loss: 0.4278\n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4091 - val_loss: 0.4270\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4085 - val_loss: 0.4269\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4080 - val_loss: 0.4257\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4072 - val_loss: 0.4256\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4067 - val_loss: 0.4247\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4061 - val_loss: 0.4239\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4056 - val_loss: 0.4240\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4050 - val_loss: 0.4228\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4045 - val_loss: 0.4225\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4040 - val_loss: 0.4223\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4033 - val_loss: 0.4211\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4028 - val_loss: 0.4206\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4023 - val_loss: 0.4203\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4018 - val_loss: 0.4200\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4012 - val_loss: 0.4193\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4006 - val_loss: 0.4190\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4001 - val_loss: 0.4187\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3996 - val_loss: 0.4184\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3991 - val_loss: 0.4178\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3985 - val_loss: 0.4164\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3981 - val_loss: 0.4162\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3975 - val_loss: 0.4156\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3969 - val_loss: 0.4153\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3965 - val_loss: 0.4144\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3960 - val_loss: 0.4139\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3953 - val_loss: 0.4140\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3948 - val_loss: 0.4136\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3939 - val_loss: 0.4125\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3939 - val_loss: 0.4123\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3934 - val_loss: 0.4115\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3927 - val_loss: 0.4113\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3922 - val_loss: 0.4105\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3917 - val_loss: 0.4104\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3911 - val_loss: 0.4094\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3906 - val_loss: 0.4092\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3902 - val_loss: 0.4084\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3896 - val_loss: 0.4085\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3891 - val_loss: 0.4079\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3886 - val_loss: 0.4075\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3882 - val_loss: 0.4064\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3876 - val_loss: 0.4066\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3872 - val_loss: 0.4056\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3867 - val_loss: 0.4051\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3862 - val_loss: 0.4046\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3855 - val_loss: 0.4043\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3850 - val_loss: 0.4042\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3846 - val_loss: 0.4033\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3841 - val_loss: 0.4028\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3837 - val_loss: 0.4018\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3833 - val_loss: 0.4016\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3827 - val_loss: 0.4014\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3820 - val_loss: 0.4005\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3817 - val_loss: 0.4004\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3812 - val_loss: 0.3996\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3808 - val_loss: 0.3992\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3802 - val_loss: 0.3984\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3798 - val_loss: 0.3983\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3793 - val_loss: 0.3976\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3786 - val_loss: 0.3975\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3782 - val_loss: 0.3968\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3777 - val_loss: 0.3963\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3772 - val_loss: 0.3962\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3768 - val_loss: 0.3953\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3764 - val_loss: 0.3947\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3758 - val_loss: 0.3943\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3751 - val_loss: 0.3946\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3748 - val_loss: 0.3939\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3743 - val_loss: 0.3931\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3737 - val_loss: 0.3925\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3735 - val_loss: 0.3922\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3728 - val_loss: 0.3920\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3722 - val_loss: 0.3920\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3720 - val_loss: 0.3910\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3713 - val_loss: 0.3908\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3709 - val_loss: 0.3896\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3706 - val_loss: 0.3898\n",
      "Epoch 161/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3701 - val_loss: 0.3894\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3696 - val_loss: 0.3889\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3692 - val_loss: 0.3888\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3688 - val_loss: 0.3887\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3684 - val_loss: 0.3875\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3678 - val_loss: 0.3868\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3677 - val_loss: 0.3868\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3671 - val_loss: 0.3862\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3668 - val_loss: 0.3863\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3662 - val_loss: 0.3862\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3658 - val_loss: 0.3857\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3653 - val_loss: 0.3855\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3649 - val_loss: 0.3853\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3646 - val_loss: 0.3842\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3642 - val_loss: 0.3839\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3638 - val_loss: 0.3834\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3633 - val_loss: 0.3836\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3631 - val_loss: 0.3828\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3625 - val_loss: 0.3830\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3623 - val_loss: 0.3829\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3620 - val_loss: 0.3821\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3616 - val_loss: 0.3820\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3612 - val_loss: 0.3812\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3609 - val_loss: 0.3813\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3605 - val_loss: 0.3806\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3600 - val_loss: 0.3806\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3598 - val_loss: 0.3802\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3595 - val_loss: 0.3803\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3589 - val_loss: 0.3793\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3589 - val_loss: 0.3795\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3585 - val_loss: 0.3793\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3581 - val_loss: 0.3794\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3578 - val_loss: 0.3791\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3575 - val_loss: 0.3778\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3572 - val_loss: 0.3778\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3569 - val_loss: 0.3779\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3565 - val_loss: 0.3772\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3562 - val_loss: 0.3770\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3558 - val_loss: 0.3766\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3557 - val_loss: 0.3763\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3554 - val_loss: 0.3759\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3551 - val_loss: 0.3757\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3546 - val_loss: 0.3754\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3543 - val_loss: 0.3754\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3541 - val_loss: 0.3753\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3539 - val_loss: 0.3748\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3534 - val_loss: 0.3746\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3531 - val_loss: 0.3741\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3530 - val_loss: 0.3741\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3523 - val_loss: 0.3738\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3521 - val_loss: 0.3726\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3521 - val_loss: 0.3728\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3517 - val_loss: 0.3726\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3512 - val_loss: 0.3721\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3511 - val_loss: 0.3723\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3507 - val_loss: 0.3713\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3505 - val_loss: 0.3716\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3500 - val_loss: 0.3717\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3499 - val_loss: 0.3711\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3496 - val_loss: 0.3705\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3493 - val_loss: 0.3703\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3490 - val_loss: 0.3701\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3487 - val_loss: 0.3702\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3484 - val_loss: 0.3700\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3482 - val_loss: 0.3692\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3477 - val_loss: 0.3696\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3477 - val_loss: 0.3687\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3475 - val_loss: 0.3687\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3471 - val_loss: 0.3686\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3469 - val_loss: 0.3683\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3467 - val_loss: 0.3681\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3463 - val_loss: 0.3680\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3460 - val_loss: 0.3678\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3459 - val_loss: 0.3689\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3457 - val_loss: 0.3677\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3453 - val_loss: 0.3669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3450 - val_loss: 0.3665\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3449 - val_loss: 0.3664\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3447 - val_loss: 0.3667\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3444 - val_loss: 0.3665\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3442 - val_loss: 0.3660\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3441 - val_loss: 0.3657\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3436 - val_loss: 0.3652\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3435 - val_loss: 0.3654\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3432 - val_loss: 0.3650\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3431 - val_loss: 0.3649\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3428 - val_loss: 0.3647\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3424 - val_loss: 0.3654\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3420 - val_loss: 0.3657\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3421 - val_loss: 0.3645\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3416 - val_loss: 0.3643\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3415 - val_loss: 0.3640\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3414 - val_loss: 0.3641\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3410 - val_loss: 0.3632\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3409 - val_loss: 0.3638\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3408 - val_loss: 0.3627\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3405 - val_loss: 0.3628\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3403 - val_loss: 0.3628\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3399 - val_loss: 0.3626\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3397 - val_loss: 0.3626\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3396 - val_loss: 0.3619\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3394 - val_loss: 0.3619\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3390 - val_loss: 0.3620\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3389 - val_loss: 0.3616\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3386 - val_loss: 0.3616\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3384 - val_loss: 0.3612\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3383 - val_loss: 0.3609\n",
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3379 - val_loss: 0.3605\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3376 - val_loss: 0.3614\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3375 - val_loss: 0.3605\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3372 - val_loss: 0.3608\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3369 - val_loss: 0.3602\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3367 - val_loss: 0.3603\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3366 - val_loss: 0.3595\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3361 - val_loss: 0.3603\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3362 - val_loss: 0.3590\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3358 - val_loss: 0.3607\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3358 - val_loss: 0.3592\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3356 - val_loss: 0.3588\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3352 - val_loss: 0.3587\n",
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3350 - val_loss: 0.3583\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3348 - val_loss: 0.3581\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3347 - val_loss: 0.3579\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3345 - val_loss: 0.3578\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3342 - val_loss: 0.3577\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3340 - val_loss: 0.3577\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3340 - val_loss: 0.3578\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3337 - val_loss: 0.3575\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3336 - val_loss: 0.3572\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3334 - val_loss: 0.3575\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3331 - val_loss: 0.3571\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3329 - val_loss: 0.3577\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3327 - val_loss: 0.3567\n",
      "Epoch 294/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3326 - val_loss: 0.3570\n",
      "Epoch 295/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3325 - val_loss: 0.3563\n",
      "Epoch 296/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3322 - val_loss: 0.3564\n",
      "Epoch 297/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3322 - val_loss: 0.3562\n",
      "Epoch 298/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3318 - val_loss: 0.3568\n",
      "Epoch 299/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3319 - val_loss: 0.3563\n",
      "Epoch 300/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3314 - val_loss: 0.3562\n",
      "Epoch 301/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3314 - val_loss: 0.3562\n",
      "Epoch 302/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3311 - val_loss: 0.3570\n",
      "Epoch 303/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3310 - val_loss: 0.3556\n",
      "Epoch 304/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3308 - val_loss: 0.3554\n",
      "Epoch 305/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3306 - val_loss: 0.3566\n",
      "Epoch 306/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3302 - val_loss: 0.3546\n",
      "Epoch 307/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3303 - val_loss: 0.3548\n",
      "Epoch 308/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3299 - val_loss: 0.3545\n",
      "Epoch 309/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3301 - val_loss: 0.3548\n",
      "Epoch 310/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3297 - val_loss: 0.3548\n",
      "Epoch 311/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3296 - val_loss: 0.3541\n",
      "Epoch 312/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3293 - val_loss: 0.3545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3294 - val_loss: 0.3548\n",
      "Epoch 314/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3289 - val_loss: 0.3544\n",
      "Epoch 315/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3287 - val_loss: 0.3551\n",
      "Epoch 316/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3288 - val_loss: 0.3539\n",
      "Epoch 317/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3287 - val_loss: 0.3546\n",
      "Epoch 318/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3283 - val_loss: 0.3545\n",
      "Epoch 319/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3280 - val_loss: 0.3542\n",
      "Epoch 320/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3282 - val_loss: 0.3540\n",
      "Epoch 321/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3279 - val_loss: 0.3535\n",
      "Epoch 322/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3278 - val_loss: 0.3533\n",
      "Epoch 323/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3277 - val_loss: 0.3530\n",
      "Epoch 324/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3276 - val_loss: 0.3530\n",
      "Epoch 325/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3271 - val_loss: 0.3544\n",
      "Epoch 326/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3271 - val_loss: 0.3538\n",
      "Epoch 327/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3269 - val_loss: 0.3528\n",
      "Epoch 328/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3267 - val_loss: 0.3538\n",
      "Epoch 329/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3265 - val_loss: 0.3534\n",
      "Epoch 330/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3263 - val_loss: 0.3528\n",
      "Epoch 331/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3263 - val_loss: 0.3524\n",
      "Epoch 332/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3262 - val_loss: 0.3533\n",
      "Epoch 333/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3260 - val_loss: 0.3528\n",
      "Epoch 334/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3258 - val_loss: 0.3526\n",
      "Epoch 335/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3255 - val_loss: 0.3521\n",
      "Epoch 336/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3254 - val_loss: 0.3526\n",
      "Epoch 337/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3255 - val_loss: 0.3528\n",
      "Epoch 338/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3252 - val_loss: 0.3518\n",
      "Epoch 339/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3251 - val_loss: 0.3524\n",
      "Epoch 340/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3251 - val_loss: 0.3520\n",
      "Epoch 341/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3251 - val_loss: 0.3516\n",
      "Epoch 342/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3247 - val_loss: 0.3525\n",
      "Epoch 343/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3245 - val_loss: 0.3514\n",
      "Epoch 344/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3243 - val_loss: 0.3510\n",
      "Epoch 345/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3240 - val_loss: 0.3521\n",
      "Epoch 346/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3243 - val_loss: 0.3512\n",
      "Epoch 347/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3239 - val_loss: 0.3517\n",
      "Epoch 348/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3238 - val_loss: 0.3509\n",
      "Epoch 349/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3238 - val_loss: 0.3518\n",
      "Epoch 350/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3237 - val_loss: 0.3506\n",
      "Epoch 351/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3234 - val_loss: 0.3506\n",
      "Epoch 352/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3235 - val_loss: 0.3510\n",
      "Epoch 353/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3233 - val_loss: 0.3517\n",
      "Epoch 354/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3234 - val_loss: 0.3502\n",
      "Epoch 355/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3231 - val_loss: 0.3507\n",
      "Epoch 356/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3229 - val_loss: 0.3506\n",
      "Epoch 357/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3232 - val_loss: 0.3506\n",
      "Epoch 358/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3227 - val_loss: 0.3505\n",
      "Epoch 359/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3230 - val_loss: 0.3505\n",
      "Epoch 360/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3231 - val_loss: 0.3500\n",
      "Epoch 361/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3228 - val_loss: 0.3508\n",
      "Epoch 362/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3232 - val_loss: 0.3503\n",
      "Epoch 363/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3239 - val_loss: 0.3496\n",
      "Epoch 364/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3236 - val_loss: 0.3494\n",
      "Epoch 365/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3235 - val_loss: 0.3507\n",
      "Epoch 366/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3233 - val_loss: 0.3505\n",
      "Epoch 367/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3242 - val_loss: 0.3494\n",
      "Epoch 368/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3244 - val_loss: 0.3491\n",
      "Epoch 369/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3246 - val_loss: 0.3497\n",
      "Epoch 370/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3246 - val_loss: 0.3489\n",
      "Epoch 371/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3253 - val_loss: 0.3490\n",
      "Epoch 372/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3254 - val_loss: 0.3501\n",
      "Epoch 373/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3270 - val_loss: 0.3501\n",
      "Epoch 374/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3274 - val_loss: 0.3489\n",
      "Epoch 375/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3276 - val_loss: 0.3495\n",
      "Epoch 376/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3283 - val_loss: 0.3487\n",
      "Epoch 377/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3291 - val_loss: 0.3499\n",
      "Epoch 378/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3353 - val_loss: 0.3483\n",
      "Epoch 379/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3436 - val_loss: 0.3493\n",
      "Epoch 380/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3444 - val_loss: 0.3509\n",
      "Epoch 381/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3477 - val_loss: 0.3494\n",
      "Epoch 382/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3512 - val_loss: 0.3471\n",
      "Epoch 383/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3490 - val_loss: 0.3524\n",
      "Epoch 384/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3493 - val_loss: 0.3481\n",
      "Epoch 385/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3483 - val_loss: 0.3512\n",
      "Epoch 386/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3456 - val_loss: 0.3481\n",
      "Epoch 387/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3417 - val_loss: 0.3484\n",
      "Epoch 388/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3369 - val_loss: 0.3481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3335 - val_loss: 0.3485\n",
      "Epoch 390/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3303 - val_loss: 0.3480\n",
      "Epoch 391/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3291 - val_loss: 0.3476\n",
      "Epoch 392/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3271 - val_loss: 0.3476\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3638\n",
      "[CV]  learning_rate=0.0010811218976198044, n_hidden=1, n_neurons=28, total= 2.3min\n",
      "[CV] learning_rate=0.002317134505774989, n_hidden=1, n_neurons=45 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.8009 - val_loss: 0.7783\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 1.4751 - val_loss: 0.7588\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.9122 - val_loss: 0.6682\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6669 - val_loss: 0.6296\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6250 - val_loss: 0.5985\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5915 - val_loss: 0.5702\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5672 - val_loss: 0.5492\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5482 - val_loss: 0.5310\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5327 - val_loss: 0.5203\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5193 - val_loss: 0.5229\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5053 - val_loss: 0.4950\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5019 - val_loss: 0.4927\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4894 - val_loss: 0.4922\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4807 - val_loss: 0.4748\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4838 - val_loss: 0.4788\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4730 - val_loss: 0.4656\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4758 - val_loss: 0.4651\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4647 - val_loss: 0.4709\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4606 - val_loss: 0.4557\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4645 - val_loss: 0.4535\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4576 - val_loss: 0.4509\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4559 - val_loss: 0.4476\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4580 - val_loss: 0.4474\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4497 - val_loss: 0.4531\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4485 - val_loss: 0.4494\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4460 - val_loss: 0.4404\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4435 - val_loss: 0.4372\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4439 - val_loss: 0.4363\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4401 - val_loss: 0.4353\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4389 - val_loss: 0.4331\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4346 - val_loss: 0.4318\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4354 - val_loss: 0.4332\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4333 - val_loss: 0.4331\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4305 - val_loss: 0.4279\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4309 - val_loss: 0.4272\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4297 - val_loss: 0.4254\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4295 - val_loss: 0.4240\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4245 - val_loss: 0.4219\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4249 - val_loss: 0.4210\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4232 - val_loss: 0.4192\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4217 - val_loss: 0.4247\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4213 - val_loss: 0.4193\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4195 - val_loss: 0.4159\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4184 - val_loss: 0.4143\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4175 - val_loss: 0.4136\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4159 - val_loss: 0.4134\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4146 - val_loss: 0.4122\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4138 - val_loss: 0.4111\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4124 - val_loss: 0.4098\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4117 - val_loss: 0.4102\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4104 - val_loss: 0.4078\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4092 - val_loss: 0.4067\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4085 - val_loss: 0.4056\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4078 - val_loss: 0.4050\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4065 - val_loss: 0.4040\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4057 - val_loss: 0.4038\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4044 - val_loss: 0.4036\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4037 - val_loss: 0.4012\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4027 - val_loss: 0.4006\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4020 - val_loss: 0.4008\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4009 - val_loss: 0.3997\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4002 - val_loss: 0.3989\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3990 - val_loss: 0.3981\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3987 - val_loss: 0.3967\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3975 - val_loss: 0.3961\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3965 - val_loss: 0.3958\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3958 - val_loss: 0.3965\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3954 - val_loss: 0.3942\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3943 - val_loss: 0.3937\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3935 - val_loss: 0.3920\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3928 - val_loss: 0.3927\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3922 - val_loss: 0.3930\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3912 - val_loss: 0.3904\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3903 - val_loss: 0.3896\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3896 - val_loss: 0.3909\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3887 - val_loss: 0.3889\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3880 - val_loss: 0.3880\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3873 - val_loss: 0.3881\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3866 - val_loss: 0.3856\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3859 - val_loss: 0.3861\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3851 - val_loss: 0.3854\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3842 - val_loss: 0.3856\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3838 - val_loss: 0.3846\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3831 - val_loss: 0.3837\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3823 - val_loss: 0.3833\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3816 - val_loss: 0.3825\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3810 - val_loss: 0.3813\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3805 - val_loss: 0.3826\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3798 - val_loss: 0.3805\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3790 - val_loss: 0.3797\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3787 - val_loss: 0.3800\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3777 - val_loss: 0.3797\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3772 - val_loss: 0.3793\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3768 - val_loss: 0.3779\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3766 - val_loss: 0.3786\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3758 - val_loss: 0.3784\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3746 - val_loss: 0.3805\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3746 - val_loss: 0.3758\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3741 - val_loss: 0.3756\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3739 - val_loss: 0.3766\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3732 - val_loss: 0.3758\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3723 - val_loss: 0.3747\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3717 - val_loss: 0.3752\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3710 - val_loss: 0.3748\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3706 - val_loss: 0.3734\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3708 - val_loss: 0.3720\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3700 - val_loss: 0.3726\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3694 - val_loss: 0.3743\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3687 - val_loss: 0.3721\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3682 - val_loss: 0.3722\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3676 - val_loss: 0.3708\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3673 - val_loss: 0.3711\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3667 - val_loss: 0.3694\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3661 - val_loss: 0.3700\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3660 - val_loss: 0.3699\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3654 - val_loss: 0.3692\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3651 - val_loss: 0.3695\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3643 - val_loss: 0.3695\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3636 - val_loss: 0.3693\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3638 - val_loss: 0.3671\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3630 - val_loss: 0.3663\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3625 - val_loss: 0.3680\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3626 - val_loss: 0.3686\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3620 - val_loss: 0.3657\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3612 - val_loss: 0.3655\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3615 - val_loss: 0.3655\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3600 - val_loss: 0.3684\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3604 - val_loss: 0.3658\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3608 - val_loss: 0.3641\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3598 - val_loss: 0.3635\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3588 - val_loss: 0.3650\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3595 - val_loss: 0.3631\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3593 - val_loss: 0.3631\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3579 - val_loss: 0.3647\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3672 - val_loss: 0.3638\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3588 - val_loss: 0.3629\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3569 - val_loss: 0.3627\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3568 - val_loss: 0.3620\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3572 - val_loss: 0.3623\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3560 - val_loss: 0.3623\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3557 - val_loss: 0.3598\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3553 - val_loss: 0.3607\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3545 - val_loss: 0.3599\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3542 - val_loss: 0.3596\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3537 - val_loss: 0.3597\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3539 - val_loss: 0.3606\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3548 - val_loss: 0.3583\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3538 - val_loss: 0.3593\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3524 - val_loss: 0.3591\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3524 - val_loss: 0.3569\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3519 - val_loss: 0.3575\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3515 - val_loss: 0.3572\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3504 - val_loss: 0.3580\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3506 - val_loss: 0.3568\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3515 - val_loss: 0.3566\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3510 - val_loss: 0.3570\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3502 - val_loss: 0.3563\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3500 - val_loss: 0.3573\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3498 - val_loss: 0.3553\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3494 - val_loss: 0.3556\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3488 - val_loss: 0.3544\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3481 - val_loss: 0.3565\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3485 - val_loss: 0.3574\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3481 - val_loss: 0.3540\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3476 - val_loss: 0.3532\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3470 - val_loss: 0.3530\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3471 - val_loss: 0.3520\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3466 - val_loss: 0.3520\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3478 - val_loss: 0.3530\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3461 - val_loss: 0.3544\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3457 - val_loss: 0.3545\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3457 - val_loss: 0.3664\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3586 - val_loss: 0.3517\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3493 - val_loss: 0.3536\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3451 - val_loss: 0.3512\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3453 - val_loss: 0.3519\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3443 - val_loss: 0.3605\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3496 - val_loss: 0.3510\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3453 - val_loss: 0.3511\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3435 - val_loss: 0.3495\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3429 - val_loss: 0.3533\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3528 - val_loss: 0.3493\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3418 - val_loss: 0.3505\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3421 - val_loss: 0.3509\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3413 - val_loss: 0.3505\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3406 - val_loss: 0.3487\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3437 - val_loss: 0.3484\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3410 - val_loss: 0.3476\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3399 - val_loss: 0.3483\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3417 - val_loss: 0.3484\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3409 - val_loss: 0.3491\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3397 - val_loss: 0.3475\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3414 - val_loss: 0.3471\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3402 - val_loss: 0.3483\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3408 - val_loss: 0.3489\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3384 - val_loss: 0.3485\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3382 - val_loss: 0.3488\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3401 - val_loss: 0.3480\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3377 - val_loss: 0.3471\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3381 - val_loss: 0.3466\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3373 - val_loss: 0.3461\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3371 - val_loss: 0.3477\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3366 - val_loss: 0.3466\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3409 - val_loss: 0.3462\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3400 - val_loss: 0.3506\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3458 - val_loss: 0.3455\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3381 - val_loss: 0.3453\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3362 - val_loss: 0.3440\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3358 - val_loss: 0.3459\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3359 - val_loss: 0.3435\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3360 - val_loss: 0.3444\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3350 - val_loss: 0.3462\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3351 - val_loss: 0.3450\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3336 - val_loss: 0.3451\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3348 - val_loss: 0.3439\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3340 - val_loss: 0.3443\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3356 - val_loss: 0.3449\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3335 - val_loss: 0.3438\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3335 - val_loss: 0.3426\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3336 - val_loss: 0.3418\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3322 - val_loss: 0.3446\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3320 - val_loss: 0.3422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3324 - val_loss: 0.3440\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3321 - val_loss: 0.3414\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3317 - val_loss: 0.3430\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3360 - val_loss: 0.3472\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3356 - val_loss: 0.3424\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3306 - val_loss: 0.3419\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3326 - val_loss: 0.3432\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3428 - val_loss: 0.3423\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3332 - val_loss: 0.3412\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3332 - val_loss: 0.3412\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3337 - val_loss: 0.3408\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3315 - val_loss: 0.3451\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3309 - val_loss: 0.3429\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3299 - val_loss: 0.3405\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3299 - val_loss: 0.3409\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3308 - val_loss: 0.3416\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3333 - val_loss: 0.3417\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3305 - val_loss: 0.3408\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3330 - val_loss: 0.3406\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3316 - val_loss: 0.3393\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3290 - val_loss: 0.3413\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3287 - val_loss: 0.3402\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3291 - val_loss: 0.3386\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3276 - val_loss: 0.3386\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3280 - val_loss: 0.3400\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3277 - val_loss: 0.3447\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3282 - val_loss: 0.3391\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3287 - val_loss: 0.3389\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3279 - val_loss: 0.3382\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3281 - val_loss: 0.3420\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3262 - val_loss: 0.3387\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3278 - val_loss: 0.3383\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3264 - val_loss: 0.3398\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3298 - val_loss: 0.3414\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3286 - val_loss: 0.3386\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3287 - val_loss: 0.3390\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3272 - val_loss: 0.3387\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3265 - val_loss: 0.3406\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3261 - val_loss: 0.3480\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.3182\n",
      "[CV]  learning_rate=0.002317134505774989, n_hidden=1, n_neurons=45, total= 1.5min\n",
      "[CV] learning_rate=0.002317134505774989, n_hidden=1, n_neurons=45 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.6208 - val_loss: 0.6941\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6479 - val_loss: 0.6213\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6075 - val_loss: 0.5870\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5727 - val_loss: 0.5615\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5479 - val_loss: 0.5398\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5289 - val_loss: 0.5247\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5102 - val_loss: 0.5081\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4965 - val_loss: 0.4969\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4898 - val_loss: 0.4888\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4797 - val_loss: 0.4849\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4715 - val_loss: 0.4749\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4655 - val_loss: 0.4691\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4610 - val_loss: 0.4671\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4548 - val_loss: 0.4625\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4503 - val_loss: 0.4574\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4475 - val_loss: 0.4548\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4445 - val_loss: 0.4534\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4412 - val_loss: 0.4499\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4390 - val_loss: 0.4478\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4389 - val_loss: 0.4455\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4354 - val_loss: 0.4431\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4336 - val_loss: 0.4426\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4310 - val_loss: 0.4407\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4296 - val_loss: 0.4399\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4270 - val_loss: 0.4364\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4257 - val_loss: 0.4356\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4238 - val_loss: 0.4333\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4228 - val_loss: 0.4331\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4210 - val_loss: 0.4322\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4197 - val_loss: 0.4303\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4180 - val_loss: 0.4281\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4169 - val_loss: 0.4269\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4157 - val_loss: 0.4266\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4145 - val_loss: 0.4244\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4134 - val_loss: 0.4247\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4119 - val_loss: 0.4230\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4109 - val_loss: 0.4214\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4097 - val_loss: 0.4213\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4084 - val_loss: 0.4200\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4073 - val_loss: 0.4187\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4064 - val_loss: 0.4185\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4055 - val_loss: 0.4175\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4043 - val_loss: 0.4165\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4030 - val_loss: 0.4153\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4024 - val_loss: 0.4161\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4016 - val_loss: 0.4145\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4009 - val_loss: 0.4138\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4000 - val_loss: 0.4124\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3988 - val_loss: 0.4128\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3977 - val_loss: 0.4125\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3973 - val_loss: 0.4107\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3963 - val_loss: 0.4092\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3952 - val_loss: 0.4091\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3948 - val_loss: 0.4083\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3937 - val_loss: 0.4080\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3930 - val_loss: 0.4072\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3920 - val_loss: 0.4055\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3915 - val_loss: 0.4058\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3903 - val_loss: 0.4051\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3900 - val_loss: 0.4039\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3887 - val_loss: 0.4043\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3883 - val_loss: 0.4022\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3874 - val_loss: 0.4017\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3870 - val_loss: 0.4020\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3863 - val_loss: 0.4012\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3856 - val_loss: 0.3996\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3847 - val_loss: 0.4002\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3840 - val_loss: 0.3995\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3832 - val_loss: 0.3988\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3828 - val_loss: 0.3979\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3823 - val_loss: 0.3972\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3813 - val_loss: 0.3984\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3804 - val_loss: 0.3965\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3804 - val_loss: 0.3960\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3797 - val_loss: 0.3958\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3793 - val_loss: 0.3949\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3783 - val_loss: 0.3942\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3777 - val_loss: 0.3948\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3775 - val_loss: 0.3941\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3767 - val_loss: 0.3920\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3770 - val_loss: 0.3925\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3754 - val_loss: 0.3957\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3756 - val_loss: 0.3916\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3744 - val_loss: 0.3923\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3744 - val_loss: 0.3907\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3745 - val_loss: 0.3911\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3735 - val_loss: 0.3904\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3727 - val_loss: 0.3889\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3724 - val_loss: 0.3886\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3716 - val_loss: 0.3891\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3711 - val_loss: 0.3896\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3715 - val_loss: 0.3877\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3698 - val_loss: 0.3873\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3695 - val_loss: 0.3876\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3694 - val_loss: 0.3865\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3686 - val_loss: 0.3857\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3682 - val_loss: 0.3855\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3676 - val_loss: 0.3848\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3669 - val_loss: 0.3849\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3672 - val_loss: 0.3838\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3661 - val_loss: 0.3845\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3656 - val_loss: 0.3824\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3656 - val_loss: 0.3834\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3647 - val_loss: 0.3820\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3661 - val_loss: 0.3827\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3641 - val_loss: 0.3811\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3635 - val_loss: 0.3810\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3630 - val_loss: 0.3826\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3622 - val_loss: 0.3811\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3620 - val_loss: 0.3815\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3620 - val_loss: 0.3805\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3616 - val_loss: 0.3804\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3609 - val_loss: 0.3798\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3603 - val_loss: 0.3792\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3598 - val_loss: 0.3806\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3601 - val_loss: 0.3791\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3592 - val_loss: 0.3804\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3591 - val_loss: 0.3782\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3594 - val_loss: 0.3789\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3578 - val_loss: 0.3789\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3575 - val_loss: 0.3771\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3594 - val_loss: 0.3771\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3569 - val_loss: 0.3784\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3568 - val_loss: 0.3758\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3561 - val_loss: 0.3762\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3558 - val_loss: 0.3756\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3556 - val_loss: 0.3757\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3550 - val_loss: 0.3750\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3547 - val_loss: 0.3755\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3551 - val_loss: 0.3752\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3538 - val_loss: 0.3741\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3534 - val_loss: 0.3744\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3532 - val_loss: 0.3743\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3540 - val_loss: 0.3772\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3547 - val_loss: 0.3748\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3521 - val_loss: 0.3735\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3522 - val_loss: 0.3738\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3519 - val_loss: 0.3727\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3512 - val_loss: 0.3721\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3509 - val_loss: 0.3716\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3503 - val_loss: 0.3713\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3505 - val_loss: 0.3715\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3503 - val_loss: 0.3738\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3501 - val_loss: 0.3703\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3495 - val_loss: 0.3698\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3498 - val_loss: 0.3701\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3490 - val_loss: 0.3693\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3510 - val_loss: 0.3701\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3486 - val_loss: 0.3691\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3481 - val_loss: 0.3712\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3476 - val_loss: 0.3678\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3474 - val_loss: 0.3679\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3472 - val_loss: 0.3712\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3469 - val_loss: 0.3681\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3465 - val_loss: 0.3676\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3463 - val_loss: 0.3673\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3462 - val_loss: 0.3667\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3456 - val_loss: 0.3668\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3451 - val_loss: 0.3682\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3454 - val_loss: 0.3657\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3450 - val_loss: 0.3671\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3449 - val_loss: 0.3664\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3443 - val_loss: 0.3658\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3441 - val_loss: 0.3667\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3440 - val_loss: 0.3652\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3433 - val_loss: 0.3647\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3437 - val_loss: 0.3723\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3443 - val_loss: 0.3646\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3428 - val_loss: 0.3662\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3427 - val_loss: 0.3662\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3463 - val_loss: 0.3634\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3438 - val_loss: 0.3683\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3432 - val_loss: 0.3648\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3424 - val_loss: 0.3640\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3424 - val_loss: 0.3658\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3478 - val_loss: 0.3627\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3415 - val_loss: 0.3626\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3411 - val_loss: 0.3630\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3406 - val_loss: 0.3620\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3399 - val_loss: 0.3617\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3397 - val_loss: 0.3623\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3397 - val_loss: 0.3637\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3398 - val_loss: 0.3614\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3416 - val_loss: 0.3619\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3411 - val_loss: 0.3605\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3407 - val_loss: 0.3612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3386 - val_loss: 0.3633\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3387 - val_loss: 0.3609\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3384 - val_loss: 0.3608\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3381 - val_loss: 0.3607\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3376 - val_loss: 0.3592\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3374 - val_loss: 0.3604\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3372 - val_loss: 0.3596\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3382 - val_loss: 0.3599\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3364 - val_loss: 0.3632\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3367 - val_loss: 0.3595\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3365 - val_loss: 0.3589\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3367 - val_loss: 0.3593\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3358 - val_loss: 0.3585\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3362 - val_loss: 0.3592\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3356 - val_loss: 0.3581\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3351 - val_loss: 0.3591\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3357 - val_loss: 0.3611\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3368 - val_loss: 0.3575\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3363 - val_loss: 0.3569\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3345 - val_loss: 0.3566\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3344 - val_loss: 0.3564\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3340 - val_loss: 0.3571\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3346 - val_loss: 0.3571\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3335 - val_loss: 0.3565\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3335 - val_loss: 0.3569\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3342 - val_loss: 0.3565\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3333 - val_loss: 0.3562\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3329 - val_loss: 0.3567\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3324 - val_loss: 0.3566\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3346 - val_loss: 0.3552\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3323 - val_loss: 0.3561\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3324 - val_loss: 0.3550\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3326 - val_loss: 0.3548\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3317 - val_loss: 0.3555\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3319 - val_loss: 0.3541\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3312 - val_loss: 0.3557\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3311 - val_loss: 0.3551\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3310 - val_loss: 0.3537\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3310 - val_loss: 0.3536\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3308 - val_loss: 0.3595\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3302 - val_loss: 0.3552\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3302 - val_loss: 0.3535\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3301 - val_loss: 0.3552\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3302 - val_loss: 0.3526\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3311 - val_loss: 0.3532\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3296 - val_loss: 0.3531\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3299 - val_loss: 0.3522\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3321 - val_loss: 0.3526\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3331 - val_loss: 0.3518\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3284 - val_loss: 0.3520\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3283 - val_loss: 0.3551\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3286 - val_loss: 0.3540\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3284 - val_loss: 0.3514\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3284 - val_loss: 0.3579\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3296 - val_loss: 0.3545\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3286 - val_loss: 0.3519\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3277 - val_loss: 0.3501\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3272 - val_loss: 0.3519\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3264 - val_loss: 0.3502\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3267 - val_loss: 0.3499\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3261 - val_loss: 0.3509\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3264 - val_loss: 0.3495\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3271 - val_loss: 0.3500\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3265 - val_loss: 0.3508\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3257 - val_loss: 0.3491\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3261 - val_loss: 0.3494\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3258 - val_loss: 0.3495\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3257 - val_loss: 0.3499\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3253 - val_loss: 0.3492\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3246 - val_loss: 0.3499\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3248 - val_loss: 0.3477\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3244 - val_loss: 0.3489\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3246 - val_loss: 0.3490\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3259 - val_loss: 0.3473\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3239 - val_loss: 0.3481\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3235 - val_loss: 0.3474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3239 - val_loss: 0.3476\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3240 - val_loss: 0.3485\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3237 - val_loss: 0.3466\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3230 - val_loss: 0.3485\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3233 - val_loss: 0.3477\n",
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3225 - val_loss: 0.3489\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3232 - val_loss: 0.3471\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3226 - val_loss: 0.3489\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3247 - val_loss: 0.3465\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3228 - val_loss: 0.3460\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3217 - val_loss: 0.3471\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3218 - val_loss: 0.3466\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3216 - val_loss: 0.3453\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3214 - val_loss: 0.3459\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3211 - val_loss: 0.3453\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3211 - val_loss: 0.3460\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3208 - val_loss: 0.3453\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3208 - val_loss: 0.3441\n",
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3204 - val_loss: 0.3447\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3196 - val_loss: 0.3456\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3237 - val_loss: 0.3456\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3207 - val_loss: 0.3447\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3200 - val_loss: 0.3459\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3196 - val_loss: 0.3438\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3193 - val_loss: 0.3445\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3211 - val_loss: 0.3437\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3196 - val_loss: 0.3452\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3199 - val_loss: 0.3439\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3196 - val_loss: 0.3437\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3188 - val_loss: 0.3438\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3191 - val_loss: 0.3436\n",
      "Epoch 294/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3189 - val_loss: 0.3431\n",
      "Epoch 295/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3191 - val_loss: 0.3426\n",
      "Epoch 296/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3183 - val_loss: 0.3421\n",
      "Epoch 297/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3219 - val_loss: 0.3440\n",
      "Epoch 298/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3191 - val_loss: 0.3449\n",
      "Epoch 299/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3184 - val_loss: 0.3442\n",
      "Epoch 300/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3171 - val_loss: 0.3422\n",
      "Epoch 301/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3173 - val_loss: 0.3422\n",
      "Epoch 302/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3174 - val_loss: 0.3436\n",
      "Epoch 303/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3172 - val_loss: 0.3409\n",
      "Epoch 304/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3167 - val_loss: 0.3417\n",
      "Epoch 305/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3169 - val_loss: 0.3411\n",
      "Epoch 306/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3166 - val_loss: 0.3415\n",
      "Epoch 307/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3163 - val_loss: 0.3439\n",
      "Epoch 308/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3164 - val_loss: 0.3409\n",
      "Epoch 309/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3170 - val_loss: 0.3408\n",
      "Epoch 310/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3169 - val_loss: 0.3415\n",
      "Epoch 311/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3156 - val_loss: 0.3416\n",
      "Epoch 312/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3156 - val_loss: 0.3406\n",
      "Epoch 313/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3159 - val_loss: 0.3402\n",
      "Epoch 314/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3151 - val_loss: 0.3396\n",
      "Epoch 315/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3152 - val_loss: 0.3403\n",
      "Epoch 316/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3154 - val_loss: 0.3390\n",
      "Epoch 317/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3152 - val_loss: 0.3390\n",
      "Epoch 318/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3149 - val_loss: 0.3393\n",
      "Epoch 319/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3143 - val_loss: 0.3416\n",
      "Epoch 320/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3142 - val_loss: 0.3419\n",
      "Epoch 321/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3148 - val_loss: 0.3391\n",
      "Epoch 322/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3157 - val_loss: 0.3401\n",
      "Epoch 323/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3141 - val_loss: 0.3432\n",
      "Epoch 324/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3139 - val_loss: 0.3393\n",
      "Epoch 325/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3137 - val_loss: 0.3402\n",
      "Epoch 326/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3136 - val_loss: 0.3419\n",
      "Epoch 327/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3138 - val_loss: 0.3379\n",
      "Epoch 328/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3149 - val_loss: 0.3444\n",
      "Epoch 329/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3234 - val_loss: 0.3402\n",
      "Epoch 330/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3138 - val_loss: 0.3394\n",
      "Epoch 331/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3132 - val_loss: 0.3375\n",
      "Epoch 332/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3123 - val_loss: 0.3381\n",
      "Epoch 333/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3139 - val_loss: 0.3392\n",
      "Epoch 334/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3121 - val_loss: 0.3374\n",
      "Epoch 335/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3122 - val_loss: 0.3365\n",
      "Epoch 336/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3131 - val_loss: 0.3381\n",
      "Epoch 337/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3122 - val_loss: 0.3368\n",
      "Epoch 338/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3127 - val_loss: 0.3361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3118 - val_loss: 0.3379\n",
      "Epoch 340/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3121 - val_loss: 0.3378\n",
      "Epoch 341/500\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3122 - val_loss: 0.3364\n",
      "Epoch 342/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3117 - val_loss: 0.3394\n",
      "Epoch 343/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3116 - val_loss: 0.3354\n",
      "Epoch 344/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3115 - val_loss: 0.3391\n",
      "Epoch 345/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3111 - val_loss: 0.3358\n",
      "Epoch 346/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3111 - val_loss: 0.3372\n",
      "Epoch 347/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3109 - val_loss: 0.3358\n",
      "Epoch 348/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3111 - val_loss: 0.3373\n",
      "Epoch 349/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3112 - val_loss: 0.3354\n",
      "Epoch 350/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3109 - val_loss: 0.3347\n",
      "Epoch 351/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3110 - val_loss: 0.3348\n",
      "Epoch 352/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3108 - val_loss: 0.3354\n",
      "Epoch 353/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3100 - val_loss: 0.3385\n",
      "Epoch 354/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3098 - val_loss: 0.3346\n",
      "Epoch 355/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3098 - val_loss: 0.3352\n",
      "Epoch 356/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3098 - val_loss: 0.3364\n",
      "Epoch 357/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3101 - val_loss: 0.3411\n",
      "Epoch 358/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3113 - val_loss: 0.3348\n",
      "Epoch 359/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3094 - val_loss: 0.3345\n",
      "Epoch 360/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3094 - val_loss: 0.3338\n",
      "Epoch 361/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3089 - val_loss: 0.3340\n",
      "Epoch 362/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3090 - val_loss: 0.3338\n",
      "Epoch 363/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3098 - val_loss: 0.3353\n",
      "Epoch 364/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3083 - val_loss: 0.3340\n",
      "Epoch 365/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3090 - val_loss: 0.3344\n",
      "Epoch 366/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3097 - val_loss: 0.3337\n",
      "Epoch 367/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3083 - val_loss: 0.3340\n",
      "Epoch 368/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3076 - val_loss: 0.3354\n",
      "Epoch 369/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3082 - val_loss: 0.3326\n",
      "Epoch 370/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3082 - val_loss: 0.3335\n",
      "Epoch 371/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3082 - val_loss: 0.3347\n",
      "Epoch 372/500\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3082 - val_loss: 0.3317\n",
      "Epoch 373/500\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3080 - val_loss: 0.3345\n",
      "Epoch 374/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3075 - val_loss: 0.3327\n",
      "Epoch 375/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3083 - val_loss: 0.3338\n",
      "Epoch 376/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3076 - val_loss: 0.3319\n",
      "Epoch 377/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3084 - val_loss: 0.3328\n",
      "Epoch 378/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3075 - val_loss: 0.3337\n",
      "Epoch 379/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3068 - val_loss: 0.3310\n",
      "Epoch 380/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3071 - val_loss: 0.3330\n",
      "Epoch 381/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3065 - val_loss: 0.3326\n",
      "Epoch 382/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3067 - val_loss: 0.3327\n",
      "Epoch 383/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3064 - val_loss: 0.3346\n",
      "Epoch 384/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3071 - val_loss: 0.3305\n",
      "Epoch 385/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3086 - val_loss: 0.3430\n",
      "Epoch 386/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3194 - val_loss: 0.3328\n",
      "Epoch 387/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3068 - val_loss: 0.3313\n",
      "Epoch 388/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3064 - val_loss: 0.3330\n",
      "Epoch 389/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3062 - val_loss: 0.3309\n",
      "Epoch 390/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3062 - val_loss: 0.3314\n",
      "Epoch 391/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3059 - val_loss: 0.3341\n",
      "Epoch 392/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3062 - val_loss: 0.3321\n",
      "Epoch 393/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3053 - val_loss: 0.3370\n",
      "Epoch 394/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3057 - val_loss: 0.3324\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.4566\n",
      "[CV]  learning_rate=0.002317134505774989, n_hidden=1, n_neurons=45, total= 2.2min\n",
      "[CV] learning_rate=0.002317134505774989, n_hidden=1, n_neurons=45 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.4589 - val_loss: 0.8029\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7488 - val_loss: 0.6688\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7691 - val_loss: 0.6453\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 1.1359 - val_loss: 0.5743\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.9749 - val_loss: 0.6607\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5571 - val_loss: 0.5324\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5143 - val_loss: 0.5117\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4962 - val_loss: 0.4982\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4831 - val_loss: 0.4877\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4734 - val_loss: 0.4789\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4650 - val_loss: 0.4742\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4595 - val_loss: 0.4667\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4539 - val_loss: 0.4619\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4494 - val_loss: 0.4581\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4454 - val_loss: 0.4541\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4417 - val_loss: 0.4506\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4384 - val_loss: 0.4480\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4353 - val_loss: 0.4451\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4326 - val_loss: 0.4429\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4297 - val_loss: 0.4408\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4273 - val_loss: 0.4384\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4248 - val_loss: 0.4372\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4230 - val_loss: 0.4356\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4203 - val_loss: 0.4347\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4190 - val_loss: 0.4312\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4172 - val_loss: 0.4299\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4155 - val_loss: 0.4284\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4139 - val_loss: 0.4271\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4120 - val_loss: 0.4259\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4110 - val_loss: 0.4237\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4094 - val_loss: 0.4239\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4082 - val_loss: 0.4212\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4065 - val_loss: 0.4229\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4058 - val_loss: 0.4197\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4043 - val_loss: 0.4188\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4030 - val_loss: 0.4175\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4020 - val_loss: 0.4155\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4008 - val_loss: 0.4145\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3995 - val_loss: 0.4140\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3985 - val_loss: 0.4126\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3973 - val_loss: 0.4124\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3963 - val_loss: 0.4120\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3955 - val_loss: 0.4104\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3945 - val_loss: 0.4093\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3931 - val_loss: 0.4088\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3923 - val_loss: 0.4089\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3912 - val_loss: 0.4077\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3905 - val_loss: 0.4067\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3896 - val_loss: 0.4060\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3886 - val_loss: 0.4043\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3879 - val_loss: 0.4034\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3868 - val_loss: 0.4027\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3860 - val_loss: 0.4033\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3856 - val_loss: 0.4019\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3846 - val_loss: 0.4012\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3838 - val_loss: 0.4011\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3829 - val_loss: 0.4003\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3824 - val_loss: 0.3993\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3812 - val_loss: 0.3984\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3807 - val_loss: 0.3974\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3794 - val_loss: 0.3974\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3792 - val_loss: 0.3965\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3783 - val_loss: 0.3972\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3777 - val_loss: 0.3950\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3770 - val_loss: 0.3953\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3765 - val_loss: 0.3943\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3757 - val_loss: 0.3954\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3751 - val_loss: 0.3932\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3743 - val_loss: 0.3930\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3738 - val_loss: 0.3928\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3729 - val_loss: 0.3914\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3726 - val_loss: 0.3919\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3720 - val_loss: 0.3901\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3709 - val_loss: 0.3914\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3708 - val_loss: 0.3896\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3702 - val_loss: 0.3901\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3699 - val_loss: 0.3891\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3690 - val_loss: 0.3877\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3686 - val_loss: 0.3887\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3678 - val_loss: 0.3877\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3675 - val_loss: 0.3870\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3670 - val_loss: 0.3866\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3659 - val_loss: 0.3871\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3659 - val_loss: 0.3858\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3650 - val_loss: 0.3853\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3650 - val_loss: 0.3847\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3644 - val_loss: 0.3844\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3637 - val_loss: 0.3844\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3634 - val_loss: 0.3838\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3625 - val_loss: 0.3834\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3623 - val_loss: 0.3835\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3617 - val_loss: 0.3835\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3611 - val_loss: 0.3824\n",
      "Epoch 94/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3610 - val_loss: 0.3823\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3605 - val_loss: 0.3813\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3600 - val_loss: 0.3806\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3596 - val_loss: 0.3808\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3593 - val_loss: 0.3810\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3586 - val_loss: 0.3819\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3584 - val_loss: 0.3801\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3577 - val_loss: 0.3795\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3575 - val_loss: 0.3790\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3573 - val_loss: 0.3788\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3565 - val_loss: 0.3784\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3557 - val_loss: 0.3788\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3559 - val_loss: 0.3790\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3554 - val_loss: 0.3770\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3548 - val_loss: 0.3774\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3547 - val_loss: 0.3769\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3542 - val_loss: 0.3770\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3537 - val_loss: 0.3765\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3533 - val_loss: 0.3762\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3530 - val_loss: 0.3766\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3526 - val_loss: 0.3757\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3518 - val_loss: 0.3774\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3522 - val_loss: 0.3753\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3517 - val_loss: 0.3747\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3511 - val_loss: 0.3749\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3510 - val_loss: 0.3745\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3505 - val_loss: 0.3757\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3503 - val_loss: 0.3747\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3495 - val_loss: 0.3736\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3493 - val_loss: 0.3729\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3489 - val_loss: 0.3730\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3486 - val_loss: 0.3730\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3483 - val_loss: 0.3737\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3481 - val_loss: 0.3715\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3467 - val_loss: 0.3719\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3472 - val_loss: 0.3727\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3466 - val_loss: 0.3739\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3467 - val_loss: 0.3713\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3462 - val_loss: 0.3718\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3459 - val_loss: 0.3717\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3452 - val_loss: 0.3708\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3452 - val_loss: 0.3712\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3442 - val_loss: 0.3705\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3442 - val_loss: 0.3699\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3443 - val_loss: 0.3700\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3434 - val_loss: 0.3695\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3435 - val_loss: 0.3681\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3430 - val_loss: 0.3686\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3428 - val_loss: 0.3684\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3419 - val_loss: 0.3701\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3422 - val_loss: 0.3675\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3417 - val_loss: 0.3683\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3410 - val_loss: 0.3678\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3411 - val_loss: 0.3669\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3406 - val_loss: 0.3663\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3406 - val_loss: 0.3674\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3401 - val_loss: 0.3661\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3396 - val_loss: 0.3669\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3396 - val_loss: 0.3664\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3387 - val_loss: 0.3660\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3385 - val_loss: 0.3666\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3384 - val_loss: 0.3659\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3379 - val_loss: 0.3657\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3377 - val_loss: 0.3668\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3374 - val_loss: 0.3662\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3373 - val_loss: 0.3642\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3369 - val_loss: 0.3642\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3369 - val_loss: 0.3642\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3363 - val_loss: 0.3645\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3365 - val_loss: 0.3652\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3360 - val_loss: 0.3637\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3355 - val_loss: 0.3636\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3354 - val_loss: 0.3636\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3350 - val_loss: 0.3621\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3344 - val_loss: 0.3628\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3345 - val_loss: 0.3631\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3343 - val_loss: 0.3631\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3332 - val_loss: 0.3665\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3340 - val_loss: 0.3616\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3334 - val_loss: 0.3611\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3332 - val_loss: 0.3614\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3329 - val_loss: 0.3619\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3327 - val_loss: 0.3611\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3323 - val_loss: 0.3604\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3322 - val_loss: 0.3602\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3315 - val_loss: 0.3619\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3314 - val_loss: 0.3620\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3313 - val_loss: 0.3632\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3309 - val_loss: 0.3604\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3309 - val_loss: 0.3610\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3302 - val_loss: 0.3603\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3299 - val_loss: 0.3599\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3301 - val_loss: 0.3608\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3300 - val_loss: 0.3586\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3296 - val_loss: 0.3595\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3294 - val_loss: 0.3603\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3287 - val_loss: 0.3593\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3286 - val_loss: 0.3585\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3285 - val_loss: 0.3580\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3280 - val_loss: 0.3588\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3275 - val_loss: 0.3576\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3274 - val_loss: 0.3591\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3276 - val_loss: 0.3565\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3271 - val_loss: 0.3559\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3270 - val_loss: 0.3566\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3267 - val_loss: 0.3563\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3267 - val_loss: 0.3561\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3263 - val_loss: 0.3572\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3256 - val_loss: 0.3572\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3257 - val_loss: 0.3554\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3254 - val_loss: 0.3553\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3250 - val_loss: 0.3560\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3250 - val_loss: 0.3557\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3247 - val_loss: 0.3558\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3241 - val_loss: 0.3568\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3245 - val_loss: 0.3560\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3238 - val_loss: 0.3563\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3239 - val_loss: 0.3555\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3232 - val_loss: 0.3550\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3232 - val_loss: 0.3542\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3228 - val_loss: 0.3538\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3230 - val_loss: 0.3534\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3226 - val_loss: 0.3531\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3220 - val_loss: 0.3573\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3223 - val_loss: 0.3529\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3218 - val_loss: 0.3523\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3216 - val_loss: 0.3522\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3212 - val_loss: 0.3531\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3214 - val_loss: 0.3523\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3206 - val_loss: 0.3532\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3208 - val_loss: 0.3531\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3200 - val_loss: 0.3535\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3200 - val_loss: 0.3523\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3198 - val_loss: 0.3522\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3195 - val_loss: 0.3512\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3193 - val_loss: 0.3512\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3187 - val_loss: 0.3517\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3185 - val_loss: 0.3499\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3182 - val_loss: 0.3511\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3187 - val_loss: 0.3508\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3183 - val_loss: 0.3495\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3180 - val_loss: 0.3505\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3178 - val_loss: 0.3505\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3175 - val_loss: 0.3510\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3175 - val_loss: 0.3509\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3172 - val_loss: 0.3499\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3169 - val_loss: 0.3491\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3164 - val_loss: 0.3494\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3162 - val_loss: 0.3498\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3160 - val_loss: 0.3500\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3163 - val_loss: 0.3485\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3156 - val_loss: 0.3485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3155 - val_loss: 0.3486\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3155 - val_loss: 0.3484\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3155 - val_loss: 0.3479\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3148 - val_loss: 0.3472\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3149 - val_loss: 0.3482\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3147 - val_loss: 0.3472\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3143 - val_loss: 0.3481\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3137 - val_loss: 0.3480\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3134 - val_loss: 0.3494\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3132 - val_loss: 0.3473\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3133 - val_loss: 0.3471\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3130 - val_loss: 0.3481\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3130 - val_loss: 0.3455\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3123 - val_loss: 0.3488\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3128 - val_loss: 0.3474\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3121 - val_loss: 0.3458\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3126 - val_loss: 0.3458\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3121 - val_loss: 0.3462\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3123 - val_loss: 0.3464\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3117 - val_loss: 0.3457\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3122 - val_loss: 0.3442\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3114 - val_loss: 0.3446\n",
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3107 - val_loss: 0.3457\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3108 - val_loss: 0.3443\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3102 - val_loss: 0.3443\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3107 - val_loss: 0.3452\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3099 - val_loss: 0.3453\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3103 - val_loss: 0.3442\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3097 - val_loss: 0.3467\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3098 - val_loss: 0.3445\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3098 - val_loss: 0.3436\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3098 - val_loss: 0.3432\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3092 - val_loss: 0.3458\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3086 - val_loss: 0.3442\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3091 - val_loss: 0.3436\n",
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3086 - val_loss: 0.3435\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3089 - val_loss: 0.3427\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3081 - val_loss: 0.3416\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3081 - val_loss: 0.3443\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3079 - val_loss: 0.3430\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3080 - val_loss: 0.3440\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3078 - val_loss: 0.3453\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3079 - val_loss: 0.3423\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3072 - val_loss: 0.3417\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3076 - val_loss: 0.3421\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3070 - val_loss: 0.3433\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3067 - val_loss: 0.3430\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3068 - val_loss: 0.3424\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.3587\n",
      "[CV]  learning_rate=0.002317134505774989, n_hidden=1, n_neurons=45, total= 1.6min\n",
      "[CV] learning_rate=0.0011709267674750974, n_hidden=1, n_neurons=3 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 4.4263 - val_loss: 2.3826\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 2.0932 - val_loss: 1.6199\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1.4438 - val_loss: 1.1111\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.9598 - val_loss: 0.7905\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7311 - val_loss: 0.6747\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6543 - val_loss: 0.6326\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6251 - val_loss: 0.6129\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6098 - val_loss: 0.6008\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5993 - val_loss: 0.5915\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5906 - val_loss: 0.5836\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5835 - val_loss: 0.5772\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5773 - val_loss: 0.5714\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5721 - val_loss: 0.5661\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5673 - val_loss: 0.5612\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5629 - val_loss: 0.5569\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5589 - val_loss: 0.5527\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5550 - val_loss: 0.5489\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5514 - val_loss: 0.5453\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5480 - val_loss: 0.5421\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5449 - val_loss: 0.5388\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5418 - val_loss: 0.5356\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5390 - val_loss: 0.5325\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5362 - val_loss: 0.5297\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5337 - val_loss: 0.5271\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5312 - val_loss: 0.5248\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5286 - val_loss: 0.5223\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5259 - val_loss: 0.5195\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5234 - val_loss: 0.5171\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5209 - val_loss: 0.5147\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5185 - val_loss: 0.5121\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5161 - val_loss: 0.5097\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5135 - val_loss: 0.5080\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5112 - val_loss: 0.5053\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5090 - val_loss: 0.5033\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5069 - val_loss: 0.5013\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5049 - val_loss: 0.4996\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5028 - val_loss: 0.4980\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5009 - val_loss: 0.4959\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4991 - val_loss: 0.4943\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4975 - val_loss: 0.4926\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4958 - val_loss: 0.4910\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4940 - val_loss: 0.4891\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4923 - val_loss: 0.4879\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4908 - val_loss: 0.4863\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4895 - val_loss: 0.4849\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4886 - val_loss: 0.4840\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4876 - val_loss: 0.4829\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4868 - val_loss: 0.4819\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4860 - val_loss: 0.4809\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4851 - val_loss: 0.4798\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4841 - val_loss: 0.4790\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4839 - val_loss: 0.4784\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4829 - val_loss: 0.4774\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4825 - val_loss: 0.4769\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4816 - val_loss: 0.4760\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4811 - val_loss: 0.4754\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4803 - val_loss: 0.4739\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4801 - val_loss: 0.4737\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4792 - val_loss: 0.4726\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4786 - val_loss: 0.4717\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4787 - val_loss: 0.4718\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4776 - val_loss: 0.4711\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4775 - val_loss: 0.4703\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4767 - val_loss: 0.4696\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4764 - val_loss: 0.4691\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4759 - val_loss: 0.4695\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4754 - val_loss: 0.4686\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4748 - val_loss: 0.4674\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4750 - val_loss: 0.4676\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4742 - val_loss: 0.4668\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4736 - val_loss: 0.4659\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4739 - val_loss: 0.4662\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4731 - val_loss: 0.4660\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4725 - val_loss: 0.4649\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4727 - val_loss: 0.4648\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4720 - val_loss: 0.4641\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4719 - val_loss: 0.4645\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4712 - val_loss: 0.4640\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4709 - val_loss: 0.4631\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4707 - val_loss: 0.4632\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4703 - val_loss: 0.4628\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4701 - val_loss: 0.4627\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4698 - val_loss: 0.4622\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4694 - val_loss: 0.4617\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4688 - val_loss: 0.4607\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4687 - val_loss: 0.4612\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4678 - val_loss: 0.4597\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4681 - val_loss: 0.4605\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4668 - val_loss: 0.4584\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4675 - val_loss: 0.4597\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4664 - val_loss: 0.4589\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4661 - val_loss: 0.4584\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4654 - val_loss: 0.4575\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4656 - val_loss: 0.4573\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4651 - val_loss: 0.4574\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4642 - val_loss: 0.4562\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4645 - val_loss: 0.4565\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4634 - val_loss: 0.4555\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4638 - val_loss: 0.4558\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4630 - val_loss: 0.4556\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4626 - val_loss: 0.4548\n",
      "Epoch 102/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4621 - val_loss: 0.4542\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4618 - val_loss: 0.4536\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4622 - val_loss: 0.4545\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4611 - val_loss: 0.4536\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4609 - val_loss: 0.4530\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4606 - val_loss: 0.4525\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4605 - val_loss: 0.4531\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4598 - val_loss: 0.4521\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4597 - val_loss: 0.4526\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4592 - val_loss: 0.4520\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4589 - val_loss: 0.4518\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4587 - val_loss: 0.4516\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4579 - val_loss: 0.4503\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4584 - val_loss: 0.4514\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4577 - val_loss: 0.4514\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4570 - val_loss: 0.4496\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4575 - val_loss: 0.4505\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4562 - val_loss: 0.4491\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4569 - val_loss: 0.4496\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4554 - val_loss: 0.4479\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4566 - val_loss: 0.4488\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4549 - val_loss: 0.4477\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4556 - val_loss: 0.4480\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4543 - val_loss: 0.4473\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4549 - val_loss: 0.4476\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4536 - val_loss: 0.4462\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4542 - val_loss: 0.4472\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4534 - val_loss: 0.4472\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4527 - val_loss: 0.4458\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4531 - val_loss: 0.4461\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4529 - val_loss: 0.4469\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4519 - val_loss: 0.4452\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4519 - val_loss: 0.4456\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4515 - val_loss: 0.4453\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4514 - val_loss: 0.4455\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4509 - val_loss: 0.4454\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4502 - val_loss: 0.4442\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4510 - val_loss: 0.4449\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4500 - val_loss: 0.4438\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4497 - val_loss: 0.4438\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4495 - val_loss: 0.4445\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4492 - val_loss: 0.4436\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4490 - val_loss: 0.4442\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4486 - val_loss: 0.4434\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4482 - val_loss: 0.4425\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4482 - val_loss: 0.4436\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4479 - val_loss: 0.4426\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4468 - val_loss: 0.4415\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4479 - val_loss: 0.4438\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4472 - val_loss: 0.4426\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4466 - val_loss: 0.4415\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4466 - val_loss: 0.4414\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4460 - val_loss: 0.4410\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4462 - val_loss: 0.4407\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4457 - val_loss: 0.4411\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4455 - val_loss: 0.4411\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4449 - val_loss: 0.4403\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4455 - val_loss: 0.4399\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4448 - val_loss: 0.4396\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4448 - val_loss: 0.4409\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4443 - val_loss: 0.4397\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4434 - val_loss: 0.4380\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4451 - val_loss: 0.4402\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4437 - val_loss: 0.4386\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4437 - val_loss: 0.4392\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4431 - val_loss: 0.4383\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4429 - val_loss: 0.4386\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4427 - val_loss: 0.4381\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4424 - val_loss: 0.4375\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4417 - val_loss: 0.4371\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4429 - val_loss: 0.4375\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4418 - val_loss: 0.4383\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4415 - val_loss: 0.4368\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4413 - val_loss: 0.4368\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4413 - val_loss: 0.4366\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4414 - val_loss: 0.4368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4409 - val_loss: 0.4367\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4405 - val_loss: 0.4364\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4400 - val_loss: 0.4365\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4407 - val_loss: 0.4374\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4402 - val_loss: 0.4358\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4394 - val_loss: 0.4357\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4400 - val_loss: 0.4354\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4389 - val_loss: 0.4350\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4396 - val_loss: 0.4348\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4386 - val_loss: 0.4345\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4397 - val_loss: 0.4352\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4386 - val_loss: 0.4350\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4384 - val_loss: 0.4347\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4384 - val_loss: 0.4355\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4380 - val_loss: 0.4346\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4377 - val_loss: 0.4338\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4384 - val_loss: 0.4349\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4374 - val_loss: 0.4339\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4373 - val_loss: 0.4360\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4373 - val_loss: 0.4342\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4369 - val_loss: 0.4332\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4362 - val_loss: 0.4327\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4379 - val_loss: 0.4340\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4364 - val_loss: 0.4329\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4364 - val_loss: 0.4328\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4357 - val_loss: 0.4321\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4364 - val_loss: 0.4326\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4359 - val_loss: 0.4327\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4349 - val_loss: 0.4312\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4364 - val_loss: 0.4319\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4345 - val_loss: 0.4314\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4354 - val_loss: 0.4329\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4347 - val_loss: 0.4310\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4348 - val_loss: 0.4310\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4352 - val_loss: 0.4323\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4342 - val_loss: 0.4322\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4338 - val_loss: 0.4306\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4350 - val_loss: 0.4327\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4340 - val_loss: 0.4315\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4333 - val_loss: 0.4304\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4343 - val_loss: 0.4310\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4332 - val_loss: 0.4306\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4330 - val_loss: 0.4314\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4331 - val_loss: 0.4310\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4328 - val_loss: 0.4306\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4324 - val_loss: 0.4300\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4319 - val_loss: 0.4297\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4330 - val_loss: 0.4298\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4316 - val_loss: 0.4290\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4325 - val_loss: 0.4293\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4323 - val_loss: 0.4305\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4317 - val_loss: 0.4295\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4317 - val_loss: 0.4289\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4313 - val_loss: 0.4294\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4312 - val_loss: 0.4291\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4304 - val_loss: 0.4279\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4321 - val_loss: 0.4295\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4302 - val_loss: 0.4279\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4318 - val_loss: 0.4288\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4304 - val_loss: 0.4287\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4304 - val_loss: 0.4282\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4300 - val_loss: 0.4294\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4302 - val_loss: 0.4283\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4299 - val_loss: 0.4282\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4295 - val_loss: 0.4272\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4290 - val_loss: 0.4266\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4303 - val_loss: 0.4279\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4292 - val_loss: 0.4272\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4291 - val_loss: 0.4290\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4293 - val_loss: 0.4269\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4288 - val_loss: 0.4268\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4291 - val_loss: 0.4271\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4285 - val_loss: 0.4273\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4278 - val_loss: 0.4255\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4294 - val_loss: 0.4268\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4277 - val_loss: 0.4253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4285 - val_loss: 0.4260\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4281 - val_loss: 0.4275\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4277 - val_loss: 0.4257\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4278 - val_loss: 0.4260\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4267 - val_loss: 0.4253\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4288 - val_loss: 0.4270\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4271 - val_loss: 0.4257\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4263 - val_loss: 0.4244\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4272 - val_loss: 0.4252\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4262 - val_loss: 0.4245\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4274 - val_loss: 0.4250\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4264 - val_loss: 0.4257\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4258 - val_loss: 0.4239\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4267 - val_loss: 0.4262\n",
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4260 - val_loss: 0.4256\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4257 - val_loss: 0.4240\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4258 - val_loss: 0.4240\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4262 - val_loss: 0.4262\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4257 - val_loss: 0.4238\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4257 - val_loss: 0.4254\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4253 - val_loss: 0.4239\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4249 - val_loss: 0.4232\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4259 - val_loss: 0.4244\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4247 - val_loss: 0.4235\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4253 - val_loss: 0.4259\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4249 - val_loss: 0.4242\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4248 - val_loss: 0.4244\n",
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4248 - val_loss: 0.4232\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4243 - val_loss: 0.4230\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4246 - val_loss: 0.4257\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4243 - val_loss: 0.4225\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4243 - val_loss: 0.4240\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4238 - val_loss: 0.4225\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4243 - val_loss: 0.4235\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4235 - val_loss: 0.4220\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4238 - val_loss: 0.4238\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4235 - val_loss: 0.4224\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4231 - val_loss: 0.4216\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4234 - val_loss: 0.4226\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4233 - val_loss: 0.4224\n",
      "Epoch 294/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4223 - val_loss: 0.4214\n",
      "Epoch 295/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4250 - val_loss: 0.4243\n",
      "Epoch 296/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4237 - val_loss: 0.4227\n",
      "Epoch 297/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4221 - val_loss: 0.4208\n",
      "Epoch 298/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4232 - val_loss: 0.4217\n",
      "Epoch 299/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4223 - val_loss: 0.4229\n",
      "Epoch 300/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4219 - val_loss: 0.4208\n",
      "Epoch 301/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4227 - val_loss: 0.4213\n",
      "Epoch 302/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4215 - val_loss: 0.4215\n",
      "Epoch 303/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4219 - val_loss: 0.4209\n",
      "Epoch 304/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4217 - val_loss: 0.4217\n",
      "Epoch 305/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4215 - val_loss: 0.4216\n",
      "Epoch 306/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4213 - val_loss: 0.4200\n",
      "Epoch 307/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4215 - val_loss: 0.4202\n",
      "Epoch 308/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4207 - val_loss: 0.4206\n",
      "Epoch 309/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4219 - val_loss: 0.4207\n",
      "Epoch 310/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4205 - val_loss: 0.4205\n",
      "Epoch 311/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4210 - val_loss: 0.4202\n",
      "Epoch 312/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4199 - val_loss: 0.4186\n",
      "Epoch 313/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4209 - val_loss: 0.4205\n",
      "Epoch 314/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4197 - val_loss: 0.4196\n",
      "Epoch 315/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4215 - val_loss: 0.4209\n",
      "Epoch 316/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4205 - val_loss: 0.4199\n",
      "Epoch 317/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4200 - val_loss: 0.4218\n",
      "Epoch 318/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4200 - val_loss: 0.4194\n",
      "Epoch 319/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4190 - val_loss: 0.4193\n",
      "Epoch 320/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4206 - val_loss: 0.4192\n",
      "Epoch 321/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4192 - val_loss: 0.4186\n",
      "Epoch 322/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4194 - val_loss: 0.4187\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.3878\n",
      "[CV]  learning_rate=0.0011709267674750974, n_hidden=1, n_neurons=3, total= 1.7min\n",
      "[CV] learning_rate=0.0011709267674750974, n_hidden=1, n_neurons=3 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 3.1918 - val_loss: 2.0042\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.6447 - val_loss: 1.2551\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.0932 - val_loss: 0.9005\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.8296 - val_loss: 0.7492\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7185 - val_loss: 0.6815\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6664 - val_loss: 0.6447\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6336 - val_loss: 0.6177\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6090 - val_loss: 0.5964\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5899 - val_loss: 0.5801\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5743 - val_loss: 0.5654\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5614 - val_loss: 0.5544\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5507 - val_loss: 0.5444\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5414 - val_loss: 0.5352\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5335 - val_loss: 0.5282\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5267 - val_loss: 0.5214\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5204 - val_loss: 0.5154\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5149 - val_loss: 0.5109\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5102 - val_loss: 0.5055\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5059 - val_loss: 0.5016\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5020 - val_loss: 0.4982\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4985 - val_loss: 0.4956\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4955 - val_loss: 0.4918\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4928 - val_loss: 0.4897\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4903 - val_loss: 0.4872\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4879 - val_loss: 0.4848\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4857 - val_loss: 0.4826\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4843 - val_loss: 0.4816\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4822 - val_loss: 0.4795\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4810 - val_loss: 0.4783\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4792 - val_loss: 0.4762\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4777 - val_loss: 0.4748\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4768 - val_loss: 0.4749\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4753 - val_loss: 0.4721\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4746 - val_loss: 0.4732\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4732 - val_loss: 0.4710\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4724 - val_loss: 0.4698\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4716 - val_loss: 0.4706\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4705 - val_loss: 0.4679\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4699 - val_loss: 0.4677\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4689 - val_loss: 0.4669\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4679 - val_loss: 0.4662\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4676 - val_loss: 0.4663\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4666 - val_loss: 0.4647\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4660 - val_loss: 0.4646\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4654 - val_loss: 0.4646\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4645 - val_loss: 0.4626\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4637 - val_loss: 0.4616\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4638 - val_loss: 0.4617\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4625 - val_loss: 0.4611\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4621 - val_loss: 0.4600\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4618 - val_loss: 0.4614\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4611 - val_loss: 0.4593\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4606 - val_loss: 0.4591\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4598 - val_loss: 0.4581\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4597 - val_loss: 0.4580\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4588 - val_loss: 0.4578\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4581 - val_loss: 0.4564\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4579 - val_loss: 0.4558\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4575 - val_loss: 0.4564\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4566 - val_loss: 0.4561\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4558 - val_loss: 0.4543\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4562 - val_loss: 0.4548\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4552 - val_loss: 0.4540\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4545 - val_loss: 0.4533\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4541 - val_loss: 0.4530\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4539 - val_loss: 0.4548\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4531 - val_loss: 0.4530\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4532 - val_loss: 0.4523\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4518 - val_loss: 0.4507\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4518 - val_loss: 0.4506\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4514 - val_loss: 0.4510\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4500 - val_loss: 0.4493\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4502 - val_loss: 0.4491\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4498 - val_loss: 0.4498\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4488 - val_loss: 0.4482\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4482 - val_loss: 0.4470\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4480 - val_loss: 0.4470\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4474 - val_loss: 0.4469\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4465 - val_loss: 0.4473\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4459 - val_loss: 0.4457\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4455 - val_loss: 0.4454\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4452 - val_loss: 0.4447\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4445 - val_loss: 0.4461\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4440 - val_loss: 0.4440\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4436 - val_loss: 0.4440\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4427 - val_loss: 0.4427\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4426 - val_loss: 0.4426\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4416 - val_loss: 0.4420\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4417 - val_loss: 0.4414\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4409 - val_loss: 0.4425\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4403 - val_loss: 0.4405\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4401 - val_loss: 0.4412\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4393 - val_loss: 0.4400\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4391 - val_loss: 0.4401\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4380 - val_loss: 0.4388\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4386 - val_loss: 0.4404\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4375 - val_loss: 0.4387\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4369 - val_loss: 0.4380\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4368 - val_loss: 0.4379\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4359 - val_loss: 0.4367\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4358 - val_loss: 0.4375\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4348 - val_loss: 0.4360\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4353 - val_loss: 0.4363\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4342 - val_loss: 0.4363\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4336 - val_loss: 0.4347\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4336 - val_loss: 0.4352\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4328 - val_loss: 0.4351\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4323 - val_loss: 0.4339\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4320 - val_loss: 0.4346\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4316 - val_loss: 0.4327\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4316 - val_loss: 0.4337\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4304 - val_loss: 0.4324\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4310 - val_loss: 0.4338\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4302 - val_loss: 0.4323\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4295 - val_loss: 0.4320\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4288 - val_loss: 0.4302\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4292 - val_loss: 0.4307\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4283 - val_loss: 0.4300\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4280 - val_loss: 0.4298\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4278 - val_loss: 0.4306\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4274 - val_loss: 0.4295\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4269 - val_loss: 0.4305\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4264 - val_loss: 0.4294\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4259 - val_loss: 0.4280\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4260 - val_loss: 0.4295\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4256 - val_loss: 0.4281\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4250 - val_loss: 0.4281\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4247 - val_loss: 0.4271\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4245 - val_loss: 0.4275\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4241 - val_loss: 0.4268\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4240 - val_loss: 0.4276\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4233 - val_loss: 0.4264\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4229 - val_loss: 0.4255\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4231 - val_loss: 0.4257\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4225 - val_loss: 0.4253\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4220 - val_loss: 0.4246\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4214 - val_loss: 0.4242\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4221 - val_loss: 0.4244\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4212 - val_loss: 0.4245\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4212 - val_loss: 0.4251\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4208 - val_loss: 0.4235\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4204 - val_loss: 0.4235\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4200 - val_loss: 0.4232\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4196 - val_loss: 0.4224\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4195 - val_loss: 0.4221\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4197 - val_loss: 0.4237\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4192 - val_loss: 0.4220\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4188 - val_loss: 0.4223\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4183 - val_loss: 0.4214\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4182 - val_loss: 0.4220\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4179 - val_loss: 0.4217\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4176 - val_loss: 0.4206\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4175 - val_loss: 0.4221\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4172 - val_loss: 0.4207\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4169 - val_loss: 0.4202\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4167 - val_loss: 0.4205\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4164 - val_loss: 0.4199\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4160 - val_loss: 0.4198\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4158 - val_loss: 0.4192\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4160 - val_loss: 0.4200\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4157 - val_loss: 0.4189\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4149 - val_loss: 0.4182\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4158 - val_loss: 0.4187\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4148 - val_loss: 0.4185\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4146 - val_loss: 0.4181\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4144 - val_loss: 0.4189\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4142 - val_loss: 0.4176\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4141 - val_loss: 0.4182\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4139 - val_loss: 0.4170\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4137 - val_loss: 0.4184\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4135 - val_loss: 0.4171\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4131 - val_loss: 0.4172\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4130 - val_loss: 0.4160\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4126 - val_loss: 0.4156\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4125 - val_loss: 0.4161\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4124 - val_loss: 0.4164\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4122 - val_loss: 0.4154\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4117 - val_loss: 0.4146\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4121 - val_loss: 0.4151\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4115 - val_loss: 0.4148\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4112 - val_loss: 0.4162\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4111 - val_loss: 0.4149\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4113 - val_loss: 0.4150\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4107 - val_loss: 0.4152\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4102 - val_loss: 0.4137\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4110 - val_loss: 0.4142\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4101 - val_loss: 0.4146\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4103 - val_loss: 0.4141\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4097 - val_loss: 0.4137\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4100 - val_loss: 0.4135\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4093 - val_loss: 0.4134\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4096 - val_loss: 0.4131\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4092 - val_loss: 0.4133\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4092 - val_loss: 0.4128\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4087 - val_loss: 0.4128\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4087 - val_loss: 0.4131\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4084 - val_loss: 0.4129\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4087 - val_loss: 0.4127\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4081 - val_loss: 0.4134\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4081 - val_loss: 0.4119\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4082 - val_loss: 0.4118\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4079 - val_loss: 0.4124\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4078 - val_loss: 0.4119\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4074 - val_loss: 0.4114\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4074 - val_loss: 0.4112\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4073 - val_loss: 0.4118\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4071 - val_loss: 0.4105\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4072 - val_loss: 0.4112\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4066 - val_loss: 0.4115\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4070 - val_loss: 0.4106\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4063 - val_loss: 0.4105\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4066 - val_loss: 0.4113\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4063 - val_loss: 0.4103\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4060 - val_loss: 0.4100\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4058 - val_loss: 0.4124\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4064 - val_loss: 0.4105\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4058 - val_loss: 0.4103\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4057 - val_loss: 0.4104\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4055 - val_loss: 0.4102\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4055 - val_loss: 0.4092\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4052 - val_loss: 0.4096\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4051 - val_loss: 0.4105\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4052 - val_loss: 0.4103\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4049 - val_loss: 0.4100\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4048 - val_loss: 0.4095\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4048 - val_loss: 0.4094\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4043 - val_loss: 0.4097\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4046 - val_loss: 0.4090\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4042 - val_loss: 0.4090\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4048 - val_loss: 0.4099\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4044 - val_loss: 0.4086\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4035 - val_loss: 0.4088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4042 - val_loss: 0.4089\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4040 - val_loss: 0.4092\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4036 - val_loss: 0.4093\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4041 - val_loss: 0.4086\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4035 - val_loss: 0.4086\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4035 - val_loss: 0.4086\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4033 - val_loss: 0.4082\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4033 - val_loss: 0.4079\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4032 - val_loss: 0.4090\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4032 - val_loss: 0.4084\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4029 - val_loss: 0.4084\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4026 - val_loss: 0.4092\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4032 - val_loss: 0.4084\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4028 - val_loss: 0.4082\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4026 - val_loss: 0.4084\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4027 - val_loss: 0.4077\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4024 - val_loss: 0.4080\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4027 - val_loss: 0.4080\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4023 - val_loss: 0.4078\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4023 - val_loss: 0.4070\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4022 - val_loss: 0.4072\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4020 - val_loss: 0.4084\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4023 - val_loss: 0.4078\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4019 - val_loss: 0.4078\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4021 - val_loss: 0.4087\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4023 - val_loss: 0.4075\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4018 - val_loss: 0.4075\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4019 - val_loss: 0.4073\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4017 - val_loss: 0.4068\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4017 - val_loss: 0.4077\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4017 - val_loss: 0.4077\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4017 - val_loss: 0.4071\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4015 - val_loss: 0.4067\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4015 - val_loss: 0.4066\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4014 - val_loss: 0.4067\n",
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4010 - val_loss: 0.4073\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4011 - val_loss: 0.4069\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4012 - val_loss: 0.4066\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4011 - val_loss: 0.4070\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4010 - val_loss: 0.4065\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4010 - val_loss: 0.4063\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4006 - val_loss: 0.4070\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4011 - val_loss: 0.4069\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4009 - val_loss: 0.4063\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4007 - val_loss: 0.4066\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4007 - val_loss: 0.4057\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4005 - val_loss: 0.4060\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4006 - val_loss: 0.4062\n",
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4005 - val_loss: 0.4065\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4005 - val_loss: 0.4065\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4003 - val_loss: 0.4057\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4004 - val_loss: 0.4072\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4005 - val_loss: 0.4061\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4004 - val_loss: 0.4058\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4002 - val_loss: 0.4061\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4003 - val_loss: 0.4057\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4002 - val_loss: 0.4065\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4003 - val_loss: 0.4062\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4003 - val_loss: 0.4065\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4003 - val_loss: 0.4054\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3998 - val_loss: 0.4066\n",
      "Epoch 294/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4001 - val_loss: 0.4058\n",
      "Epoch 295/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4001 - val_loss: 0.4060\n",
      "Epoch 296/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4000 - val_loss: 0.4055\n",
      "Epoch 297/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4001 - val_loss: 0.4052\n",
      "Epoch 298/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3998 - val_loss: 0.4058\n",
      "Epoch 299/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3997 - val_loss: 0.4052\n",
      "Epoch 300/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3997 - val_loss: 0.4067\n",
      "Epoch 301/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3999 - val_loss: 0.4056\n",
      "Epoch 302/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3995 - val_loss: 0.4056\n",
      "Epoch 303/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3997 - val_loss: 0.4057\n",
      "Epoch 304/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3996 - val_loss: 0.4059\n",
      "Epoch 305/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3995 - val_loss: 0.4054\n",
      "Epoch 306/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3993 - val_loss: 0.4057\n",
      "Epoch 307/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3995 - val_loss: 0.4058\n",
      "Epoch 308/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3994 - val_loss: 0.4055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3994 - val_loss: 0.4050\n",
      "Epoch 310/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3994 - val_loss: 0.4050\n",
      "Epoch 311/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3997 - val_loss: 0.4058\n",
      "Epoch 312/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3995 - val_loss: 0.4052\n",
      "Epoch 313/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3993 - val_loss: 0.4056\n",
      "Epoch 314/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3992 - val_loss: 0.4058\n",
      "Epoch 315/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3989 - val_loss: 0.4054\n",
      "Epoch 316/500\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3991 - val_loss: 0.4053\n",
      "Epoch 317/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3991 - val_loss: 0.4046\n",
      "Epoch 318/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3991 - val_loss: 0.4051\n",
      "Epoch 319/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3989 - val_loss: 0.4050\n",
      "Epoch 320/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3991 - val_loss: 0.4044\n",
      "Epoch 321/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3988 - val_loss: 0.4045\n",
      "Epoch 322/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3986 - val_loss: 0.4052\n",
      "Epoch 323/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3989 - val_loss: 0.4048\n",
      "Epoch 324/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3987 - val_loss: 0.4045\n",
      "Epoch 325/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3990 - val_loss: 0.4046\n",
      "Epoch 326/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3987 - val_loss: 0.4054\n",
      "Epoch 327/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3986 - val_loss: 0.4054\n",
      "Epoch 328/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3988 - val_loss: 0.4050\n",
      "Epoch 329/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3987 - val_loss: 0.4047\n",
      "Epoch 330/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3987 - val_loss: 0.4046\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.4845\n",
      "[CV]  learning_rate=0.0011709267674750974, n_hidden=1, n_neurons=3, total= 1.8min\n",
      "[CV] learning_rate=0.0011709267674750974, n_hidden=1, n_neurons=3 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 3.2345 - val_loss: 1.8763\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.4698 - val_loss: 1.1136\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.9470 - val_loss: 0.7697\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7025 - val_loss: 0.6359\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6151 - val_loss: 0.5989\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5857 - val_loss: 0.5855\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5708 - val_loss: 0.5762\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5615 - val_loss: 0.5691\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5528 - val_loss: 0.5623\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5458 - val_loss: 0.5564\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5395 - val_loss: 0.5504\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5339 - val_loss: 0.5451\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5292 - val_loss: 0.5404\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5248 - val_loss: 0.5361\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5207 - val_loss: 0.5324\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5170 - val_loss: 0.5281\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5139 - val_loss: 0.5248\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5107 - val_loss: 0.5216\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5078 - val_loss: 0.5185\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5053 - val_loss: 0.5161\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5025 - val_loss: 0.5129\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5010 - val_loss: 0.5107\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4982 - val_loss: 0.5086\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4960 - val_loss: 0.5062\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4945 - val_loss: 0.5045\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4924 - val_loss: 0.5023\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4918 - val_loss: 0.5009\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4890 - val_loss: 0.4995\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4884 - val_loss: 0.4979\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4866 - val_loss: 0.4969\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4849 - val_loss: 0.4952\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4839 - val_loss: 0.4943\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4824 - val_loss: 0.4937\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4816 - val_loss: 0.4925\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4803 - val_loss: 0.4918\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4793 - val_loss: 0.4901\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4788 - val_loss: 0.4895\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4773 - val_loss: 0.4879\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4774 - val_loss: 0.4878\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4763 - val_loss: 0.4866\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4765 - val_loss: 0.4864\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4746 - val_loss: 0.4853\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4743 - val_loss: 0.4847\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4729 - val_loss: 0.4835\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4726 - val_loss: 0.4843\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4716 - val_loss: 0.4820\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4720 - val_loss: 0.4818\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4704 - val_loss: 0.4808\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4704 - val_loss: 0.4810\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4694 - val_loss: 0.4791\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4704 - val_loss: 0.4802\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4686 - val_loss: 0.4784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4681 - val_loss: 0.4784\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4672 - val_loss: 0.4773\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4681 - val_loss: 0.4773\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4660 - val_loss: 0.4763\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4669 - val_loss: 0.4769\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4655 - val_loss: 0.4756\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4651 - val_loss: 0.4761\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4644 - val_loss: 0.4750\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4640 - val_loss: 0.4742\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4632 - val_loss: 0.4733\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4639 - val_loss: 0.4732\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4625 - val_loss: 0.4719\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4639 - val_loss: 0.4726\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4629 - val_loss: 0.4711\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4644 - val_loss: 0.4725\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4623 - val_loss: 0.4702\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4617 - val_loss: 0.4704\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4601 - val_loss: 0.4697\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4602 - val_loss: 0.4698\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4594 - val_loss: 0.4688\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4591 - val_loss: 0.4684\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4586 - val_loss: 0.4680\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4580 - val_loss: 0.4679\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4584 - val_loss: 0.4677\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4575 - val_loss: 0.4667\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4573 - val_loss: 0.4666\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4566 - val_loss: 0.4664\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4562 - val_loss: 0.4654\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4559 - val_loss: 0.4651\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4556 - val_loss: 0.4643\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4551 - val_loss: 0.4640\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4548 - val_loss: 0.4645\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4540 - val_loss: 0.4648\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4541 - val_loss: 0.4634\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4535 - val_loss: 0.4630\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4531 - val_loss: 0.4623\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4526 - val_loss: 0.4616\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4523 - val_loss: 0.4614\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4517 - val_loss: 0.4610\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4515 - val_loss: 0.4614\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4511 - val_loss: 0.4603\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4503 - val_loss: 0.4592\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4504 - val_loss: 0.4601\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4498 - val_loss: 0.4590\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4492 - val_loss: 0.4580\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4491 - val_loss: 0.4579\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4484 - val_loss: 0.4579\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4481 - val_loss: 0.4568\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4476 - val_loss: 0.4564\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4474 - val_loss: 0.4567\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4468 - val_loss: 0.4557\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4469 - val_loss: 0.4555\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4460 - val_loss: 0.4548\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4457 - val_loss: 0.4546\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4453 - val_loss: 0.4543\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4449 - val_loss: 0.4536\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4447 - val_loss: 0.4534\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4440 - val_loss: 0.4528\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4450 - val_loss: 0.4532\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4433 - val_loss: 0.4523\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4433 - val_loss: 0.4520\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4423 - val_loss: 0.4505\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4433 - val_loss: 0.4509\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4416 - val_loss: 0.4498\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4422 - val_loss: 0.4500\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4409 - val_loss: 0.4496\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4404 - val_loss: 0.4488\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4399 - val_loss: 0.4486\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4394 - val_loss: 0.4474\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4394 - val_loss: 0.4473\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4386 - val_loss: 0.4473\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4383 - val_loss: 0.4471\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4378 - val_loss: 0.4462\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4377 - val_loss: 0.4459\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4371 - val_loss: 0.4459\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4366 - val_loss: 0.4447\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4376 - val_loss: 0.4452\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4366 - val_loss: 0.4439\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4370 - val_loss: 0.4447\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4357 - val_loss: 0.4431\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4353 - val_loss: 0.4435\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4342 - val_loss: 0.4429\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4345 - val_loss: 0.4433\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4335 - val_loss: 0.4417\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4341 - val_loss: 0.4417\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4326 - val_loss: 0.4409\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4321 - val_loss: 0.4408\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4315 - val_loss: 0.4408\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4311 - val_loss: 0.4405\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4305 - val_loss: 0.4396\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4302 - val_loss: 0.4402\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4297 - val_loss: 0.4391\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4292 - val_loss: 0.4386\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4289 - val_loss: 0.4385\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4285 - val_loss: 0.4377\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4279 - val_loss: 0.4372\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4277 - val_loss: 0.4370\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4270 - val_loss: 0.4358\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4272 - val_loss: 0.4363\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4263 - val_loss: 0.4359\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4256 - val_loss: 0.4351\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4255 - val_loss: 0.4353\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4249 - val_loss: 0.4344\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4244 - val_loss: 0.4346\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4242 - val_loss: 0.4340\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4236 - val_loss: 0.4332\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4234 - val_loss: 0.4331\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4228 - val_loss: 0.4325\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4225 - val_loss: 0.4327\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4218 - val_loss: 0.4321\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4217 - val_loss: 0.4316\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4210 - val_loss: 0.4311\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4205 - val_loss: 0.4308\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4203 - val_loss: 0.4305\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4198 - val_loss: 0.4300\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4193 - val_loss: 0.4297\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4186 - val_loss: 0.4306\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4185 - val_loss: 0.4293\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4179 - val_loss: 0.4290\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4175 - val_loss: 0.4280\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4171 - val_loss: 0.4276\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4166 - val_loss: 0.4272\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4165 - val_loss: 0.4272\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4158 - val_loss: 0.4258\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4154 - val_loss: 0.4266\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4148 - val_loss: 0.4258\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4149 - val_loss: 0.4254\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4140 - val_loss: 0.4259\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4136 - val_loss: 0.4244\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4134 - val_loss: 0.4248\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4128 - val_loss: 0.4240\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4127 - val_loss: 0.4239\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4120 - val_loss: 0.4238\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4120 - val_loss: 0.4234\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4112 - val_loss: 0.4232\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4111 - val_loss: 0.4229\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4104 - val_loss: 0.4222\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4102 - val_loss: 0.4218\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4093 - val_loss: 0.4214\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4096 - val_loss: 0.4211\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4086 - val_loss: 0.4207\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4085 - val_loss: 0.4206\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4079 - val_loss: 0.4206\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4080 - val_loss: 0.4203\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4070 - val_loss: 0.4193\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4071 - val_loss: 0.4196\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4065 - val_loss: 0.4188\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4060 - val_loss: 0.4187\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4055 - val_loss: 0.4182\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4054 - val_loss: 0.4179\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4047 - val_loss: 0.4177\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4043 - val_loss: 0.4180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4043 - val_loss: 0.4173\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4038 - val_loss: 0.4172\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4035 - val_loss: 0.4170\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4029 - val_loss: 0.4164\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4027 - val_loss: 0.4164\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4022 - val_loss: 0.4161\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4021 - val_loss: 0.4152\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4014 - val_loss: 0.4148\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4015 - val_loss: 0.4156\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4007 - val_loss: 0.4152\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4005 - val_loss: 0.4143\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4000 - val_loss: 0.4145\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3997 - val_loss: 0.4139\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3993 - val_loss: 0.4139\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3992 - val_loss: 0.4138\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3987 - val_loss: 0.4134\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3984 - val_loss: 0.4125\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3981 - val_loss: 0.4130\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3977 - val_loss: 0.4126\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3976 - val_loss: 0.4127\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3970 - val_loss: 0.4125\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3968 - val_loss: 0.4122\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3963 - val_loss: 0.4128\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3961 - val_loss: 0.4114\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3956 - val_loss: 0.4108\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3954 - val_loss: 0.4104\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3949 - val_loss: 0.4114\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3945 - val_loss: 0.4101\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3942 - val_loss: 0.4097\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3942 - val_loss: 0.4095\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3937 - val_loss: 0.4096\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3932 - val_loss: 0.4089\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3931 - val_loss: 0.4096\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3928 - val_loss: 0.4089\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3924 - val_loss: 0.4089\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3921 - val_loss: 0.4083\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3919 - val_loss: 0.4085\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3916 - val_loss: 0.4080\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3913 - val_loss: 0.4080\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3909 - val_loss: 0.4071\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3906 - val_loss: 0.4074\n",
      "Epoch 246/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3905 - val_loss: 0.4068\n",
      "Epoch 247/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3901 - val_loss: 0.4069\n",
      "Epoch 248/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3899 - val_loss: 0.4070\n",
      "Epoch 249/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3895 - val_loss: 0.4070\n",
      "Epoch 250/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3893 - val_loss: 0.4065\n",
      "Epoch 251/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3890 - val_loss: 0.4063\n",
      "Epoch 252/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3887 - val_loss: 0.4060\n",
      "Epoch 253/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3886 - val_loss: 0.4056\n",
      "Epoch 254/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3884 - val_loss: 0.4055\n",
      "Epoch 255/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3882 - val_loss: 0.4057\n",
      "Epoch 256/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3878 - val_loss: 0.4047\n",
      "Epoch 257/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3877 - val_loss: 0.4054\n",
      "Epoch 258/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3873 - val_loss: 0.4057\n",
      "Epoch 259/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3872 - val_loss: 0.4046\n",
      "Epoch 260/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3870 - val_loss: 0.4044\n",
      "Epoch 261/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3867 - val_loss: 0.4042\n",
      "Epoch 262/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3866 - val_loss: 0.4045\n",
      "Epoch 263/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3864 - val_loss: 0.4039\n",
      "Epoch 264/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3861 - val_loss: 0.4042\n",
      "Epoch 265/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3859 - val_loss: 0.4038\n",
      "Epoch 266/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3857 - val_loss: 0.4042\n",
      "Epoch 267/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3855 - val_loss: 0.4041\n",
      "Epoch 268/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3854 - val_loss: 0.4032\n",
      "Epoch 269/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3850 - val_loss: 0.4039\n",
      "Epoch 270/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3849 - val_loss: 0.4034\n",
      "Epoch 271/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3845 - val_loss: 0.4028\n",
      "Epoch 272/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3845 - val_loss: 0.4025\n",
      "Epoch 273/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3843 - val_loss: 0.4025\n",
      "Epoch 274/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3839 - val_loss: 0.4019\n",
      "Epoch 275/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3838 - val_loss: 0.4029\n",
      "Epoch 276/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3837 - val_loss: 0.4019\n",
      "Epoch 277/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3835 - val_loss: 0.4023\n",
      "Epoch 278/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3833 - val_loss: 0.4017\n",
      "Epoch 279/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3832 - val_loss: 0.4021\n",
      "Epoch 280/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3830 - val_loss: 0.4020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3828 - val_loss: 0.4014\n",
      "Epoch 282/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3825 - val_loss: 0.4007\n",
      "Epoch 283/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3825 - val_loss: 0.4022\n",
      "Epoch 284/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3824 - val_loss: 0.4022\n",
      "Epoch 285/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3821 - val_loss: 0.4017\n",
      "Epoch 286/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3820 - val_loss: 0.4013\n",
      "Epoch 287/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3817 - val_loss: 0.4007\n",
      "Epoch 288/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3817 - val_loss: 0.4008\n",
      "Epoch 289/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3814 - val_loss: 0.4010\n",
      "Epoch 290/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3814 - val_loss: 0.4005\n",
      "Epoch 291/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3811 - val_loss: 0.4005\n",
      "Epoch 292/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3809 - val_loss: 0.4012\n",
      "Epoch 293/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3810 - val_loss: 0.4006\n",
      "Epoch 294/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3808 - val_loss: 0.4001\n",
      "Epoch 295/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3806 - val_loss: 0.3998\n",
      "Epoch 296/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3803 - val_loss: 0.3999\n",
      "Epoch 297/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3804 - val_loss: 0.3997\n",
      "Epoch 298/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3801 - val_loss: 0.3991\n",
      "Epoch 299/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3800 - val_loss: 0.4003\n",
      "Epoch 300/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3798 - val_loss: 0.4001\n",
      "Epoch 301/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3796 - val_loss: 0.4000\n",
      "Epoch 302/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3795 - val_loss: 0.3994\n",
      "Epoch 303/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3794 - val_loss: 0.3996\n",
      "Epoch 304/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3793 - val_loss: 0.3994\n",
      "Epoch 305/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3792 - val_loss: 0.3992\n",
      "Epoch 306/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3790 - val_loss: 0.3990\n",
      "Epoch 307/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3789 - val_loss: 0.3991\n",
      "Epoch 308/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3789 - val_loss: 0.3992\n",
      "Epoch 309/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3788 - val_loss: 0.3987\n",
      "Epoch 310/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3785 - val_loss: 0.3984\n",
      "Epoch 311/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3784 - val_loss: 0.3987\n",
      "Epoch 312/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3783 - val_loss: 0.3991\n",
      "Epoch 313/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3780 - val_loss: 0.3992\n",
      "Epoch 314/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3780 - val_loss: 0.3989\n",
      "Epoch 315/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3779 - val_loss: 0.3982\n",
      "Epoch 316/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3779 - val_loss: 0.3985\n",
      "Epoch 317/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3776 - val_loss: 0.3981\n",
      "Epoch 318/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3776 - val_loss: 0.3978\n",
      "Epoch 319/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3773 - val_loss: 0.3983\n",
      "Epoch 320/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3771 - val_loss: 0.3976\n",
      "Epoch 321/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3771 - val_loss: 0.3983\n",
      "Epoch 322/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3768 - val_loss: 0.3974\n",
      "Epoch 323/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3770 - val_loss: 0.3979\n",
      "Epoch 324/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3768 - val_loss: 0.3973\n",
      "Epoch 325/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3767 - val_loss: 0.3970\n",
      "Epoch 326/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3764 - val_loss: 0.3974\n",
      "Epoch 327/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3763 - val_loss: 0.3972\n",
      "Epoch 328/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3763 - val_loss: 0.3970\n",
      "Epoch 329/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3763 - val_loss: 0.3968\n",
      "Epoch 330/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3761 - val_loss: 0.3972\n",
      "Epoch 331/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3760 - val_loss: 0.3966\n",
      "Epoch 332/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3758 - val_loss: 0.3965\n",
      "Epoch 333/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3756 - val_loss: 0.3965\n",
      "Epoch 334/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3756 - val_loss: 0.3962\n",
      "Epoch 335/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3755 - val_loss: 0.3972\n",
      "Epoch 336/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3754 - val_loss: 0.3970\n",
      "Epoch 337/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3753 - val_loss: 0.3965\n",
      "Epoch 338/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3752 - val_loss: 0.3967\n",
      "Epoch 339/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3752 - val_loss: 0.3960\n",
      "Epoch 340/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3747 - val_loss: 0.3967\n",
      "Epoch 341/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3747 - val_loss: 0.3958\n",
      "Epoch 342/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3746 - val_loss: 0.3968\n",
      "Epoch 343/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3748 - val_loss: 0.3959\n",
      "Epoch 344/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3745 - val_loss: 0.3959\n",
      "Epoch 345/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3743 - val_loss: 0.3966\n",
      "Epoch 346/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3741 - val_loss: 0.3961\n",
      "Epoch 347/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3742 - val_loss: 0.3961\n",
      "Epoch 348/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3740 - val_loss: 0.3958\n",
      "Epoch 349/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3738 - val_loss: 0.3957\n",
      "Epoch 350/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3737 - val_loss: 0.3951\n",
      "Epoch 351/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3734 - val_loss: 0.3959\n",
      "Epoch 352/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3737 - val_loss: 0.3950\n",
      "Epoch 353/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3735 - val_loss: 0.3950\n",
      "Epoch 354/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3733 - val_loss: 0.3962\n",
      "Epoch 355/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3734 - val_loss: 0.3956\n",
      "Epoch 356/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3732 - val_loss: 0.3952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3730 - val_loss: 0.3951\n",
      "Epoch 358/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3729 - val_loss: 0.3947\n",
      "Epoch 359/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3728 - val_loss: 0.3946\n",
      "Epoch 360/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3728 - val_loss: 0.3947\n",
      "Epoch 361/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3726 - val_loss: 0.3945\n",
      "Epoch 362/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3725 - val_loss: 0.3947\n",
      "Epoch 363/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3725 - val_loss: 0.3942\n",
      "Epoch 364/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3724 - val_loss: 0.3949\n",
      "Epoch 365/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3723 - val_loss: 0.3939\n",
      "Epoch 366/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3721 - val_loss: 0.3940\n",
      "Epoch 367/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3721 - val_loss: 0.3940\n",
      "Epoch 368/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3720 - val_loss: 0.3939\n",
      "Epoch 369/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3718 - val_loss: 0.3943\n",
      "Epoch 370/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3717 - val_loss: 0.3940\n",
      "Epoch 371/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3717 - val_loss: 0.3942\n",
      "Epoch 372/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3714 - val_loss: 0.3936\n",
      "Epoch 373/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3713 - val_loss: 0.3942\n",
      "Epoch 374/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3715 - val_loss: 0.3938\n",
      "Epoch 375/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3713 - val_loss: 0.3939\n",
      "Epoch 376/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3712 - val_loss: 0.3936\n",
      "Epoch 377/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3713 - val_loss: 0.3936\n",
      "Epoch 378/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3710 - val_loss: 0.3938\n",
      "Epoch 379/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3711 - val_loss: 0.3936\n",
      "Epoch 380/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3709 - val_loss: 0.3935\n",
      "Epoch 381/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3709 - val_loss: 0.3935\n",
      "Epoch 382/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3707 - val_loss: 0.3930\n",
      "Epoch 383/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3707 - val_loss: 0.3933\n",
      "Epoch 384/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3706 - val_loss: 0.3931\n",
      "Epoch 385/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3703 - val_loss: 0.3931\n",
      "Epoch 386/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3702 - val_loss: 0.3928\n",
      "Epoch 387/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3702 - val_loss: 0.3930\n",
      "Epoch 388/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3702 - val_loss: 0.3930\n",
      "Epoch 389/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3699 - val_loss: 0.3941\n",
      "Epoch 390/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3702 - val_loss: 0.3933\n",
      "Epoch 391/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3700 - val_loss: 0.3934\n",
      "Epoch 392/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3697 - val_loss: 0.3934\n",
      "Epoch 393/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3697 - val_loss: 0.3930\n",
      "Epoch 394/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3694 - val_loss: 0.3938\n",
      "Epoch 395/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3696 - val_loss: 0.3921\n",
      "Epoch 396/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3694 - val_loss: 0.3932\n",
      "Epoch 397/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3694 - val_loss: 0.3921\n",
      "Epoch 398/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3693 - val_loss: 0.3933\n",
      "Epoch 399/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3693 - val_loss: 0.3928\n",
      "Epoch 400/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3693 - val_loss: 0.3924\n",
      "Epoch 401/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3691 - val_loss: 0.3930\n",
      "Epoch 402/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3691 - val_loss: 0.3928\n",
      "Epoch 403/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3689 - val_loss: 0.3932\n",
      "Epoch 404/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3689 - val_loss: 0.3926\n",
      "Epoch 405/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3689 - val_loss: 0.3924\n",
      "Epoch 406/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3688 - val_loss: 0.3923\n",
      "Epoch 407/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3688 - val_loss: 0.3923\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.4170\n",
      "[CV]  learning_rate=0.0011709267674750974, n_hidden=1, n_neurons=3, total= 2.2min\n",
      "[CV] learning_rate=0.012531483736867816, n_hidden=2, n_neurons=60 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 1.5353 - val_loss: 0.6444\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 17.0283 - val_loss: 0.9196\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.8435 - val_loss: 0.7334\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6892 - val_loss: 0.6707\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6049 - val_loss: 0.5551\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5707 - val_loss: 0.5627\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5392 - val_loss: 0.5452\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5187 - val_loss: 0.5190\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5062 - val_loss: 0.5044\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4950 - val_loss: 0.4699\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4815 - val_loss: 0.5184\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4790 - val_loss: 0.4544\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4565 - val_loss: 0.5079\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4557 - val_loss: 0.4352\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4437 - val_loss: 0.4770\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4426 - val_loss: 0.4306\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4326 - val_loss: 0.4318\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4308 - val_loss: 0.4400\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4288 - val_loss: 0.4122\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4229 - val_loss: 0.4534\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4168 - val_loss: 0.4592\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4136 - val_loss: 0.4102\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4096 - val_loss: 0.4426\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4121 - val_loss: 0.4097\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4208 - val_loss: 0.4044\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4065 - val_loss: 0.4374\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4056 - val_loss: 0.4190\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3979 - val_loss: 0.3995\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3951 - val_loss: 0.3961\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3997 - val_loss: 0.4238\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3940 - val_loss: 0.3909\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4000 - val_loss: 0.4046\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3867 - val_loss: 0.4668\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3889 - val_loss: 0.3815\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3860 - val_loss: 0.3819\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3844 - val_loss: 0.3818\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3804 - val_loss: 0.5289\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3892 - val_loss: 0.3793\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3810 - val_loss: 0.3778\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3759 - val_loss: 0.3960\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3744 - val_loss: 0.3734\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3723 - val_loss: 0.3838\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3682 - val_loss: 0.3902\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3685 - val_loss: 0.3714\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3910 - val_loss: 0.3909\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3705 - val_loss: 0.3647\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3658 - val_loss: 0.3931\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3656 - val_loss: 0.3925\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3604 - val_loss: 0.4064\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3597 - val_loss: 0.3650\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3570 - val_loss: 0.3786\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3550 - val_loss: 0.3574\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3538 - val_loss: 0.3558\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3543 - val_loss: 0.3991\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3539 - val_loss: 0.3804\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3511 - val_loss: 0.3530\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3480 - val_loss: 0.3677\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3538 - val_loss: 0.3615\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3457 - val_loss: 0.3824\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3497 - val_loss: 0.3642\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3470 - val_loss: 0.3550\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3489 - val_loss: 0.3453\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3410 - val_loss: 0.3640\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3458 - val_loss: 0.3692\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3451 - val_loss: 0.3549\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3454 - val_loss: 0.3560\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3384 - val_loss: 0.3805\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3410 - val_loss: 0.4016\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3382 - val_loss: 0.3723\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3372 - val_loss: 0.3793\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3378 - val_loss: 0.3523\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3346 - val_loss: 0.3602\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3342\n",
      "[CV]  learning_rate=0.012531483736867816, n_hidden=2, n_neurons=60, total=  26.7s\n",
      "[CV] learning_rate=0.012531483736867816, n_hidden=2, n_neurons=60 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7700 - val_loss: 0.5025\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4772 - val_loss: 0.4439\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4371 - val_loss: 0.4337\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4252 - val_loss: 0.4095\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4315 - val_loss: 0.4203\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4235 - val_loss: 0.3926\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3837 - val_loss: 0.4045\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3987 - val_loss: 0.4035\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3722 - val_loss: 0.3840\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3645 - val_loss: 0.3733\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3563 - val_loss: 0.3640\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3506 - val_loss: 0.3650\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3455 - val_loss: 0.3622\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3424 - val_loss: 0.3527\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3385 - val_loss: 0.3546\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3391 - val_loss: 0.3568\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3319 - val_loss: 0.3454\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3258 - val_loss: 0.3708\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3269 - val_loss: 0.3425\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3230 - val_loss: 0.3447\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3199 - val_loss: 0.3479\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3196 - val_loss: 0.3325\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3147 - val_loss: 0.3354\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3125 - val_loss: 0.3354\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3096 - val_loss: 0.3257\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3108 - val_loss: 0.3205\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3078 - val_loss: 0.3176\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3044 - val_loss: 0.3249\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3022 - val_loss: 0.3203\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3016 - val_loss: 0.3218\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3032 - val_loss: 0.3117\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2993 - val_loss: 0.3110\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2995 - val_loss: 0.3136\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2987 - val_loss: 0.3131\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2932 - val_loss: 0.3177\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2939 - val_loss: 0.3082\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2911 - val_loss: 0.3105\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2906 - val_loss: 0.3120\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2886 - val_loss: 0.3074\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2881 - val_loss: 0.3113\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2888 - val_loss: 0.3048\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2866 - val_loss: 0.3067\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2857 - val_loss: 0.3124\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2830 - val_loss: 0.3076\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2819 - val_loss: 0.3056\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2819 - val_loss: 0.3175\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2804 - val_loss: 0.3041\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2815 - val_loss: 0.3059\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2806 - val_loss: 0.3117\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2796 - val_loss: 0.3066\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2784 - val_loss: 0.3243\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2776 - val_loss: 0.2995\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2779 - val_loss: 0.3125\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2758 - val_loss: 0.3086\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2756 - val_loss: 0.3152\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2755 - val_loss: 0.2969\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2744 - val_loss: 0.3224\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2722 - val_loss: 0.3086\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2733 - val_loss: 0.3057\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2693 - val_loss: 0.2968\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2730 - val_loss: 0.3020\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2716 - val_loss: 0.2999\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2700 - val_loss: 0.3096\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2698 - val_loss: 0.2998\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2699 - val_loss: 0.3003\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2677 - val_loss: 0.3252\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2681 - val_loss: 0.3038\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2659 - val_loss: 0.3142\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2664 - val_loss: 0.2950\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2666 - val_loss: 0.2970\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2654 - val_loss: 0.2957\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2654 - val_loss: 0.3008\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2656 - val_loss: 0.3153\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2631 - val_loss: 0.3003\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2636 - val_loss: 0.2920\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2619 - val_loss: 0.2950\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2617 - val_loss: 0.3106\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2615 - val_loss: 0.3284\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2618 - val_loss: 0.3128\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2599 - val_loss: 0.2891\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2591 - val_loss: 0.2939\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2583 - val_loss: 0.2921\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2590 - val_loss: 0.2923\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2587 - val_loss: 0.2967\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2575 - val_loss: 0.2988\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2571 - val_loss: 0.2950\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2571 - val_loss: 0.2975\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2566 - val_loss: 0.3117\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2567 - val_loss: 0.2951\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2563 - val_loss: 0.2961\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4816\n",
      "[CV]  learning_rate=0.012531483736867816, n_hidden=2, n_neurons=60, total=  33.8s\n",
      "[CV] learning_rate=0.012531483736867816, n_hidden=2, n_neurons=60 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7349 - val_loss: 0.5725\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 1.3331 - val_loss: 0.4429\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 2.1136 - val_loss: 0.4693\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: nan - val_loss: nan\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: nan - val_loss: nan\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: nan\n",
      "[CV]  learning_rate=0.012531483736867816, n_hidden=2, n_neurons=60, total=   4.9s\n",
      "[CV] learning_rate=0.0015923781441655972, n_hidden=3, n_neurons=75 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 2.2796 - val_loss: 0.9796\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.8086 - val_loss: 0.7030\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6756 - val_loss: 0.6428\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6240 - val_loss: 0.6003\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5847 - val_loss: 0.5673\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5524 - val_loss: 0.5403\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5267 - val_loss: 0.5191\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5060 - val_loss: 0.4997\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4897 - val_loss: 0.4860\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4766 - val_loss: 0.4741\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4659 - val_loss: 0.4651\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4570 - val_loss: 0.4573\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4497 - val_loss: 0.4497\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4435 - val_loss: 0.4455\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4379 - val_loss: 0.4399\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4326 - val_loss: 0.4359\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4288 - val_loss: 0.4310\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4244 - val_loss: 0.4294\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4207 - val_loss: 0.4236\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4178 - val_loss: 0.4216\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4147 - val_loss: 0.4172\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4110 - val_loss: 0.4146\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4084 - val_loss: 0.4112\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4059 - val_loss: 0.4095\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4029 - val_loss: 0.4064\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4008 - val_loss: 0.4063\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3983 - val_loss: 0.4038\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3957 - val_loss: 0.3997\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3938 - val_loss: 0.4004\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3917 - val_loss: 0.3993\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3894 - val_loss: 0.3948\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3872 - val_loss: 0.3928\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3854 - val_loss: 0.3916\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3836 - val_loss: 0.3902\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3814 - val_loss: 0.3875\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3799 - val_loss: 0.3864\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3786 - val_loss: 0.3851\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3771 - val_loss: 0.3871\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3751 - val_loss: 0.3853\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3737 - val_loss: 0.3803\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3715 - val_loss: 0.3814\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3703 - val_loss: 0.3778\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3687 - val_loss: 0.3767\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3669 - val_loss: 0.3747\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3652 - val_loss: 0.3757\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3646 - val_loss: 0.3722\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3629 - val_loss: 0.3752\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3614 - val_loss: 0.3734\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3600 - val_loss: 0.3687\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3587 - val_loss: 0.3682\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3571 - val_loss: 0.3673\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3563 - val_loss: 0.3643\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3552 - val_loss: 0.3641\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3550 - val_loss: 0.3630\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3543 - val_loss: 0.3613\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3521 - val_loss: 0.3609\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3506 - val_loss: 0.3606\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3487 - val_loss: 0.3630\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3473 - val_loss: 0.3584\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3458 - val_loss: 0.3545\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3444 - val_loss: 0.3540\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3435 - val_loss: 0.3539\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3422 - val_loss: 0.3548\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3408 - val_loss: 0.3533\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3397 - val_loss: 0.3503\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3387 - val_loss: 0.3484\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3375 - val_loss: 0.3512\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3365 - val_loss: 0.3481\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3353 - val_loss: 0.3479\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3333 - val_loss: 0.3457\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3339 - val_loss: 0.3442\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3326 - val_loss: 0.3444\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3315 - val_loss: 0.3422\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3291 - val_loss: 0.3478\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3295 - val_loss: 0.3420\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3275 - val_loss: 0.3396\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3275 - val_loss: 0.3461\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3261 - val_loss: 0.3388\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3252 - val_loss: 0.3409\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3245 - val_loss: 0.3386\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3243 - val_loss: 0.3359\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3233 - val_loss: 0.3343\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3221 - val_loss: 0.3351\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3220 - val_loss: 0.3355\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3222 - val_loss: 0.3326\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3210 - val_loss: 0.3323\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3197 - val_loss: 0.3319\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3186 - val_loss: 0.3325\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3178 - val_loss: 0.3344\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3169 - val_loss: 0.3321\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3155 - val_loss: 0.3339\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3141 - val_loss: 0.3286\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3144 - val_loss: 0.3341\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3132 - val_loss: 0.3279\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3137 - val_loss: 0.3279\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3129 - val_loss: 0.3286\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3136 - val_loss: 0.3324\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3135 - val_loss: 0.3318\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3143 - val_loss: 0.3265\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3144 - val_loss: 0.3241\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3151 - val_loss: 0.3261\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3141 - val_loss: 0.3228\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3153 - val_loss: 0.3243\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3136 - val_loss: 0.3222\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3098 - val_loss: 0.3254\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3061 - val_loss: 0.3207\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3048 - val_loss: 0.3229\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3032 - val_loss: 0.3222\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3030 - val_loss: 0.3208\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3015 - val_loss: 0.3196\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3007 - val_loss: 0.3221\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3007 - val_loss: 0.3178\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3001 - val_loss: 0.3170\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2984 - val_loss: 0.3165\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2981 - val_loss: 0.3209\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2980 - val_loss: 0.3171\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2971 - val_loss: 0.3155\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2966 - val_loss: 0.3195\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2955 - val_loss: 0.3245\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2947 - val_loss: 0.3161\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2953 - val_loss: 0.3150\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2960 - val_loss: 0.3192\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2931 - val_loss: 0.3361\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2930 - val_loss: 0.3149\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2931 - val_loss: 0.3193\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2928 - val_loss: 0.3137\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2910 - val_loss: 0.3149\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2914 - val_loss: 0.3134\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2907 - val_loss: 0.3127\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2890 - val_loss: 0.3127\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2899 - val_loss: 0.3148\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2889 - val_loss: 0.3105\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2874 - val_loss: 0.3105\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2884 - val_loss: 0.3105\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2890 - val_loss: 0.3162\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2878 - val_loss: 0.3090\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2856 - val_loss: 0.3116\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2871 - val_loss: 0.3144\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2859 - val_loss: 0.3118\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2854 - val_loss: 0.3107\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2861 - val_loss: 0.3089\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2849 - val_loss: 0.3102\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2845 - val_loss: 0.3061\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2851 - val_loss: 0.3078\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2846 - val_loss: 0.3099\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2844 - val_loss: 0.3082\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2843 - val_loss: 0.3068\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2849 - val_loss: 0.3067\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2850 - val_loss: 0.3066\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2851 - val_loss: 0.3082\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2852 - val_loss: 0.3056\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2877 - val_loss: 0.3184\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2978 - val_loss: 0.3070\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2917 - val_loss: 0.3154\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2822 - val_loss: 0.3155\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2795 - val_loss: 0.3029\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2801 - val_loss: 0.3066\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2784 - val_loss: 0.3053\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2780 - val_loss: 0.3033\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2778 - val_loss: 0.3048\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2777 - val_loss: 0.3048\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2772 - val_loss: 0.3134\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2762 - val_loss: 0.3116\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2767 - val_loss: 0.3015\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2765 - val_loss: 0.3033\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2755 - val_loss: 0.3021\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2765 - val_loss: 0.3023\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2747 - val_loss: 0.3068\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2745 - val_loss: 0.3050\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2749 - val_loss: 0.2999\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2740 - val_loss: 0.2999\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2742 - val_loss: 0.3017\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2735 - val_loss: 0.3000\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2728 - val_loss: 0.3020\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2728 - val_loss: 0.3015\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2730 - val_loss: 0.2996\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2719 - val_loss: 0.3080\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2725 - val_loss: 0.2997\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2720 - val_loss: 0.3016\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2711 - val_loss: 0.3079\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2708 - val_loss: 0.2996\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2711 - val_loss: 0.2995\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2702 - val_loss: 0.3051\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2698 - val_loss: 0.2974\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2699 - val_loss: 0.2976\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2700 - val_loss: 0.3023\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2692 - val_loss: 0.3023\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2694 - val_loss: 0.2992\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2687 - val_loss: 0.3022\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2681 - val_loss: 0.3109\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2679 - val_loss: 0.2982\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2677 - val_loss: 0.3034\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2671 - val_loss: 0.2958\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2670 - val_loss: 0.2987\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2679 - val_loss: 0.2969\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2673 - val_loss: 0.3006\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2673 - val_loss: 0.2960\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2665 - val_loss: 0.2963\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2661 - val_loss: 0.3074\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2658 - val_loss: 0.2954\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2658 - val_loss: 0.2960\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2660 - val_loss: 0.3012\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2653 - val_loss: 0.2992\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2643 - val_loss: 0.2943\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2647 - val_loss: 0.2996\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2641 - val_loss: 0.3018\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2643 - val_loss: 0.3000\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2639 - val_loss: 0.2950\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2638 - val_loss: 0.2961\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2640 - val_loss: 0.2934\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2624 - val_loss: 0.2963\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2623 - val_loss: 0.2999\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2629 - val_loss: 0.2941\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2625 - val_loss: 0.2934\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2628 - val_loss: 0.2992\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2624 - val_loss: 0.2975\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2616 - val_loss: 0.2931\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2611 - val_loss: 0.3015\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2627 - val_loss: 0.2937\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2622 - val_loss: 0.2956\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2605 - val_loss: 0.2970\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2605 - val_loss: 0.3046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2608 - val_loss: 0.2945\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2605 - val_loss: 0.2967\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2602 - val_loss: 0.2961\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2596 - val_loss: 0.2944\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2601 - val_loss: 0.2944\n",
      "3870/3870 [==============================] - 0s 24us/sample - loss: 0.2766\n",
      "[CV]  learning_rate=0.0015923781441655972, n_hidden=3, n_neurons=75, total= 1.6min\n",
      "[CV] learning_rate=0.0015923781441655972, n_hidden=3, n_neurons=75 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.7208 - val_loss: 0.7242\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6715 - val_loss: 0.6283\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6062 - val_loss: 0.5853\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5689 - val_loss: 0.5570\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5404 - val_loss: 0.5321\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5186 - val_loss: 0.5133\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5009 - val_loss: 0.4966\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4861 - val_loss: 0.4847\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4738 - val_loss: 0.4736\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4624 - val_loss: 0.4635\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4531 - val_loss: 0.4539\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4445 - val_loss: 0.4499\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4390 - val_loss: 0.4415\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4318 - val_loss: 0.4371\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4259 - val_loss: 0.4305\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4214 - val_loss: 0.4256\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4159 - val_loss: 0.4224\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4130 - val_loss: 0.4179\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4090 - val_loss: 0.4147\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4063 - val_loss: 0.4112\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4029 - val_loss: 0.4094\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3999 - val_loss: 0.4068\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3975 - val_loss: 0.4053\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3949 - val_loss: 0.4035\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3928 - val_loss: 0.4018\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3907 - val_loss: 0.4024\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3889 - val_loss: 0.3983\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3861 - val_loss: 0.3973\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3844 - val_loss: 0.3943\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3828 - val_loss: 0.3926\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3810 - val_loss: 0.3930\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3793 - val_loss: 0.3909\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3772 - val_loss: 0.3902\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3757 - val_loss: 0.3886\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3741 - val_loss: 0.3870\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3724 - val_loss: 0.3837\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3711 - val_loss: 0.3821\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3690 - val_loss: 0.3827\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3676 - val_loss: 0.3812\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3658 - val_loss: 0.3822\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3645 - val_loss: 0.3790\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3634 - val_loss: 0.3774\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3617 - val_loss: 0.3762\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3604 - val_loss: 0.3767\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3592 - val_loss: 0.3756\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3573 - val_loss: 0.3769\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3569 - val_loss: 0.3725\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3550 - val_loss: 0.3728\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3539 - val_loss: 0.3698\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3523 - val_loss: 0.3739\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3511 - val_loss: 0.3675\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3492 - val_loss: 0.3657\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3485 - val_loss: 0.3652\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3465 - val_loss: 0.3650\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3462 - val_loss: 0.3675\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3448 - val_loss: 0.3637\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3438 - val_loss: 0.3607\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3428 - val_loss: 0.3612\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3411 - val_loss: 0.3640\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3406 - val_loss: 0.3599\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3392 - val_loss: 0.3582\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3379 - val_loss: 0.3623\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3369 - val_loss: 0.3616\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3353 - val_loss: 0.3552\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3346 - val_loss: 0.3554\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3341 - val_loss: 0.3556\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3330 - val_loss: 0.3542\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3322 - val_loss: 0.3520\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3316 - val_loss: 0.3522\n",
      "Epoch 70/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3297 - val_loss: 0.3528\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3287 - val_loss: 0.3523\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3272 - val_loss: 0.3500\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3268 - val_loss: 0.3490\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3258 - val_loss: 0.3477\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3249 - val_loss: 0.3587\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3238 - val_loss: 0.3475\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3226 - val_loss: 0.3465\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3223 - val_loss: 0.3461\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3217 - val_loss: 0.3460\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3203 - val_loss: 0.3467\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3202 - val_loss: 0.3447\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3193 - val_loss: 0.3486\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3183 - val_loss: 0.3480\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3170 - val_loss: 0.3447\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3171 - val_loss: 0.3418\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3162 - val_loss: 0.3417\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3150 - val_loss: 0.3416\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3144 - val_loss: 0.3426\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3137 - val_loss: 0.3412\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3125 - val_loss: 0.3402\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3121 - val_loss: 0.3379\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3112 - val_loss: 0.3403\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3103 - val_loss: 0.3413\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3101 - val_loss: 0.3406\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3086 - val_loss: 0.3362\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3083 - val_loss: 0.3426\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3072 - val_loss: 0.3374\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3070 - val_loss: 0.3355\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3069 - val_loss: 0.3351\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3060 - val_loss: 0.3369\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3052 - val_loss: 0.3341\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3038 - val_loss: 0.3328\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3030 - val_loss: 0.3324\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3030 - val_loss: 0.3344\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3024 - val_loss: 0.3310\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3015 - val_loss: 0.3299\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3016 - val_loss: 0.3305\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3003 - val_loss: 0.3333\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2998 - val_loss: 0.3296\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2994 - val_loss: 0.3308\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2985 - val_loss: 0.3289\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2979 - val_loss: 0.3282\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2973 - val_loss: 0.3292\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2968 - val_loss: 0.3279\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2949 - val_loss: 0.3292\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2954 - val_loss: 0.3263\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2945 - val_loss: 0.3269\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2945 - val_loss: 0.3259\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2939 - val_loss: 0.3268\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2926 - val_loss: 0.3251\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2910 - val_loss: 0.3257\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2925 - val_loss: 0.3247\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2913 - val_loss: 0.3243\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2906 - val_loss: 0.3237\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2893 - val_loss: 0.3233\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2894 - val_loss: 0.3230\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2887 - val_loss: 0.3244\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2884 - val_loss: 0.3297\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2878 - val_loss: 0.3263\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2873 - val_loss: 0.3198\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2871 - val_loss: 0.3233\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2856 - val_loss: 0.3224\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2854 - val_loss: 0.3222\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2855 - val_loss: 0.3204\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2849 - val_loss: 0.3195\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2844 - val_loss: 0.3188\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2840 - val_loss: 0.3187\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2832 - val_loss: 0.3200\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2831 - val_loss: 0.3193\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2829 - val_loss: 0.3190\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2811 - val_loss: 0.3189\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2807 - val_loss: 0.3176\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2809 - val_loss: 0.3187\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2804 - val_loss: 0.3179\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2803 - val_loss: 0.3165\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2804 - val_loss: 0.3183\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2792 - val_loss: 0.3177\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2785 - val_loss: 0.3168\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2785 - val_loss: 0.3173\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2776 - val_loss: 0.3175\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2778 - val_loss: 0.3175\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2777 - val_loss: 0.3143\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2767 - val_loss: 0.3190\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2767 - val_loss: 0.3208\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2751 - val_loss: 0.3140\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2762 - val_loss: 0.3135\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2756 - val_loss: 0.3143\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2750 - val_loss: 0.3136\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2742 - val_loss: 0.3138\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2747 - val_loss: 0.3128\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2739 - val_loss: 0.3140\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2726 - val_loss: 0.3146\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2731 - val_loss: 0.3133\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2729 - val_loss: 0.3137\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2730 - val_loss: 0.3134\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2711 - val_loss: 0.3146\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2716 - val_loss: 0.3115\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2716 - val_loss: 0.3112\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2704 - val_loss: 0.3131\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2704 - val_loss: 0.3108\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2701 - val_loss: 0.3129\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2703 - val_loss: 0.3107\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2702 - val_loss: 0.3151\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2689 - val_loss: 0.3099\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2690 - val_loss: 0.3101\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2682 - val_loss: 0.3119\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2688 - val_loss: 0.3106\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2677 - val_loss: 0.3105\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2673 - val_loss: 0.3125\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2677 - val_loss: 0.3111\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2670 - val_loss: 0.3171\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2668 - val_loss: 0.3102\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2659 - val_loss: 0.3122\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2665 - val_loss: 0.3086\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2651 - val_loss: 0.3086\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2660 - val_loss: 0.3069\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2656 - val_loss: 0.3101\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2654 - val_loss: 0.3084\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2646 - val_loss: 0.3075\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2637 - val_loss: 0.3113\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2636 - val_loss: 0.3083\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2637 - val_loss: 0.3064\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2635 - val_loss: 0.3059\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2633 - val_loss: 0.3057\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2624 - val_loss: 0.3060\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2617 - val_loss: 0.3071\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2620 - val_loss: 0.3103\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2630 - val_loss: 0.3093\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2623 - val_loss: 0.3056\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2620 - val_loss: 0.3078\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2615 - val_loss: 0.3045\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2599 - val_loss: 0.3054\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2607 - val_loss: 0.3097\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2596 - val_loss: 0.3067\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2595 - val_loss: 0.3178\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2595 - val_loss: 0.3027\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2586 - val_loss: 0.3054\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2586 - val_loss: 0.3035\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2594 - val_loss: 0.3045\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2585 - val_loss: 0.3020\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2577 - val_loss: 0.3036\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2575 - val_loss: 0.3051\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2577 - val_loss: 0.3031\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2574 - val_loss: 0.3042\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2576 - val_loss: 0.3054\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2571 - val_loss: 0.3020\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2562 - val_loss: 0.3007\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2561 - val_loss: 0.3033\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2563 - val_loss: 0.3007\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2560 - val_loss: 0.3040\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2558 - val_loss: 0.3026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2558 - val_loss: 0.3020\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2554 - val_loss: 0.2996\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2546 - val_loss: 0.2993\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2538 - val_loss: 0.3103\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2536 - val_loss: 0.2994\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2545 - val_loss: 0.3032\n",
      "Epoch 228/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2536 - val_loss: 0.3046\n",
      "Epoch 229/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2537 - val_loss: 0.2990\n",
      "Epoch 230/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2543 - val_loss: 0.2981\n",
      "Epoch 231/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2530 - val_loss: 0.3094\n",
      "Epoch 232/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2532 - val_loss: 0.3158\n",
      "Epoch 233/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2534 - val_loss: 0.3020\n",
      "Epoch 234/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2540 - val_loss: 0.2978\n",
      "Epoch 235/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2522 - val_loss: 0.2973\n",
      "Epoch 236/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2517 - val_loss: 0.3032\n",
      "Epoch 237/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2519 - val_loss: 0.3018\n",
      "Epoch 238/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2514 - val_loss: 0.2975\n",
      "Epoch 239/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2519 - val_loss: 0.3091\n",
      "Epoch 240/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2515 - val_loss: 0.2992\n",
      "Epoch 241/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2516 - val_loss: 0.3062\n",
      "Epoch 242/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2509 - val_loss: 0.3047\n",
      "Epoch 243/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2511 - val_loss: 0.3053\n",
      "Epoch 244/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2514 - val_loss: 0.3036\n",
      "Epoch 245/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2516 - val_loss: 0.2992\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.5099\n",
      "[CV]  learning_rate=0.0015923781441655972, n_hidden=3, n_neurons=75, total= 1.7min\n",
      "[CV] learning_rate=0.0015923781441655972, n_hidden=3, n_neurons=75 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 1.8594 - val_loss: 0.7697\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.8375 - val_loss: 0.6564\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6221 - val_loss: 0.6038\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5701 - val_loss: 0.5698\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5389 - val_loss: 0.5434\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5145 - val_loss: 0.5206\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4943 - val_loss: 0.5037\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4784 - val_loss: 0.4881\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4651 - val_loss: 0.4761\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4545 - val_loss: 0.4645\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4450 - val_loss: 0.4559\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4378 - val_loss: 0.4476\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4308 - val_loss: 0.4420\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4253 - val_loss: 0.4361\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4197 - val_loss: 0.4309\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4155 - val_loss: 0.4265\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4108 - val_loss: 0.4228\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4074 - val_loss: 0.4188\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4043 - val_loss: 0.4160\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4010 - val_loss: 0.4139\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3975 - val_loss: 0.4121\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3954 - val_loss: 0.4086\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3923 - val_loss: 0.4048\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3896 - val_loss: 0.4033\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3866 - val_loss: 0.4002\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3845 - val_loss: 0.3989\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3821 - val_loss: 0.3982\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3801 - val_loss: 0.3984\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3773 - val_loss: 0.3934\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3752 - val_loss: 0.3968\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3734 - val_loss: 0.3893\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3710 - val_loss: 0.3875\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3688 - val_loss: 0.3897\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3675 - val_loss: 0.3854\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3655 - val_loss: 0.3844\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3639 - val_loss: 0.3817\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3609 - val_loss: 0.3811\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3604 - val_loss: 0.3783\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3576 - val_loss: 0.3778\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3562 - val_loss: 0.3754\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3549 - val_loss: 0.3742\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3529 - val_loss: 0.3727\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3517 - val_loss: 0.3713\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3499 - val_loss: 0.3697\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3483 - val_loss: 0.3702\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3468 - val_loss: 0.3688\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3459 - val_loss: 0.3689\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3442 - val_loss: 0.3660\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3422 - val_loss: 0.3688\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3415 - val_loss: 0.3692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3399 - val_loss: 0.3686\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3390 - val_loss: 0.3622\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3365 - val_loss: 0.3609\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3363 - val_loss: 0.3590\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3347 - val_loss: 0.3608\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3340 - val_loss: 0.3584\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3326 - val_loss: 0.3570\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3299 - val_loss: 0.3586\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3304 - val_loss: 0.3556\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3283 - val_loss: 0.3596\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3287 - val_loss: 0.3533\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3275 - val_loss: 0.3545\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3262 - val_loss: 0.3521\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3256 - val_loss: 0.3511\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3241 - val_loss: 0.3496\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3233 - val_loss: 0.3523\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3213 - val_loss: 0.3492\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3214 - val_loss: 0.3506\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3202 - val_loss: 0.3501\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3199 - val_loss: 0.3491\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3183 - val_loss: 0.3488\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3174 - val_loss: 0.3451\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3167 - val_loss: 0.3479\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3154 - val_loss: 0.3444\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3150 - val_loss: 0.3447\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3133 - val_loss: 0.3424\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3132 - val_loss: 0.3450\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3121 - val_loss: 0.3438\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3116 - val_loss: 0.3419\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3104 - val_loss: 0.3408\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3099 - val_loss: 0.3411\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3090 - val_loss: 0.3406\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3079 - val_loss: 0.3420\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3078 - val_loss: 0.3384\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3065 - val_loss: 0.3412\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3059 - val_loss: 0.3461\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3058 - val_loss: 0.3394\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3049 - val_loss: 0.3371\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3040 - val_loss: 0.3399\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3041 - val_loss: 0.3377\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3044 - val_loss: 0.3375\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3028 - val_loss: 0.3360\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3028 - val_loss: 0.3354\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3023 - val_loss: 0.3377\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3026 - val_loss: 0.3350\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3025 - val_loss: 0.3348\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3021 - val_loss: 0.3365\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3012 - val_loss: 0.3325\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3004 - val_loss: 0.3355\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2989 - val_loss: 0.3321\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2975 - val_loss: 0.3415\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2954 - val_loss: 0.3299\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2963 - val_loss: 0.3326\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2953 - val_loss: 0.3312\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2952 - val_loss: 0.3329\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2944 - val_loss: 0.3297\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2933 - val_loss: 0.3311\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2929 - val_loss: 0.3276\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2920 - val_loss: 0.3336\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2916 - val_loss: 0.3269\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2917 - val_loss: 0.3300\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2923 - val_loss: 0.3291\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2906 - val_loss: 0.3327\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2893 - val_loss: 0.3290\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2895 - val_loss: 0.3296\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2885 - val_loss: 0.3259\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2890 - val_loss: 0.3274\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2879 - val_loss: 0.3332\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2869 - val_loss: 0.3275\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2863 - val_loss: 0.3228\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2860 - val_loss: 0.3269\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2854 - val_loss: 0.3255\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2853 - val_loss: 0.3256\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2847 - val_loss: 0.3216\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2843 - val_loss: 0.3273\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2845 - val_loss: 0.3276\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2837 - val_loss: 0.3256\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2826 - val_loss: 0.3219\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2825 - val_loss: 0.3241\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2822 - val_loss: 0.3232\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2827 - val_loss: 0.3224\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2813 - val_loss: 0.3260\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2805 - val_loss: 0.3237\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2798 - val_loss: 0.3202\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2786 - val_loss: 0.3205\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2785 - val_loss: 0.3183\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2778 - val_loss: 0.3206\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2771 - val_loss: 0.3213\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2767 - val_loss: 0.3214\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2763 - val_loss: 0.3183\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2755 - val_loss: 0.3201\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2750 - val_loss: 0.3174\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2750 - val_loss: 0.3189\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2740 - val_loss: 0.3217\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2738 - val_loss: 0.3191\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2725 - val_loss: 0.3218\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2730 - val_loss: 0.3205\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2725 - val_loss: 0.3178\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2715 - val_loss: 0.3181\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2715 - val_loss: 0.3188\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2709 - val_loss: 0.3166\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2711 - val_loss: 0.3169\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2706 - val_loss: 0.3186\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2696 - val_loss: 0.3160\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2696 - val_loss: 0.3153\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2694 - val_loss: 0.3155\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2696 - val_loss: 0.3153\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2686 - val_loss: 0.3272\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2688 - val_loss: 0.3169\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2666 - val_loss: 0.3188\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2682 - val_loss: 0.3147\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2675 - val_loss: 0.3193\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2672 - val_loss: 0.3148\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2663 - val_loss: 0.3288\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2669 - val_loss: 0.3143\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2657 - val_loss: 0.3159\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2658 - val_loss: 0.3150\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2652 - val_loss: 0.3151\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2649 - val_loss: 0.3148\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2642 - val_loss: 0.3152\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2637 - val_loss: 0.3173\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2639 - val_loss: 0.3163\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2635 - val_loss: 0.3124\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2630 - val_loss: 0.3120\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2641 - val_loss: 0.3188\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2627 - val_loss: 0.3265\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2623 - val_loss: 0.3121\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2627 - val_loss: 0.3125\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2626 - val_loss: 0.3169\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2623 - val_loss: 0.3156\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2627 - val_loss: 0.3121\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2634 - val_loss: 0.3115\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2633 - val_loss: 0.3128\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2653 - val_loss: 0.3122\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2653 - val_loss: 0.3140\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2656 - val_loss: 0.3111\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2642 - val_loss: 0.3105\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2654 - val_loss: 0.3117\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2642 - val_loss: 0.3095\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2624 - val_loss: 0.3123\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2587 - val_loss: 0.3213\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2596 - val_loss: 0.3123\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2580 - val_loss: 0.3088\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2584 - val_loss: 0.3112\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2571 - val_loss: 0.3144\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2572 - val_loss: 0.3076\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2569 - val_loss: 0.3180\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2563 - val_loss: 0.3095\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2558 - val_loss: 0.3138\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2562 - val_loss: 0.3164\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2556 - val_loss: 0.3090\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2552 - val_loss: 0.3089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2543 - val_loss: 0.3087\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2555 - val_loss: 0.3068\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2554 - val_loss: 0.3096\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2545 - val_loss: 0.3069\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2547 - val_loss: 0.3107\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2540 - val_loss: 0.3099\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2545 - val_loss: 0.3105\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2543 - val_loss: 0.3079\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2532 - val_loss: 0.3101\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2529 - val_loss: 0.3112\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.2531 - val_loss: 0.3137\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.2524 - val_loss: 0.3093\n",
      "3870/3870 [==============================] - 0s 26us/sample - loss: 0.3260\n",
      "[CV]  learning_rate=0.0015923781441655972, n_hidden=3, n_neurons=75, total= 1.5min\n",
      "[CV] learning_rate=0.003833593497547869, n_hidden=1, n_neurons=67 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 1.4309 - val_loss: 0.6447\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 1.5386 - val_loss: 0.6425\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 1.1168 - val_loss: 0.5454\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5549 - val_loss: 0.5038\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5051 - val_loss: 0.4828\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4847 - val_loss: 0.4694\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4733 - val_loss: 0.4609\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4645 - val_loss: 0.4515\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4603 - val_loss: 0.4518\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4517 - val_loss: 0.4496\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4459 - val_loss: 0.4364\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4392 - val_loss: 0.4359\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4369 - val_loss: 0.4311\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4319 - val_loss: 0.4263\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4297 - val_loss: 0.4254\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4257 - val_loss: 0.4208\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4234 - val_loss: 0.4194\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4213 - val_loss: 0.4190\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4178 - val_loss: 0.4150\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4164 - val_loss: 0.4134\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4131 - val_loss: 0.4111\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4122 - val_loss: 0.4095\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4096 - val_loss: 0.4078\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4074 - val_loss: 0.4149\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4079 - val_loss: 0.4045\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4043 - val_loss: 0.4027\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4031 - val_loss: 0.4023\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4013 - val_loss: 0.4008\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4026 - val_loss: 0.3975\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3972 - val_loss: 0.3973\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3962 - val_loss: 0.3973\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3948 - val_loss: 0.3930\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3923 - val_loss: 0.3930\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3929 - val_loss: 0.3908\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3946 - val_loss: 0.3924\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3896 - val_loss: 0.3952\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3878 - val_loss: 0.3895\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3879 - val_loss: 0.3884\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3857 - val_loss: 0.3963\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3857 - val_loss: 0.3853\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3828 - val_loss: 0.3843\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3831 - val_loss: 0.3860\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3810 - val_loss: 0.3826\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3799 - val_loss: 0.3922\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4017 - val_loss: 0.3811\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3786 - val_loss: 0.3798\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3793 - val_loss: 0.3832\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3766 - val_loss: 0.3790\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3753 - val_loss: 0.3780\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3743 - val_loss: 0.3819\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3741 - val_loss: 0.3876\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3744 - val_loss: 0.3761\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3714 - val_loss: 0.3770\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3708 - val_loss: 0.3758\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3766 - val_loss: 0.3783\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3744 - val_loss: 0.3731\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3710 - val_loss: 0.3739\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3690 - val_loss: 0.3750\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3681 - val_loss: 0.3749\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3670 - val_loss: 0.3751\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3665 - val_loss: 0.3717\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3691 - val_loss: 0.3739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3714 - val_loss: 0.3717\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3678 - val_loss: 0.3723\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3643 - val_loss: 0.3732\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3638 - val_loss: 0.3735\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3637 - val_loss: 0.3694\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3636 - val_loss: 0.3698\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3622 - val_loss: 0.3729\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3621 - val_loss: 0.3913\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4549 - val_loss: 0.3713\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3711 - val_loss: 0.3669\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3679 - val_loss: 0.3706\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3608 - val_loss: 0.3682\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3614 - val_loss: 0.3690\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3602 - val_loss: 0.3696\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3637 - val_loss: 0.3679\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3597 - val_loss: 0.3680\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3588 - val_loss: 0.3669\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3610 - val_loss: 0.3652\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3574 - val_loss: 0.3649\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3562 - val_loss: 0.3647\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3568 - val_loss: 0.3658\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3567 - val_loss: 0.3663\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3586 - val_loss: 0.3665\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3560 - val_loss: 0.3649\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3564 - val_loss: 0.3676\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3649 - val_loss: 0.3631\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3542 - val_loss: 0.3678\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3695 - val_loss: 0.3624\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3539 - val_loss: 0.3653\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3535 - val_loss: 0.3620\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3523 - val_loss: 0.3617\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3523 - val_loss: 0.3609\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3533 - val_loss: 0.3676\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3518 - val_loss: 0.3601\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3514 - val_loss: 0.3663\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3553 - val_loss: 0.3586\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3495 - val_loss: 0.3575\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3496 - val_loss: 0.3590\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3489 - val_loss: 0.3596\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3492 - val_loss: 0.3590\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3484 - val_loss: 0.3580\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3508 - val_loss: 0.3622\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3475 - val_loss: 0.3594\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3472 - val_loss: 0.3569\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3465 - val_loss: 0.3570\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3458 - val_loss: 0.3569\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3454 - val_loss: 0.3585\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3453 - val_loss: 0.3586\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3449 - val_loss: 0.3551\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3447 - val_loss: 0.3556\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3453 - val_loss: 0.3651\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3626 - val_loss: 0.3571\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3431 - val_loss: 0.3578\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3479 - val_loss: 0.3550\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3429 - val_loss: 0.3554\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3417 - val_loss: 0.3532\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3426 - val_loss: 0.3534\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3503 - val_loss: 0.3529\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3442 - val_loss: 0.3563\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3484 - val_loss: 0.3550\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3453 - val_loss: 0.3540\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3421 - val_loss: 0.3663\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3439 - val_loss: 0.3518\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3403 - val_loss: 0.3539\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3416 - val_loss: 0.3509\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3396 - val_loss: 0.3526\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3396 - val_loss: 0.3817\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3416 - val_loss: 0.3526\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3419 - val_loss: 0.3503\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3417 - val_loss: 0.3504\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3407 - val_loss: 0.3514\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3434 - val_loss: 0.3509\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3437 - val_loss: 0.4389\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3467 - val_loss: 0.3508\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3394 - val_loss: 0.3563\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3415 - val_loss: 0.3495\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3383 - val_loss: 0.3534\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3371 - val_loss: 0.3489\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3369 - val_loss: 0.3498\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3400 - val_loss: 0.3487\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3469 - val_loss: 0.3469\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3349 - val_loss: 0.3493\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3343 - val_loss: 0.3483\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3337 - val_loss: 0.3485\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3341 - val_loss: 0.3464\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3334 - val_loss: 0.3467\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3325 - val_loss: 0.3487\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3383 - val_loss: 0.3587\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3343 - val_loss: 0.3490\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3451 - val_loss: 0.3448\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3324 - val_loss: 0.3452\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3396 - val_loss: 0.3456\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3355 - val_loss: 0.3450\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3345 - val_loss: 0.3472\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3482 - val_loss: 0.3455\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3337 - val_loss: 0.3427\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3297 - val_loss: 0.3448\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3314 - val_loss: 0.3422\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3305 - val_loss: 0.3430\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3289 - val_loss: 0.3429\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3327 - val_loss: 0.3444\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3418 - val_loss: 0.3448\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3807 - val_loss: 0.3418\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3283 - val_loss: 0.3419\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3326 - val_loss: 0.3420\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3272 - val_loss: 0.3458\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3284 - val_loss: 0.3422\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3282 - val_loss: 0.3428\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3507 - val_loss: 0.3462\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3277 - val_loss: 0.3417\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3377 - val_loss: 0.3430\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3538 - val_loss: 0.3426\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3263 - val_loss: 0.3422\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3268 - val_loss: 0.3399\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3256 - val_loss: 0.3404\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3266 - val_loss: 0.3409\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3269 - val_loss: 0.3391\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3249 - val_loss: 0.3441\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3246 - val_loss: 0.3393\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3241 - val_loss: 0.3373\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3234 - val_loss: 0.3407\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3231 - val_loss: 0.3408\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3229 - val_loss: 0.3407\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3245 - val_loss: 0.3398\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3235 - val_loss: 0.3389\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3236 - val_loss: 0.3396\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3230 - val_loss: 0.3421\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3216 - val_loss: 0.3403\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3211 - val_loss: 0.3398\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3242 - val_loss: 0.3392\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.3134\n",
      "[CV]  learning_rate=0.003833593497547869, n_hidden=1, n_neurons=67, total= 1.1min\n",
      "[CV] learning_rate=0.003833593497547869, n_hidden=1, n_neurons=67 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 1.1875 - val_loss: 0.6802\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6475 - val_loss: 0.6136\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5861 - val_loss: 0.5634\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5432 - val_loss: 0.5307\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5185 - val_loss: 0.5087\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4963 - val_loss: 0.4942\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4838 - val_loss: 0.4812\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4740 - val_loss: 0.4718\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4639 - val_loss: 0.4639\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4594 - val_loss: 0.4591\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4513 - val_loss: 0.4530\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4460 - val_loss: 0.4485\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4412 - val_loss: 0.4582\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4394 - val_loss: 0.4430\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4341 - val_loss: 0.4376\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4299 - val_loss: 0.4329\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4274 - val_loss: 0.4393\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4296 - val_loss: 0.4280\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4210 - val_loss: 0.4249\n",
      "Epoch 20/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4285 - val_loss: 0.4261\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4222 - val_loss: 0.4219\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4145 - val_loss: 0.4198\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4122 - val_loss: 0.4164\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4095 - val_loss: 0.4149\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4077 - val_loss: 0.4125\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4048 - val_loss: 0.4107\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4064 - val_loss: 0.4102\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4039 - val_loss: 0.4116\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4016 - val_loss: 0.4091\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3987 - val_loss: 0.4051\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3961 - val_loss: 0.4028\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3959 - val_loss: 0.4011\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3931 - val_loss: 0.4014\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3912 - val_loss: 0.4000\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3914 - val_loss: 0.3976\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3889 - val_loss: 0.3970\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3876 - val_loss: 0.3964\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3862 - val_loss: 0.3956\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3842 - val_loss: 0.3914\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3845 - val_loss: 0.3955\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3842 - val_loss: 0.3905\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3807 - val_loss: 0.3967\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3847 - val_loss: 0.3889\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3816 - val_loss: 0.3885\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3768 - val_loss: 0.3891\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3757 - val_loss: 0.3846\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3744 - val_loss: 0.4102\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3808 - val_loss: 0.4829\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4206 - val_loss: 0.3847\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3723 - val_loss: 0.3823\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3797 - val_loss: 0.3805\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3711 - val_loss: 0.3802\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3693 - val_loss: 0.3873\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3713 - val_loss: 0.4407\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3903 - val_loss: 0.3784\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3676 - val_loss: 0.3767\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3650 - val_loss: 0.3764\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3648 - val_loss: 0.3771\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3692 - val_loss: 0.3758\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3647 - val_loss: 0.3765\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3619 - val_loss: 0.3736\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3635 - val_loss: 0.3725\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3607 - val_loss: 0.3741\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3609 - val_loss: 0.3721\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3585 - val_loss: 0.3708\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3597 - val_loss: 0.3692\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3591 - val_loss: 0.3701\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3593 - val_loss: 0.3698\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3661 - val_loss: 0.3742\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3560 - val_loss: 0.3698\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3544 - val_loss: 0.3678\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3521 - val_loss: 0.3684\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3533 - val_loss: 0.3669\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3537 - val_loss: 0.3668\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3517 - val_loss: 0.3662\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3499 - val_loss: 0.3658\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3496 - val_loss: 0.3636\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3488 - val_loss: 0.3657\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3481 - val_loss: 0.3637\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3479 - val_loss: 0.3623\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3472 - val_loss: 0.3619\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3489 - val_loss: 0.3631\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3746 - val_loss: 0.3626\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3458 - val_loss: 0.3625\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3449 - val_loss: 0.3701\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3472 - val_loss: 0.3605\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3443 - val_loss: 0.3961\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3524 - val_loss: 0.4424\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3581 - val_loss: 0.3596\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3444 - val_loss: 0.3592\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3438 - val_loss: 0.3577\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3404 - val_loss: 0.3578\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3433 - val_loss: 0.3766\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3676 - val_loss: 0.3581\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3456 - val_loss: 0.3584\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3425 - val_loss: 0.3558\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3462 - val_loss: 0.3572\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3393 - val_loss: 0.3558\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3383 - val_loss: 0.3571\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3365 - val_loss: 0.3549\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3362 - val_loss: 0.3536\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3349 - val_loss: 0.3522\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3360 - val_loss: 0.3540\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3347 - val_loss: 0.3524\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3352 - val_loss: 0.3524\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3375 - val_loss: 0.3501\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3435 - val_loss: 0.3502\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3316 - val_loss: 0.3506\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3340 - val_loss: 0.3511\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3328 - val_loss: 0.3674\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3385 - val_loss: 0.3480\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3308 - val_loss: 0.3491\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3331 - val_loss: 0.3512\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3359 - val_loss: 0.3485\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3300 - val_loss: 0.3484\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3285 - val_loss: 0.3466\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3348 - val_loss: 0.3523\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3280 - val_loss: 0.3463\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3290 - val_loss: 0.3475\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3294 - val_loss: 0.3455\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3269 - val_loss: 0.3468\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3262 - val_loss: 0.3448\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3255 - val_loss: 0.3437\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3245 - val_loss: 0.3442\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3263 - val_loss: 0.3422\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3241 - val_loss: 0.3438\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3235 - val_loss: 0.3434\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3356 - val_loss: 0.3451\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3231 - val_loss: 0.3433\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3228 - val_loss: 0.3462\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3230 - val_loss: 0.3426\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3211 - val_loss: 0.3408\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3212 - val_loss: 0.3503\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3234 - val_loss: 0.3453\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3302 - val_loss: 0.3413\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3248 - val_loss: 0.3406\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3218 - val_loss: 0.3403\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3312 - val_loss: 0.3409\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3294 - val_loss: 0.3398\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3251 - val_loss: 0.3375\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3195 - val_loss: 0.3375\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3181 - val_loss: 0.3382\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3171 - val_loss: 0.3412\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3228 - val_loss: 0.3410\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3188 - val_loss: 0.3419\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3188 - val_loss: 0.3361\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3178 - val_loss: 0.3364\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3164 - val_loss: 0.3389\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3149 - val_loss: 0.3368\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3190 - val_loss: 0.3363\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3151 - val_loss: 0.3350\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3152 - val_loss: 0.3357\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3141 - val_loss: 0.3381\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3144 - val_loss: 0.3368\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3150 - val_loss: 0.3352\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3121 - val_loss: 0.3346\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3126 - val_loss: 0.3370\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3133 - val_loss: 0.3357\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3126 - val_loss: 0.3408\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3153 - val_loss: 0.3342\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3120 - val_loss: 0.3327\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3113 - val_loss: 0.3315\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3118 - val_loss: 0.3311\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3108 - val_loss: 0.3317\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3126 - val_loss: 0.3318\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3197 - val_loss: 0.3324\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3157 - val_loss: 0.4124\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3911 - val_loss: 0.3311\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3152 - val_loss: 0.3313\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3106 - val_loss: 0.3303\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3086 - val_loss: 0.3310\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3188 - val_loss: 0.3321\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3119 - val_loss: 0.3405\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3119 - val_loss: 0.3331\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3078 - val_loss: 0.3301\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3078 - val_loss: 0.3311\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3179 - val_loss: 0.3281\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3094 - val_loss: 0.3307\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3065 - val_loss: 0.3312\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3090 - val_loss: 0.3355\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3066 - val_loss: 0.3298\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3060 - val_loss: 0.3274\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3063 - val_loss: 0.3277\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3056 - val_loss: 0.3278\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3061 - val_loss: 0.3335\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3100 - val_loss: 0.3267\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3056 - val_loss: 0.3256\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3066 - val_loss: 0.3268\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3092 - val_loss: 0.3506\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3106 - val_loss: 0.3376\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3100 - val_loss: 0.3309\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3052 - val_loss: 0.3253\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3143 - val_loss: 0.3281\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3121 - val_loss: 0.3288\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3065 - val_loss: 0.3261\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3047 - val_loss: 0.3255\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3055 - val_loss: 0.3270\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3019 - val_loss: 0.3266\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3038 - val_loss: 0.3296\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3299 - val_loss: 0.3289\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3035 - val_loss: 0.3262\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3027 - val_loss: 0.3273\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.4942\n",
      "[CV]  learning_rate=0.003833593497547869, n_hidden=1, n_neurons=67, total= 1.2min\n",
      "[CV] learning_rate=0.003833593497547869, n_hidden=1, n_neurons=67 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 1.2648 - val_loss: 0.6144\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.7468 - val_loss: 0.8919\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.8114 - val_loss: 0.5733\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6002 - val_loss: 0.5290\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5053 - val_loss: 0.4936\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4744 - val_loss: 0.4721\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4553 - val_loss: 0.4571\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4417 - val_loss: 0.4454\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4323 - val_loss: 0.4378\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4254 - val_loss: 0.4325\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4192 - val_loss: 0.4268\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4138 - val_loss: 0.4248\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4105 - val_loss: 0.4213\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4065 - val_loss: 0.4164\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4031 - val_loss: 0.4152\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4008 - val_loss: 0.4110\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3979 - val_loss: 0.4080\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3954 - val_loss: 0.4072\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3928 - val_loss: 0.4062\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3905 - val_loss: 0.4029\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3888 - val_loss: 0.4016\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3871 - val_loss: 0.4020\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3853 - val_loss: 0.4022\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3834 - val_loss: 0.3980\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3816 - val_loss: 0.3986\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3804 - val_loss: 0.3963\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3792 - val_loss: 0.3929\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3776 - val_loss: 0.3941\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3762 - val_loss: 0.3932\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3751 - val_loss: 0.3899\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3738 - val_loss: 0.3895\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3725 - val_loss: 0.3873\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3710 - val_loss: 0.3862\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3698 - val_loss: 0.3853\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3687 - val_loss: 0.3858\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3673 - val_loss: 0.3846\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3670 - val_loss: 0.3848\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3654 - val_loss: 0.3833\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3640 - val_loss: 0.3819\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3643 - val_loss: 0.3808\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3620 - val_loss: 0.3803\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3617 - val_loss: 0.3800\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3611 - val_loss: 0.3788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3601 - val_loss: 0.3798\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3582 - val_loss: 0.3778\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3576 - val_loss: 0.3808\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3577 - val_loss: 0.3765\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3567 - val_loss: 0.3771\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3561 - val_loss: 0.3757\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3544 - val_loss: 0.3758\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3548 - val_loss: 0.3738\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3534 - val_loss: 0.3733\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3524 - val_loss: 0.3766\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3513 - val_loss: 0.3737\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3507 - val_loss: 0.3733\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3514 - val_loss: 0.3705\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3506 - val_loss: 0.3719\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3489 - val_loss: 0.3697\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3487 - val_loss: 0.3702\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3486 - val_loss: 0.3699\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3470 - val_loss: 0.3683\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3465 - val_loss: 0.3695\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3462 - val_loss: 0.3694\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3449 - val_loss: 0.3705\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3455 - val_loss: 0.3679\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3441 - val_loss: 0.3672\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3437 - val_loss: 0.3669\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3428 - val_loss: 0.3668\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3423 - val_loss: 0.3660\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3417 - val_loss: 0.3674\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3403 - val_loss: 0.3652\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3403 - val_loss: 0.3658\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3401 - val_loss: 0.3653\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3394 - val_loss: 0.3637\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3387 - val_loss: 0.3638\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3373 - val_loss: 0.3621\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3371 - val_loss: 0.3671\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3372 - val_loss: 0.3618\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3363 - val_loss: 0.3670\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3360 - val_loss: 0.3611\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3350 - val_loss: 0.3621\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3345 - val_loss: 0.3622\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3340 - val_loss: 0.3610\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3331 - val_loss: 0.3644\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3334 - val_loss: 0.3595\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3323 - val_loss: 0.3632\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3323 - val_loss: 0.3598\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3315 - val_loss: 0.3599\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3318 - val_loss: 0.3586\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3310 - val_loss: 0.3587\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3300 - val_loss: 0.3560\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3295 - val_loss: 0.3569\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3290 - val_loss: 0.3574\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3294 - val_loss: 0.3560\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3287 - val_loss: 0.3606\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3284 - val_loss: 0.3577\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3277 - val_loss: 0.3554\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3279 - val_loss: 0.3544\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3274 - val_loss: 0.3578\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3268 - val_loss: 0.3596\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3279 - val_loss: 0.3543\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3259 - val_loss: 0.3542\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3259 - val_loss: 0.3532\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3261 - val_loss: 0.3550\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3250 - val_loss: 0.3585\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3255 - val_loss: 0.3551\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3240 - val_loss: 0.3568\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3233 - val_loss: 0.3543\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3237 - val_loss: 0.3508\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3224 - val_loss: 0.3542\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3218 - val_loss: 0.3588\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3232 - val_loss: 0.3516\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3224 - val_loss: 0.3532\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3217 - val_loss: 0.3515\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3214 - val_loss: 0.3509\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3218 - val_loss: 0.3505\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3202 - val_loss: 0.3494\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3204 - val_loss: 0.3530\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3201 - val_loss: 0.3505\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3196 - val_loss: 0.3575\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3222 - val_loss: 0.3495\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3190 - val_loss: 0.3490\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3189 - val_loss: 0.3492\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3179 - val_loss: 0.3507\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3183 - val_loss: 0.3466\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3177 - val_loss: 0.3517\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3166 - val_loss: 0.3517\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3165 - val_loss: 0.3512\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3156 - val_loss: 0.3478\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3167 - val_loss: 0.3473\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3152 - val_loss: 0.3497\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3157 - val_loss: 0.3456\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3148 - val_loss: 0.3511\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3160 - val_loss: 0.3456\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3134 - val_loss: 0.3458\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3145 - val_loss: 0.3462\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3130 - val_loss: 0.3496\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3130 - val_loss: 0.3449\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3140 - val_loss: 0.3451\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3125 - val_loss: 0.3499\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3125 - val_loss: 0.3466\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3127 - val_loss: 0.3439\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3117 - val_loss: 0.3433\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3116 - val_loss: 0.3445\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3110 - val_loss: 0.3443\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3108 - val_loss: 0.3438\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3117 - val_loss: 0.3461\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3115 - val_loss: 0.3447\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3109 - val_loss: 0.3424\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3098 - val_loss: 0.3430\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3101 - val_loss: 0.3448\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3089 - val_loss: 0.3449\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3094 - val_loss: 0.3441\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3087 - val_loss: 0.3435\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3082 - val_loss: 0.3425\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3084 - val_loss: 0.3418\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3087 - val_loss: 0.3446\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3074 - val_loss: 0.3454\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3075 - val_loss: 0.3452\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3075 - val_loss: 0.3415\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3068 - val_loss: 0.3430\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3069 - val_loss: 0.3404\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3067 - val_loss: 0.3400\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3073 - val_loss: 0.3426\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3052 - val_loss: 0.3478\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3060 - val_loss: 0.3408\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3055 - val_loss: 0.3426\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3053 - val_loss: 0.3407\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3044 - val_loss: 0.3437\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3034 - val_loss: 0.3449\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3038 - val_loss: 0.3434\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3032 - val_loss: 0.3404\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3043 - val_loss: 0.3399\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3033 - val_loss: 0.3381\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3036 - val_loss: 0.3391\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3027 - val_loss: 0.3467\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3036 - val_loss: 0.3392\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3024 - val_loss: 0.3383\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3019 - val_loss: 0.3387\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3015 - val_loss: 0.3370\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3015 - val_loss: 0.3398\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3026 - val_loss: 0.3368\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3013 - val_loss: 0.3366\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3008 - val_loss: 0.3389\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3015 - val_loss: 0.3375\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3010 - val_loss: 0.3391\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3003 - val_loss: 0.3387\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3002 - val_loss: 0.3372\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2999 - val_loss: 0.3364\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2996 - val_loss: 0.3387\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3008 - val_loss: 0.3371\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.2993 - val_loss: 0.3353\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.2985 - val_loss: 0.3342\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3003 - val_loss: 0.3337\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.2986 - val_loss: 0.3357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2994 - val_loss: 0.3343\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2978 - val_loss: 0.3414\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2977 - val_loss: 0.3349\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2982 - val_loss: 0.3348\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2977 - val_loss: 0.3344\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.2974 - val_loss: 0.3353\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2990 - val_loss: 0.3350\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2968 - val_loss: 0.3381\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2982 - val_loss: 0.3333\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2964 - val_loss: 0.3324\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2966 - val_loss: 0.3340\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2952 - val_loss: 0.3326\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.2959 - val_loss: 0.3327\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2961 - val_loss: 0.3327\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.2969 - val_loss: 0.3314\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2956 - val_loss: 0.3317\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2954 - val_loss: 0.3324\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.2953 - val_loss: 0.3356\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2953 - val_loss: 0.3355\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2962 - val_loss: 0.3302\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2960 - val_loss: 0.3323\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2956 - val_loss: 0.3294\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2953 - val_loss: 0.3307\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2966 - val_loss: 0.3300\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2957 - val_loss: 0.3311\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2977 - val_loss: 0.3323\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2970 - val_loss: 0.3298\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2984 - val_loss: 0.3475\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2993 - val_loss: 0.3310\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2972 - val_loss: 0.3417\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2952 - val_loss: 0.3318\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2966 - val_loss: 0.3319\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3544\n",
      "[CV]  learning_rate=0.003833593497547869, n_hidden=1, n_neurons=67, total= 1.4min\n",
      "[CV] learning_rate=0.0043535979440111295, n_hidden=0, n_neurons=98 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 2.2598 - val_loss: 0.6859\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6208 - val_loss: 0.5848\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5814 - val_loss: 0.5669\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5666 - val_loss: 0.5526\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5566 - val_loss: 0.5437\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5503 - val_loss: 0.5365\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5572 - val_loss: 0.5359\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5777 - val_loss: 0.5180\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7344 - val_loss: 0.5622\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.3494 - val_loss: 0.5235\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 3.9924 - val_loss: 0.7699\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 15.4377 - val_loss: 0.9831\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 63.2085 - val_loss: 3.1751\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 253.6729 - val_loss: 11.1734\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1051.7726 - val_loss: 66.1874\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 4800.7608 - val_loss: 164.9801\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 19714.7006 - val_loss: 873.4066\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 85975.3342 - val_loss: 2955.1552\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 1724.2204\n",
      "[CV]  learning_rate=0.0043535979440111295, n_hidden=0, n_neurons=98, total=   6.4s\n",
      "[CV] learning_rate=0.0043535979440111295, n_hidden=0, n_neurons=98 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.5288 - val_loss: 0.6991\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6164 - val_loss: 0.5908\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5782 - val_loss: 0.5721\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5624 - val_loss: 0.5682\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5589 - val_loss: 0.5476\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5442 - val_loss: 0.5473\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5419 - val_loss: 0.5313\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5348 - val_loss: 0.5574\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5397 - val_loss: 0.5342\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5209 - val_loss: 0.5188\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5347 - val_loss: 0.5163\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5302 - val_loss: 0.5151\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5234 - val_loss: 0.5139\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5184 - val_loss: 0.5122\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5192 - val_loss: 0.5340\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5171 - val_loss: 0.5093\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5202 - val_loss: 0.5097\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5178 - val_loss: 0.5082\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5284 - val_loss: 0.5094\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5098 - val_loss: 0.5071\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5194 - val_loss: 0.5073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5166 - val_loss: 0.5059\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5171 - val_loss: 0.5061\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5149 - val_loss: 0.5060\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5183 - val_loss: 0.5075\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5161 - val_loss: 0.5074\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5118 - val_loss: 0.5052\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5105 - val_loss: 0.5245\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5175 - val_loss: 0.5058\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5142 - val_loss: 0.5044\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5157 - val_loss: 0.5059\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5084 - val_loss: 0.5039\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5116 - val_loss: 0.5053\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5115 - val_loss: 0.5046\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5130 - val_loss: 0.5244\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5059 - val_loss: 0.5030\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5164 - val_loss: 0.5038\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5159 - val_loss: 0.5046\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5090 - val_loss: 0.5030\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5153 - val_loss: 0.5034\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5126 - val_loss: 0.5056\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5076 - val_loss: 0.5032\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5089 - val_loss: 0.5191\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5005 - val_loss: 0.5032\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5166 - val_loss: 0.5044\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5048 - val_loss: 0.5033\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5158 - val_loss: 0.5027\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5174 - val_loss: 0.5028\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5168 - val_loss: 0.5031\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5069 - val_loss: 0.5026\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5147 - val_loss: 0.5124\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5121 - val_loss: 0.5057\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5101 - val_loss: 0.5030\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5055 - val_loss: 0.5026\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5077 - val_loss: 0.5026\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5102 - val_loss: 0.5040\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5017 - val_loss: 0.5396\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5094 - val_loss: 0.5025\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5096 - val_loss: 0.5295\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5028 - val_loss: 0.5021\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5111 - val_loss: 0.5026\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5163 - val_loss: 0.5027\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5074 - val_loss: 0.5031\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5069 - val_loss: 0.5021\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5048 - val_loss: 0.5362\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5043 - val_loss: 0.5019\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5104 - val_loss: 0.5326\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5049 - val_loss: 0.5023\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5119 - val_loss: 0.5219\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5118 - val_loss: 0.5028\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5117 - val_loss: 0.5027\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5068 - val_loss: 0.5074\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5035 - val_loss: 0.5016\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5135 - val_loss: 0.5020\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5185 - val_loss: 0.5026\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5077 - val_loss: 0.5023\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5181 - val_loss: 0.5044\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5066 - val_loss: 0.5023\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5157 - val_loss: 0.5040\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5059 - val_loss: 0.5025\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5113 - val_loss: 0.5357\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5044 - val_loss: 0.5023\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5183 - val_loss: 0.5032\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 3.4284\n",
      "[CV]  learning_rate=0.0043535979440111295, n_hidden=0, n_neurons=98, total=  28.1s\n",
      "[CV] learning_rate=0.0043535979440111295, n_hidden=0, n_neurons=98 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 2.3048 - val_loss: 0.8061\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.7213 - val_loss: 0.6339\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 5.5404 - val_loss: 0.8913\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 21.3357 - val_loss: 1.1389\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 92.7469 - val_loss: 4.5355\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 399.5118 - val_loss: 15.0731\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1728.9404 - val_loss: 75.6762\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 7622.6228 - val_loss: 304.1346\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 34141.6454 - val_loss: 1243.3631\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 148363.8655 - val_loss: 5484.9078\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 629042.4162 - val_loss: 30239.1344\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 2767561.1108 - val_loss: 119947.1437\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 233204.7246\n",
      "[CV]  learning_rate=0.0043535979440111295, n_hidden=0, n_neurons=98, total=   4.3s\n",
      "[CV] learning_rate=0.009555525645540398, n_hidden=0, n_neurons=12 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.9695 - val_loss: 0.8573\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 14.6082 - val_loss: 4.6586\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 615.7079 - val_loss: 117.6398\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 16030.1988 - val_loss: 3362.6971\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 370815.2830 - val_loss: 107443.8489\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 13770586.2606 - val_loss: 2985185.0621\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 402311529.3165 - val_loss: 87353606.9974\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 9236597363.4977 - val_loss: 3394936962.6460\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 404452513638.5323 - val_loss: 76265456735.7850\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 9336445185347.3418 - val_loss: 2447245669924.7793\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 354586168878592.8125 - val_loss: 66591114498879.8984\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 38652782897504.4453\n",
      "[CV]  learning_rate=0.009555525645540398, n_hidden=0, n_neurons=12, total=   3.9s\n",
      "[CV] learning_rate=0.009555525645540398, n_hidden=0, n_neurons=12 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.5035 - val_loss: 0.7540\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6177 - val_loss: 0.5837\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5513 - val_loss: 0.5530\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5298 - val_loss: 0.5637\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5355 - val_loss: 0.5216\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5148 - val_loss: 0.5173\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5133 - val_loss: 0.5122\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5299 - val_loss: 0.5154\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5059 - val_loss: 0.5065\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5179 - val_loss: 0.5062\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5153 - val_loss: 0.6548\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5790 - val_loss: 0.5032\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5577 - val_loss: 0.5038\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5477 - val_loss: 0.5087\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5079 - val_loss: 0.5048\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5167 - val_loss: 0.5040\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5552 - val_loss: 0.5053\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5260 - val_loss: 0.5335\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5130 - val_loss: 0.5058\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5276 - val_loss: 0.5027\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5434 - val_loss: 0.5056\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5190 - val_loss: 0.5346\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5133 - val_loss: 0.5055\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5456 - val_loss: 0.5069\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5371 - val_loss: 0.5049\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5430 - val_loss: 0.5040\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5081 - val_loss: 0.5038\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5032 - val_loss: 0.5499\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5064 - val_loss: 0.5026\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5577 - val_loss: 0.5177\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5131 - val_loss: 0.5031\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5267 - val_loss: 0.5008\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5216 - val_loss: 0.5028\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5502 - val_loss: 0.5061\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5416 - val_loss: 0.5041\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5250 - val_loss: 0.5059\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5343 - val_loss: 0.5022\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5231 - val_loss: 0.5045\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5256 - val_loss: 0.5040\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5231 - val_loss: 0.5036\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5333 - val_loss: 0.5052\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5191 - val_loss: 0.5049\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 3.6373\n",
      "[CV]  learning_rate=0.009555525645540398, n_hidden=0, n_neurons=12, total=  14.8s\n",
      "[CV] learning_rate=0.009555525645540398, n_hidden=0, n_neurons=12 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 2.1443 - val_loss: 0.6074\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 25.9817 - val_loss: 6.9304\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 753.7153 - val_loss: 183.5890\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 25230.1491 - val_loss: 5973.4800\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 726230.4503 - val_loss: 200951.5884\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 22498261.7874 - val_loss: 6739561.7140\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 721160248.8780 - val_loss: 227666300.2667\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 24683921079.9959 - val_loss: 6610650744.9220\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 743198695970.9271 - val_loss: 254455379281.0998\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 26032346402005.2695 - val_loss: 6704383299365.9697\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 787469828701573.0000 - val_loss: 224443742433252.4688\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 448528898887123.3125\n",
      "[CV]  learning_rate=0.009555525645540398, n_hidden=0, n_neurons=12, total=   4.0s\n",
      "[CV] learning_rate=0.007937577587092086, n_hidden=1, n_neurons=85 ....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.0357 - val_loss: 0.6704\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.2305 - val_loss: 0.5665\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.8241 - val_loss: 0.4816\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5393 - val_loss: 0.4497\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5365 - val_loss: 0.4304\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4419 - val_loss: 0.4069\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3965 - val_loss: 0.3935\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4001 - val_loss: 0.3858\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3831 - val_loss: 0.3803\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3807 - val_loss: 0.4025\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3822 - val_loss: 0.3731\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4348 - val_loss: 0.3910\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3913 - val_loss: 0.3771\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3825 - val_loss: 0.3707\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3724 - val_loss: 0.3651\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3737 - val_loss: 0.3675\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3609 - val_loss: 0.3598\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3749 - val_loss: 0.3598\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3834 - val_loss: 0.3605\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3624 - val_loss: 0.3738\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3535 - val_loss: 0.3580\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3488 - val_loss: 0.3501\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3506 - val_loss: 0.3563\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3443 - val_loss: 0.3503\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3558 - val_loss: 0.3492\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3438 - val_loss: 0.3441\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3464 - val_loss: 0.3444\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3403 - val_loss: 0.3448\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3432 - val_loss: 0.3384\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3361 - val_loss: 0.3389\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3599 - val_loss: 0.3437\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3556 - val_loss: 0.3394\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3585 - val_loss: 0.3506\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3663 - val_loss: 0.3483\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3351 - val_loss: 0.3392\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3389 - val_loss: 0.3398\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3301 - val_loss: 0.3369\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3279 - val_loss: 0.3350\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3300 - val_loss: 0.3362\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3268 - val_loss: 0.3481\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3315 - val_loss: 0.3462\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3243 - val_loss: 0.3364\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3277 - val_loss: 0.3327\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3208 - val_loss: 0.3292\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3255 - val_loss: 0.3390\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3218 - val_loss: 0.3358\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3259 - val_loss: 0.3304\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3191 - val_loss: 0.3320\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3327 - val_loss: 0.3280\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3197 - val_loss: 0.3277\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3315 - val_loss: 0.3284\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3384 - val_loss: 0.3273\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3166 - val_loss: 0.3335\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3245 - val_loss: 0.3268\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3142 - val_loss: 0.3268\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3131 - val_loss: 0.3431\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3181 - val_loss: 0.3268\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3152 - val_loss: 0.3223\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3126 - val_loss: 0.3981\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3916 - val_loss: 0.3355\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3306 - val_loss: 0.8171\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3492 - val_loss: 0.3768\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3206 - val_loss: 0.3283\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3125 - val_loss: 0.3221\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3241 - val_loss: 0.3202\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3114 - val_loss: 0.3218\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3120 - val_loss: 0.3190\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3079 - val_loss: 0.3189\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3062 - val_loss: 0.3206\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3066 - val_loss: 0.3203\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3055 - val_loss: 0.3213\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3058 - val_loss: 0.3174\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3038 - val_loss: 0.3223\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3153 - val_loss: 0.3152\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3049 - val_loss: 0.3191\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3029 - val_loss: 0.3187\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3029 - val_loss: 0.3190\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3036 - val_loss: 0.3173\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3058 - val_loss: 0.3309\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3023 - val_loss: 0.3175\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3009 - val_loss: 0.3167\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3001 - val_loss: 0.3096\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2993 - val_loss: 0.3136\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2994 - val_loss: 0.3124\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2989 - val_loss: 0.3183\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2991 - val_loss: 0.3182\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3096 - val_loss: 0.3114\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2972 - val_loss: 0.3146\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2966 - val_loss: 0.3093\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2964 - val_loss: 0.3100\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2957 - val_loss: 0.3118\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2961 - val_loss: 0.3126\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2956 - val_loss: 0.3210\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2948 - val_loss: 0.3093\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2937 - val_loss: 0.3082\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2946 - val_loss: 0.3096\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2940 - val_loss: 0.3145\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2938 - val_loss: 0.3078\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2931 - val_loss: 0.3103\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2927 - val_loss: 0.3095\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2922 - val_loss: 0.3172\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2909 - val_loss: 0.3066\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2901 - val_loss: 0.3084\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2905 - val_loss: 0.3066\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2898 - val_loss: 0.3118\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2903 - val_loss: 0.3068\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2895 - val_loss: 0.3096\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2913 - val_loss: 0.3076\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2900 - val_loss: 0.3051\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2875 - val_loss: 0.3287\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3127 - val_loss: 0.3156\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3095 - val_loss: 0.3125\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2951 - val_loss: 0.4088\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3085 - val_loss: 0.3068\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2897 - val_loss: 0.3059\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2885 - val_loss: 0.3068\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2901 - val_loss: 0.3023\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2868 - val_loss: 0.3076\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3036 - val_loss: 0.3092\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3266 - val_loss: 0.3187\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2949 - val_loss: 0.3084\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2890 - val_loss: 0.3060\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2906 - val_loss: 0.3094\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2885 - val_loss: 0.3141\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2862 - val_loss: 0.3033\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2856 - val_loss: 0.3155\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2874 - val_loss: 0.3107\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.2886\n",
      "[CV]  learning_rate=0.007937577587092086, n_hidden=1, n_neurons=85, total=  46.0s\n",
      "[CV] learning_rate=0.007937577587092086, n_hidden=1, n_neurons=85 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.9046 - val_loss: 0.5805\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5512 - val_loss: 0.5138\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5003 - val_loss: 0.4868\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4715 - val_loss: 0.4655\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4526 - val_loss: 0.4530\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4440 - val_loss: 0.4453\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4434 - val_loss: 0.4402\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4298 - val_loss: 0.4630\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4319 - val_loss: 0.4290\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4170 - val_loss: 0.4234\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4132 - val_loss: 0.4501\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4096 - val_loss: 0.4152\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4187 - val_loss: 0.4113\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4116 - val_loss: 0.4092\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4152 - val_loss: 0.4072\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3951 - val_loss: 0.4064\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3944 - val_loss: 0.4061\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3990 - val_loss: 0.4045\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3895 - val_loss: 0.5393\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5479 - val_loss: 0.4020\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3877 - val_loss: 0.3986\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3842 - val_loss: 0.3982\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3812 - val_loss: 0.3937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3805 - val_loss: 0.3975\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3765 - val_loss: 0.3889\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3739 - val_loss: 0.3885\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3746 - val_loss: 0.3869\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3756 - val_loss: 0.3841\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3686 - val_loss: 0.3832\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3668 - val_loss: 0.3830\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3670 - val_loss: 0.3785\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3710 - val_loss: 0.3801\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3648 - val_loss: 0.3795\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3678 - val_loss: 0.3850\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3611 - val_loss: 0.3764\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3587 - val_loss: 0.3750\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3668 - val_loss: 0.3723\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3583 - val_loss: 0.3735\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3635 - val_loss: 0.3683\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3534 - val_loss: 0.3732\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3517 - val_loss: 0.3689\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3494 - val_loss: 0.3654\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3487 - val_loss: 0.3686\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3467 - val_loss: 0.3640\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3467 - val_loss: 0.3730\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3454 - val_loss: 0.3627\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3830 - val_loss: 0.3623\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3444 - val_loss: 0.3617\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3427 - val_loss: 0.3663\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3442 - val_loss: 0.3618\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3397 - val_loss: 0.3613\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3400 - val_loss: 0.3626\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3451 - val_loss: 0.3585\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3394 - val_loss: 0.3831\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3408 - val_loss: 0.3550\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3347 - val_loss: 0.3541\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3366 - val_loss: 0.3565\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3380 - val_loss: 0.3528\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3355 - val_loss: 0.3539\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3348 - val_loss: 0.3542\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3320 - val_loss: 0.3508\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3304 - val_loss: 0.3681\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3323 - val_loss: 0.3478\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3288 - val_loss: 0.3469\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3310 - val_loss: 0.3450\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3293 - val_loss: 0.3498\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3285 - val_loss: 0.3483\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3276 - val_loss: 0.3453\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3323 - val_loss: 0.3465\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3258 - val_loss: 0.3458\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3268 - val_loss: 0.3434\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3231 - val_loss: 0.3556\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3236 - val_loss: 0.3438\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3226 - val_loss: 0.3405\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3205 - val_loss: 0.3405\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3309 - val_loss: 0.3416\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3203 - val_loss: 0.3410\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3317 - val_loss: 0.3408\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3190 - val_loss: 0.3533\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3302 - val_loss: 0.3412\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3304 - val_loss: 0.3446\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3274 - val_loss: 0.3464\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3180 - val_loss: 0.3459\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3176 - val_loss: 0.3364\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3220 - val_loss: 0.3455\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3177 - val_loss: 0.3621\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3185 - val_loss: 0.3393\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3144 - val_loss: 0.3333\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3156 - val_loss: 0.3343\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3147 - val_loss: 0.3342\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3189 - val_loss: 0.3584\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3723 - val_loss: 0.3366\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3213 - val_loss: 0.3406\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3163 - val_loss: 0.3346\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3132 - val_loss: 0.3354\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3129 - val_loss: 0.3330\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3140 - val_loss: 0.3332\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3128 - val_loss: 0.3358\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3095 - val_loss: 0.3305\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3172 - val_loss: 0.3341\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3153 - val_loss: 0.3485\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3136 - val_loss: 0.3360\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3117 - val_loss: 0.3339\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3082 - val_loss: 0.3341\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3080 - val_loss: 0.3350\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3071 - val_loss: 0.3298\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3070 - val_loss: 0.3318\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3118 - val_loss: 0.3292\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3170 - val_loss: 0.3440\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3130 - val_loss: 0.3316\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3119 - val_loss: 0.3308\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3057 - val_loss: 0.3268\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3298 - val_loss: 0.3320\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3223 - val_loss: 0.3315\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3048 - val_loss: 0.3313\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3068 - val_loss: 0.3307\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3065 - val_loss: 0.3265\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3126 - val_loss: 0.3287\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3075 - val_loss: 0.3312\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3063 - val_loss: 0.4509\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3376 - val_loss: 0.3323\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3039 - val_loss: 0.3284\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3054 - val_loss: 0.3253\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3024 - val_loss: 0.3235\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3016 - val_loss: 0.3286\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3017 - val_loss: 0.3252\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3020 - val_loss: 0.3297\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3007 - val_loss: 0.3244\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3001 - val_loss: 0.3232\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2990 - val_loss: 0.3234\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3003 - val_loss: 0.3257\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3058 - val_loss: 0.3256\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3014 - val_loss: 0.3356\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3016 - val_loss: 0.3217\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2981 - val_loss: 0.3271\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3058 - val_loss: 0.3302\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3015 - val_loss: 0.3229\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2979 - val_loss: 0.3226\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2975 - val_loss: 0.3234\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2987 - val_loss: 0.3226\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2975 - val_loss: 0.3226\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2972 - val_loss: 0.3225\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2973 - val_loss: 0.3216\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2966 - val_loss: 0.3193\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2998 - val_loss: 0.3347\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2986 - val_loss: 0.3218\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2978 - val_loss: 0.3230\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2999 - val_loss: 0.3294\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2974 - val_loss: 0.3220\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2963 - val_loss: 0.3303\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2966 - val_loss: 0.3242\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2976 - val_loss: 0.3340\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2950 - val_loss: 0.3259\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2954 - val_loss: 0.3231\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.8582\n",
      "[CV]  learning_rate=0.007937577587092086, n_hidden=1, n_neurons=85, total=  55.2s\n",
      "[CV] learning_rate=0.007937577587092086, n_hidden=1, n_neurons=85 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.0475 - val_loss: 0.5863\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 5.6490 - val_loss: 0.7275\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5335 - val_loss: 0.4898\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4179 - val_loss: 0.4267\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3825 - val_loss: 0.4071\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3665 - val_loss: 0.3964\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3627 - val_loss: 0.3916\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3549 - val_loss: 0.3815\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3492 - val_loss: 0.3828\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3481 - val_loss: 0.3808\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3450 - val_loss: 0.3740\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3418 - val_loss: 0.3683\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3408 - val_loss: 0.3680\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3381 - val_loss: 0.3718\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3371 - val_loss: 0.3639\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3360 - val_loss: 0.3663\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3346 - val_loss: 0.3693\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3337 - val_loss: 0.3625\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3310 - val_loss: 0.3642\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3323 - val_loss: 0.3613\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3297 - val_loss: 0.3648\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3290 - val_loss: 0.3632\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3274 - val_loss: 0.3609\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3267 - val_loss: 0.3646\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3280 - val_loss: 0.3640\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3261 - val_loss: 0.3556\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3248 - val_loss: 0.3597\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3242 - val_loss: 0.3611\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3221 - val_loss: 0.3587\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3245 - val_loss: 0.3538\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3222 - val_loss: 0.3624\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3217 - val_loss: 0.3606\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3210 - val_loss: 0.3518\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3202 - val_loss: 0.3520\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3209 - val_loss: 0.3493\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3196 - val_loss: 0.3506\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3202 - val_loss: 0.3501\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3169 - val_loss: 0.3558\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3163 - val_loss: 0.3527\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3159 - val_loss: 0.3514\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3160 - val_loss: 0.3534\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3151 - val_loss: 0.3519\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3142 - val_loss: 0.3522\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3138 - val_loss: 0.3621\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3119 - val_loss: 0.3469\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3122 - val_loss: 0.3486\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3118 - val_loss: 0.3512\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3133 - val_loss: 0.3510\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3117 - val_loss: 0.3472\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3090 - val_loss: 0.3508\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3106 - val_loss: 0.3439\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3092 - val_loss: 0.3483\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3093 - val_loss: 0.3464\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3099 - val_loss: 0.3464\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3078 - val_loss: 0.3477\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3069 - val_loss: 0.3484\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3079 - val_loss: 0.3543\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3064 - val_loss: 0.3468\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3060 - val_loss: 0.3466\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3069 - val_loss: 0.3484\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3055 - val_loss: 0.3456\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.3790\n",
      "[CV]  learning_rate=0.007937577587092086, n_hidden=1, n_neurons=85, total=  22.4s\n",
      "[CV] learning_rate=0.009137035796659016, n_hidden=1, n_neurons=37 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 1.5493 - val_loss: 0.6225\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 1.0489 - val_loss: 0.6331\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 3.4973 - val_loss: 0.5395\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5230 - val_loss: 0.4804\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4884 - val_loss: 0.4584\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4494 - val_loss: 0.4344\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4368 - val_loss: 0.4209\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4139 - val_loss: 0.4076\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4032 - val_loss: 0.4037\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3944 - val_loss: 0.3965\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3882 - val_loss: 0.3880\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4981 - val_loss: 0.4216\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4049 - val_loss: 0.3885\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3960 - val_loss: 0.4451\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3870 - val_loss: 0.3813\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3739 - val_loss: 0.3698\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3686 - val_loss: 0.3666\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3638 - val_loss: 0.3710\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3601 - val_loss: 0.3694\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3579 - val_loss: 0.3608\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3556 - val_loss: 0.3559\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3536 - val_loss: 0.3546\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3521 - val_loss: 0.3559\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3497 - val_loss: 0.3533\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3478 - val_loss: 0.3531\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3475 - val_loss: 0.3489\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3450 - val_loss: 0.3537\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3433 - val_loss: 0.3479\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3419 - val_loss: 0.3461\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3400 - val_loss: 0.3469\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3386 - val_loss: 0.3456\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3380 - val_loss: 0.3494\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3391 - val_loss: 0.3497\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3382 - val_loss: 0.3445\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3351 - val_loss: 0.3471\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3348 - val_loss: 0.3422\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3339 - val_loss: 0.3420\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3322 - val_loss: 0.3412\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3318 - val_loss: 0.3380\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3294 - val_loss: 0.3372\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3288 - val_loss: 0.3428\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3285 - val_loss: 0.3381\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3276 - val_loss: 0.3373\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3337 - val_loss: 0.3370\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3315 - val_loss: 0.3394\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3354 - val_loss: 0.3335\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3268 - val_loss: 0.3419\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3268 - val_loss: 0.3358\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3362 - val_loss: 0.3503\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3279 - val_loss: 0.3427\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3332 - val_loss: 0.3465\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3240 - val_loss: 0.3375\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3228 - val_loss: 0.3362\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3212 - val_loss: 0.3385\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3215 - val_loss: 0.3345\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3196 - val_loss: 0.3365\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3173\n",
      "[CV]  learning_rate=0.009137035796659016, n_hidden=1, n_neurons=37, total=  19.5s\n",
      "[CV] learning_rate=0.009137035796659016, n_hidden=1, n_neurons=37 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.9304 - val_loss: 0.5794\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5591 - val_loss: 0.5219\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5213 - val_loss: 0.4939\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4853 - val_loss: 0.4737\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4664 - val_loss: 0.4644\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4554 - val_loss: 0.4542\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4478 - val_loss: 0.4457\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4364 - val_loss: 0.4411\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4341 - val_loss: 0.4325\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4238 - val_loss: 0.4304\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4199 - val_loss: 0.4515\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4389 - val_loss: 0.4217\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4111 - val_loss: 0.4257\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4154 - val_loss: 0.4156\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4083 - val_loss: 0.4178\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4011 - val_loss: 0.4158\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4082 - val_loss: 0.4256\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3988 - val_loss: 0.4108\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4012 - val_loss: 0.4057\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3921 - val_loss: 0.4026\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3891 - val_loss: 0.4006\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3914 - val_loss: 0.3991\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3844 - val_loss: 0.3979\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3986 - val_loss: 0.3965\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3842 - val_loss: 0.3974\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3792 - val_loss: 0.3936\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3847 - val_loss: 0.4139\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3852 - val_loss: 0.3905\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3740 - val_loss: 0.3841\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3745 - val_loss: 0.3849\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3703 - val_loss: 0.3863\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3714 - val_loss: 0.3998\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3680 - val_loss: 0.4094\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3674 - val_loss: 0.3783\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3659 - val_loss: 0.3773\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3869 - val_loss: 0.3837\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3730 - val_loss: 0.4362\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3859 - val_loss: 0.3779\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3627 - val_loss: 0.3756\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3581 - val_loss: 0.3718\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3568 - val_loss: 0.3686\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3548 - val_loss: 0.3734\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3575 - val_loss: 0.3717\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3535 - val_loss: 0.3672\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3587 - val_loss: 0.3657\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3509 - val_loss: 0.3693\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3699 - val_loss: 0.3732\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3529 - val_loss: 0.3710\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3528 - val_loss: 0.3667\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3550 - val_loss: 0.3655\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3710 - val_loss: 0.3662\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3471 - val_loss: 0.3608\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3455 - val_loss: 0.3658\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3425 - val_loss: 0.3586\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3479 - val_loss: 0.3604\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3445 - val_loss: 0.3612\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3401 - val_loss: 0.3589\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3410 - val_loss: 0.3548\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3403 - val_loss: 0.3547\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4086 - val_loss: 0.3664\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3487 - val_loss: 0.3551\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3520 - val_loss: 0.3665\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3586 - val_loss: 0.3520\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3433 - val_loss: 0.3544\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3352 - val_loss: 0.3498\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3388 - val_loss: 0.3643\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3378 - val_loss: 0.3614\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3355 - val_loss: 0.3601\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3332 - val_loss: 0.3491\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3318 - val_loss: 0.3458\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3300 - val_loss: 0.3461\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3304 - val_loss: 0.3494\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3291 - val_loss: 0.3477\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3297 - val_loss: 0.3579\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3274 - val_loss: 0.3542\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3274 - val_loss: 0.3416\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3272 - val_loss: 0.3671\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3374 - val_loss: 0.3538\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3250 - val_loss: 0.3454\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3253 - val_loss: 0.3417\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3255 - val_loss: 0.3421\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4410 - val_loss: 0.3831\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3872 - val_loss: 0.6642\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3697 - val_loss: 0.3631\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3487 - val_loss: 0.3562\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3607 - val_loss: 0.3520\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3725\n",
      "[CV]  learning_rate=0.009137035796659016, n_hidden=1, n_neurons=37, total=  30.3s\n",
      "[CV] learning_rate=0.009137035796659016, n_hidden=1, n_neurons=37 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.9084 - val_loss: 0.6082\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 5.9173 - val_loss: 0.5031\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4610 - val_loss: 0.4360\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4183 - val_loss: 0.4139\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4049 - val_loss: 0.4151\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3979 - val_loss: 0.4078\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3908 - val_loss: 0.4014\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3856 - val_loss: 0.3948\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3813 - val_loss: 0.3924\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3791 - val_loss: 0.3923\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3770 - val_loss: 0.3863\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3753 - val_loss: 0.3892\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3735 - val_loss: 0.3857\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3714 - val_loss: 0.3835\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3695 - val_loss: 0.3828\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3670 - val_loss: 0.3788\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3675 - val_loss: 0.3786\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3636 - val_loss: 0.3846\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3644 - val_loss: 0.3785\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3614 - val_loss: 0.3757\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3601 - val_loss: 0.3770\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3597 - val_loss: 0.3717\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3588 - val_loss: 0.3731\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3568 - val_loss: 0.3744\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3563 - val_loss: 0.3734\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3575 - val_loss: 0.3714\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3554 - val_loss: 0.3699\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3531 - val_loss: 0.3701\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3522 - val_loss: 0.3932\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3522 - val_loss: 0.3720\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3495 - val_loss: 0.3759\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3501 - val_loss: 0.3692\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3498 - val_loss: 0.3660\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3467 - val_loss: 0.3660\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3484 - val_loss: 0.3728\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3470 - val_loss: 0.3692\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3465 - val_loss: 0.3688\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3455 - val_loss: 0.3691\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3444 - val_loss: 0.3678\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3427 - val_loss: 0.3634\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3401 - val_loss: 0.3710\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3410 - val_loss: 0.3606\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3394 - val_loss: 0.3600\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3385 - val_loss: 0.3576\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3374 - val_loss: 0.3778\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3372 - val_loss: 0.3598\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3364 - val_loss: 0.3596\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3348 - val_loss: 0.3676\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3340 - val_loss: 0.3611\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3357 - val_loss: 0.3556\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3324 - val_loss: 0.3524\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3305 - val_loss: 0.3550\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3322 - val_loss: 0.3566\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3317 - val_loss: 0.3523\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3301 - val_loss: 0.3506\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3287 - val_loss: 0.3631\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3311 - val_loss: 0.3576\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3282 - val_loss: 0.3594\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3288 - val_loss: 0.3493\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3270 - val_loss: 0.3629\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3263 - val_loss: 0.3547\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3261 - val_loss: 0.3483\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3266 - val_loss: 0.3501\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3246 - val_loss: 0.3445\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3237 - val_loss: 0.3504\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3217 - val_loss: 0.3501\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3256 - val_loss: 0.3443\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3252 - val_loss: 0.3447\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3209 - val_loss: 0.3501\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3203 - val_loss: 0.3518\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3196 - val_loss: 0.3511\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3186 - val_loss: 0.3468\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3176 - val_loss: 0.3441\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3179 - val_loss: 0.3459\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3227 - val_loss: 0.3578\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3163 - val_loss: 0.3437\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3175 - val_loss: 0.3408\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3175 - val_loss: 0.3425\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3151 - val_loss: 0.3497\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3167 - val_loss: 0.3433\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3160 - val_loss: 0.3395\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3146 - val_loss: 0.3396\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3152 - val_loss: 0.3427\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3163 - val_loss: 0.3407\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3133 - val_loss: 0.3430\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3130 - val_loss: 0.3412\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3119 - val_loss: 0.3439\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3135 - val_loss: 0.3458\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3128 - val_loss: 0.3427\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3105 - val_loss: 0.3417\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3114 - val_loss: 0.3463\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3939\n",
      "[CV]  learning_rate=0.009137035796659016, n_hidden=1, n_neurons=37, total=  31.4s\n",
      "[CV] learning_rate=0.007385522464208557, n_hidden=3, n_neurons=45 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.8835 - val_loss: 0.5244\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5050 - val_loss: 0.4656\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4703 - val_loss: 0.4289\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4325 - val_loss: 0.4335\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4137 - val_loss: 0.4153\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4033 - val_loss: 0.4041\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3942 - val_loss: 0.3967\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3888 - val_loss: 0.3820\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3845 - val_loss: 0.3837\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3780 - val_loss: 0.3847\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3749 - val_loss: 0.3727\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3727 - val_loss: 0.3760\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3678 - val_loss: 0.3712\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3624 - val_loss: 0.3755\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3597 - val_loss: 0.3595\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3546 - val_loss: 0.3830\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3535 - val_loss: 0.3531\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3510 - val_loss: 0.3600\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3479 - val_loss: 0.3534\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3420 - val_loss: 0.3466\n",
      "Epoch 21/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3399 - val_loss: 0.3473\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3382 - val_loss: 0.3458\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3371 - val_loss: 0.3465\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3336 - val_loss: 0.3356\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3317 - val_loss: 0.3367\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3291 - val_loss: 0.3311\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3269 - val_loss: 0.3408\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3246 - val_loss: 0.3351\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3236 - val_loss: 0.3427\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3203 - val_loss: 0.3276\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3188 - val_loss: 0.3964\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3193 - val_loss: 0.3224\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3150 - val_loss: 0.3492\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3146 - val_loss: 0.3297\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3120 - val_loss: 0.3222\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3104 - val_loss: 0.3251\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3103 - val_loss: 0.3334\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3070 - val_loss: 0.3222\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3050 - val_loss: 0.3191\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3068 - val_loss: 0.3161\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3019 - val_loss: 0.3282\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3007 - val_loss: 0.3187\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2993 - val_loss: 0.3266\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2980 - val_loss: 0.3269\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2990 - val_loss: 0.3221\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2974 - val_loss: 0.3171\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2960 - val_loss: 0.3145\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2942 - val_loss: 0.3135\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2926 - val_loss: 0.3133\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2924 - val_loss: 0.3073\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2921 - val_loss: 0.3210\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2909 - val_loss: 0.3265\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2897 - val_loss: 0.3269\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2878 - val_loss: 0.3120\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2907 - val_loss: 0.3250\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2878 - val_loss: 0.3245\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2904 - val_loss: 0.3431\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2876 - val_loss: 0.3048\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2864 - val_loss: 0.3089\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2840 - val_loss: 0.3021\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2804 - val_loss: 0.3087\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2834 - val_loss: 0.3079\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2829 - val_loss: 0.3058\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2813 - val_loss: 0.3029\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2804 - val_loss: 0.3224\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2802 - val_loss: 0.3091\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2799 - val_loss: 0.3013\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2781 - val_loss: 0.3009\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2788 - val_loss: 0.3106\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.2754 - val_loss: 0.3276\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2771 - val_loss: 0.3037\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2755 - val_loss: 0.2980\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.2760 - val_loss: 0.3216\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2739 - val_loss: 0.3209\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2734 - val_loss: 0.3291\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.2762 - val_loss: 0.3078\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.2706 - val_loss: 0.2997\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2708 - val_loss: 0.3116\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2715 - val_loss: 0.3182\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2724 - val_loss: 0.3320\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2695 - val_loss: 0.2960\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2706 - val_loss: 0.3011\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2716 - val_loss: 0.3048\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2697 - val_loss: 0.3027\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2713 - val_loss: 0.3045\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2690 - val_loss: 0.2967\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2682 - val_loss: 0.3187\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2669 - val_loss: 0.2999\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2657 - val_loss: 0.3001\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2669 - val_loss: 0.2950\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2639 - val_loss: 0.2984\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2659 - val_loss: 0.3043\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2626 - val_loss: 0.2970\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2657 - val_loss: 0.2949\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2613 - val_loss: 0.3143\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2629 - val_loss: 0.3809\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2632 - val_loss: 0.3379\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2619 - val_loss: 0.3088\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2620 - val_loss: 0.2934\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2599 - val_loss: 0.3004\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2602 - val_loss: 0.2955\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.2624 - val_loss: 0.2948\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.2613 - val_loss: 0.2905\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.2606 - val_loss: 0.2956\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.2598 - val_loss: 0.3229\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.2615 - val_loss: 0.2907\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2587 - val_loss: 0.2899\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2590 - val_loss: 0.3100\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2612 - val_loss: 0.2935\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2592 - val_loss: 0.3855\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2581 - val_loss: 0.2956\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.2571 - val_loss: 0.3073\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2561 - val_loss: 0.3012\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2556 - val_loss: 0.2966\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.2571 - val_loss: 0.3078\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2572 - val_loss: 0.2890\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2640 - val_loss: 0.2922\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2587 - val_loss: 0.2937\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2721 - val_loss: 0.3000\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2894 - val_loss: 0.2953\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2702 - val_loss: 0.2923\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2552 - val_loss: 0.2891\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2561 - val_loss: 0.2967\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2555 - val_loss: 0.3007\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.2557 - val_loss: 0.2966\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.2551 - val_loss: 0.2907\n",
      "3870/3870 [==============================] - 0s 24us/sample - loss: 0.2690\n",
      "[CV]  learning_rate=0.007385522464208557, n_hidden=3, n_neurons=45, total=  55.3s\n",
      "[CV] learning_rate=0.007385522464208557, n_hidden=3, n_neurons=45 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 1.0203 - val_loss: 0.5693\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5235 - val_loss: 0.5053\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4892 - val_loss: 0.4645\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4390 - val_loss: 0.4426\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4190 - val_loss: 0.4307\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4143 - val_loss: 0.4114\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3992 - val_loss: 0.4074\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3924 - val_loss: 0.3969\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3897 - val_loss: 0.3969\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3788 - val_loss: 0.3980\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3746 - val_loss: 0.3819\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3692 - val_loss: 0.3742\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3648 - val_loss: 0.3717\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3642 - val_loss: 0.3680\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3579 - val_loss: 0.3649\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3542 - val_loss: 0.3766\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3500 - val_loss: 0.3625\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3459 - val_loss: 0.3737\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3430 - val_loss: 0.3552\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3407 - val_loss: 0.3488\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3376 - val_loss: 0.3472\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3349 - val_loss: 0.3443\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3337 - val_loss: 0.3637\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3335 - val_loss: 0.3412\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3292 - val_loss: 0.3428\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3247 - val_loss: 0.3509\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3250 - val_loss: 0.3539\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3210 - val_loss: 0.3470\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3191 - val_loss: 0.3326\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3167 - val_loss: 0.3559\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3154 - val_loss: 0.3352\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3124 - val_loss: 0.3298\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3106 - val_loss: 0.3411\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3096 - val_loss: 0.3510\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3079 - val_loss: 0.3296\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3056 - val_loss: 0.3221\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3025 - val_loss: 0.3255\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3018 - val_loss: 0.3405\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2998 - val_loss: 0.3301\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2984 - val_loss: 0.3224\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2971 - val_loss: 0.3324\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3006 - val_loss: 0.3291\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2950 - val_loss: 0.3175\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2952 - val_loss: 0.3589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.2926 - val_loss: 0.3286\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2928 - val_loss: 0.3149\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.2906 - val_loss: 0.3177\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2905 - val_loss: 0.3512\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2908 - val_loss: 0.3167\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2862 - val_loss: 0.3138\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2866 - val_loss: 0.3123\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2839 - val_loss: 0.3077\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2830 - val_loss: 0.3327\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2827 - val_loss: 0.3105\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2814 - val_loss: 0.3086\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2850 - val_loss: 0.3065\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2817 - val_loss: 0.3104\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2809 - val_loss: 0.3129\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2791 - val_loss: 0.3128\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2785 - val_loss: 0.3341\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.2809 - val_loss: 0.3137\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2795 - val_loss: 0.3228\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.2772 - val_loss: 0.3088\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2753 - val_loss: 0.3007\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2770 - val_loss: 0.3143\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2748 - val_loss: 0.3154\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2729 - val_loss: 0.3046\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2724 - val_loss: 0.3216\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2744 - val_loss: 0.3041\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2701 - val_loss: 0.3765\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2718 - val_loss: 0.2996\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2716 - val_loss: 0.3049\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2707 - val_loss: 0.3045\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2677 - val_loss: 0.3016\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2685 - val_loss: 0.2998\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2679 - val_loss: 0.2997\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2676 - val_loss: 0.2965\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2681 - val_loss: 0.2979\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2679 - val_loss: 0.2979\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2675 - val_loss: 0.3017\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2669 - val_loss: 0.3108\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2677 - val_loss: 0.3028\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2650 - val_loss: 0.3077\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2656 - val_loss: 0.2984\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2657 - val_loss: 0.2974\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2620 - val_loss: 0.3031\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2637 - val_loss: 0.3056\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.7818\n",
      "[CV]  learning_rate=0.007385522464208557, n_hidden=3, n_neurons=45, total=  37.8s\n",
      "[CV] learning_rate=0.007385522464208557, n_hidden=3, n_neurons=45 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.4826 - val_loss: 0.6055\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6808 - val_loss: 0.5350\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.1208 - val_loss: 0.5134\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7257 - val_loss: 0.4178\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3756 - val_loss: 0.3871\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3581 - val_loss: 0.3788\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3494 - val_loss: 0.3733\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3429 - val_loss: 0.3731\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3365 - val_loss: 0.3693\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3329 - val_loss: 0.3667\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3299 - val_loss: 0.3559\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3263 - val_loss: 0.3567\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3228 - val_loss: 0.3566\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3198 - val_loss: 0.3535\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3153 - val_loss: 0.3571\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3135 - val_loss: 0.3476\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3104 - val_loss: 0.3625\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3098 - val_loss: 0.3477\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3053 - val_loss: 0.3450\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3056 - val_loss: 0.3473\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3030 - val_loss: 0.3383\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3019 - val_loss: 0.3632\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.2978 - val_loss: 0.3404\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.2964 - val_loss: 0.3524\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.2948 - val_loss: 0.3481\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.2935 - val_loss: 0.3327\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2906 - val_loss: 0.3292\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2911 - val_loss: 0.3219\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2889 - val_loss: 0.3280\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2873 - val_loss: 0.3249\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2850 - val_loss: 0.3235\n",
      "Epoch 32/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2828 - val_loss: 0.3238\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2827 - val_loss: 0.3226\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2815 - val_loss: 0.3172\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2800 - val_loss: 0.3290\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2794 - val_loss: 0.3204\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2776 - val_loss: 0.3242\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2772 - val_loss: 0.3172\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2749 - val_loss: 0.3110\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2731 - val_loss: 0.3298\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2739 - val_loss: 0.3093\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2722 - val_loss: 0.3153\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2721 - val_loss: 0.3078\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2716 - val_loss: 0.3083\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.2680 - val_loss: 0.3167\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2690 - val_loss: 0.3074\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2665 - val_loss: 0.3190\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2671 - val_loss: 0.3122\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2639 - val_loss: 0.3060\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2656 - val_loss: 0.3093\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2642 - val_loss: 0.3035\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2641 - val_loss: 0.3177\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2628 - val_loss: 0.3025\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2626 - val_loss: 0.3037\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2608 - val_loss: 0.3071\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2607 - val_loss: 0.3069\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2589 - val_loss: 0.3060\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2591 - val_loss: 0.3147\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2594 - val_loss: 0.3023\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2584 - val_loss: 0.3007\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2573 - val_loss: 0.3033\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2564 - val_loss: 0.3035\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2564 - val_loss: 0.3006\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2570 - val_loss: 0.2990\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2542 - val_loss: 0.2968\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2553 - val_loss: 0.3117\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2540 - val_loss: 0.2984\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2530 - val_loss: 0.2964\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2525 - val_loss: 0.3078\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2521 - val_loss: 0.2999\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2535 - val_loss: 0.2980\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2515 - val_loss: 0.3193\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2511 - val_loss: 0.2939\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2504 - val_loss: 0.2988\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2504 - val_loss: 0.3008\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2514 - val_loss: 0.2971\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.2491 - val_loss: 0.2970\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2485 - val_loss: 0.2997\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2485 - val_loss: 0.2926\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2473 - val_loss: 0.3156\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.2467 - val_loss: 0.3033\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.2492 - val_loss: 0.3007\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.2460 - val_loss: 0.2923\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2450 - val_loss: 0.3057\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2451 - val_loss: 0.3081\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2450 - val_loss: 0.2932\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2455 - val_loss: 0.2960\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2436 - val_loss: 0.3081\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2439 - val_loss: 0.3010\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2440 - val_loss: 0.2998\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2444 - val_loss: 0.3060\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2423 - val_loss: 0.3003\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2438 - val_loss: 0.2957\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3055\n",
      "[CV]  learning_rate=0.007385522464208557, n_hidden=3, n_neurons=45, total=  39.9s\n",
      "[CV] learning_rate=0.008883054605909529, n_hidden=1, n_neurons=47 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.0835 - val_loss: 0.6111\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8419 - val_loss: 0.6967\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 3.4984 - val_loss: 0.5626\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7085 - val_loss: 0.4820\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4614 - val_loss: 0.4483\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4521 - val_loss: 0.4359\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4269 - val_loss: 0.4255\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4202 - val_loss: 0.4185\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4089 - val_loss: 0.4344\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4039 - val_loss: 0.4020\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3970 - val_loss: 0.3973\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6258 - val_loss: 0.4564\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5260 - val_loss: 0.5975\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5655 - val_loss: 0.4403\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4547 - val_loss: 0.4245\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4165 - val_loss: 0.4062\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4170 - val_loss: 0.4043\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4005 - val_loss: 0.3969\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3891 - val_loss: 0.3844\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3848 - val_loss: 0.3847\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3792 - val_loss: 0.3833\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3768 - val_loss: 0.3803\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3860 - val_loss: 0.3785\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3700 - val_loss: 0.3759\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3698 - val_loss: 0.3716\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3659 - val_loss: 0.3715\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3632 - val_loss: 0.3702\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3714 - val_loss: 0.3658\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3602 - val_loss: 0.3706\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3579 - val_loss: 0.3615\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3550 - val_loss: 0.3663\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3565 - val_loss: 0.3604\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3522 - val_loss: 0.3539\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3507 - val_loss: 0.3525\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3608 - val_loss: 0.3625\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3500 - val_loss: 0.3581\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3527 - val_loss: 0.3632\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3464 - val_loss: 0.3536\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3871 - val_loss: 0.3512\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3511 - val_loss: 0.3535\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3464 - val_loss: 0.3491\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3522 - val_loss: 0.3515\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3462 - val_loss: 0.3496\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3415 - val_loss: 0.3451\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3390 - val_loss: 0.3468\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3381 - val_loss: 0.3465\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3368 - val_loss: 0.3492\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3386 - val_loss: 0.3438\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3346 - val_loss: 0.3401\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3351 - val_loss: 0.3405\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3333 - val_loss: 0.3399\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3317 - val_loss: 0.3448\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3317 - val_loss: 0.3454\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3313 - val_loss: 0.3420\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3381 - val_loss: 0.3373\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3284 - val_loss: 0.3425\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3274 - val_loss: 0.3388\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3284 - val_loss: 0.3449\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3320 - val_loss: 0.3391\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3282 - val_loss: 0.3532\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3280 - val_loss: 0.3348\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3246 - val_loss: 0.3332\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3235 - val_loss: 0.3322\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3233 - val_loss: 0.3374\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3261 - val_loss: 0.3533\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3257 - val_loss: 0.3410\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3279 - val_loss: 0.3361\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3212 - val_loss: 0.3390\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3191 - val_loss: 0.3375\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3201 - val_loss: 0.3356\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3201 - val_loss: 0.3334\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3198 - val_loss: 0.3344\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3238 - val_loss: 0.3380\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3168\n",
      "[CV]  learning_rate=0.008883054605909529, n_hidden=1, n_neurons=47, total=  26.1s\n",
      "[CV] learning_rate=0.008883054605909529, n_hidden=1, n_neurons=47 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.9405 - val_loss: 0.6605\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6212 - val_loss: 0.5476\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5275 - val_loss: 0.5010\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4870 - val_loss: 0.4763\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5338 - val_loss: 0.4638\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4536 - val_loss: 0.4596\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4423 - val_loss: 0.4473\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4375 - val_loss: 0.4373\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4321 - val_loss: 0.4372\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4375 - val_loss: 0.4282\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4318 - val_loss: 0.4299\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4214 - val_loss: 0.4245\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4171 - val_loss: 0.4454\n",
      "Epoch 14/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4345 - val_loss: 0.4176\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4082 - val_loss: 0.4188\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4048 - val_loss: 0.4093\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4137 - val_loss: 0.4119\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4106 - val_loss: 0.4071\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3984 - val_loss: 0.4052\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3968 - val_loss: 0.4008\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4027 - val_loss: 0.4002\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3910 - val_loss: 0.4146\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3938 - val_loss: 0.3961\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3851 - val_loss: 0.3952\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3943 - val_loss: 0.4050\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3831 - val_loss: 0.3912\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3798 - val_loss: 0.3875\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3821 - val_loss: 0.3864\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3782 - val_loss: 0.3931\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3847 - val_loss: 0.3900\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3747 - val_loss: 0.3837\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3754 - val_loss: 0.4271\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3955 - val_loss: 0.3907\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3902 - val_loss: 0.4123\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4064 - val_loss: 0.9447\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4849 - val_loss: 0.3881\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3818 - val_loss: 0.4263\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3852 - val_loss: 0.3789\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3714 - val_loss: 0.3804\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3662 - val_loss: 0.3775\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3800 - val_loss: 0.3801\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3671 - val_loss: 0.3797\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3654 - val_loss: 0.3762\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3664 - val_loss: 0.4059\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4278 - val_loss: 0.3723\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3772 - val_loss: 0.5292\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4140 - val_loss: 0.3788\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3653 - val_loss: 0.3765\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3609 - val_loss: 0.3850\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3619 - val_loss: 0.3736\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3590 - val_loss: 0.3812\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3586 - val_loss: 0.3724\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3554 - val_loss: 0.3696\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3527 - val_loss: 0.3678\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3514 - val_loss: 0.3664\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3512 - val_loss: 0.3664\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3511 - val_loss: 0.3637\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3497 - val_loss: 0.3631\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3487 - val_loss: 0.3638\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3513 - val_loss: 0.3654\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3443 - val_loss: 0.3693\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3460 - val_loss: 0.3666\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3455 - val_loss: 0.3560\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3451 - val_loss: 0.3604\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3427 - val_loss: 0.3628\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3405 - val_loss: 0.3596\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3404 - val_loss: 0.3578\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3384 - val_loss: 0.3561\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3375 - val_loss: 0.3802\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3411 - val_loss: 0.3557\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3388 - val_loss: 0.3645\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3373 - val_loss: 0.3597\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3410 - val_loss: 0.3554\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3353 - val_loss: 0.3545\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3589 - val_loss: 0.3687\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3437 - val_loss: 0.3606\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3452 - val_loss: 0.3614\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3381 - val_loss: 0.3599\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3408 - val_loss: 0.3597\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3352 - val_loss: 0.3522\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3345 - val_loss: 0.3531\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3326 - val_loss: 0.3550\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3329 - val_loss: 0.3543\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3307 - val_loss: 0.3554\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3301 - val_loss: 0.3490\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3278 - val_loss: 0.3447\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3278 - val_loss: 0.3439\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3267 - val_loss: 0.3534\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3260 - val_loss: 0.3467\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3267 - val_loss: 0.3444\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3258 - val_loss: 0.3462\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3259 - val_loss: 0.3515\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3274 - val_loss: 0.3442\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3278 - val_loss: 0.3410\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3265 - val_loss: 0.3466\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3250 - val_loss: 0.3417\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3230 - val_loss: 0.3419\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3214 - val_loss: 0.3552\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3204 - val_loss: 0.3415\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3204 - val_loss: 0.3397\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3424 - val_loss: 0.3426\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3476 - val_loss: 0.3501\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3224 - val_loss: 0.3382\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3205 - val_loss: 0.3393\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3192 - val_loss: 0.3395\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3208 - val_loss: 0.3439\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3174 - val_loss: 0.3352\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3166 - val_loss: 0.3351\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3164 - val_loss: 0.3389\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3421 - val_loss: 0.3426\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3225 - val_loss: 0.3455\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3168 - val_loss: 0.3354\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3152 - val_loss: 0.3396\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3298 - val_loss: 0.3432\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3197 - val_loss: 0.3419\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3203 - val_loss: 0.3370\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3153 - val_loss: 0.3383\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3147 - val_loss: 0.3360\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.5653\n",
      "[CV]  learning_rate=0.008883054605909529, n_hidden=1, n_neurons=47, total=  40.8s\n",
      "[CV] learning_rate=0.008883054605909529, n_hidden=1, n_neurons=47 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8747 - val_loss: 0.9732\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 5.5033 - val_loss: 0.5428\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4859 - val_loss: 0.4565\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4216 - val_loss: 0.4191\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3987 - val_loss: 0.4052\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3908 - val_loss: 0.4031\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3757 - val_loss: 0.3987\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3700 - val_loss: 0.4041\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3672 - val_loss: 0.4019\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3613 - val_loss: 0.3828\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3609 - val_loss: 0.3905\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3584 - val_loss: 0.3815\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3552 - val_loss: 0.3885\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3551 - val_loss: 0.3755\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3543 - val_loss: 0.3730\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3489 - val_loss: 0.3726\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3479 - val_loss: 0.3806\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3486 - val_loss: 0.3757\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3502 - val_loss: 0.3788\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3461 - val_loss: 0.3754\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3430 - val_loss: 0.3796\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3423 - val_loss: 0.3754\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3424 - val_loss: 0.3696\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3395 - val_loss: 0.3692\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3402 - val_loss: 0.3819\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3368 - val_loss: 0.3897\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3368 - val_loss: 0.3700\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3351 - val_loss: 0.3829\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3349 - val_loss: 0.3657\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3348 - val_loss: 0.3701\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3332 - val_loss: 0.3798\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3332 - val_loss: 0.3730\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3327 - val_loss: 0.3683\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3316 - val_loss: 0.3673\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3300 - val_loss: 0.3696\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3312 - val_loss: 0.3665\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3284 - val_loss: 0.3653\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3281 - val_loss: 0.4096\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3291 - val_loss: 0.3783\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3289 - val_loss: 0.3646\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3272 - val_loss: 0.3747\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3264 - val_loss: 0.3659\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3251 - val_loss: 0.3635\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3262 - val_loss: 0.3671\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3246 - val_loss: 0.3631\n",
      "Epoch 46/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3234 - val_loss: 0.3649\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3240 - val_loss: 0.3640\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3239 - val_loss: 0.3659\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3231 - val_loss: 0.3590\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3220 - val_loss: 0.3622\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3197 - val_loss: 0.3732\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3197 - val_loss: 0.3674\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3201 - val_loss: 0.3640\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3231 - val_loss: 0.3723\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3201 - val_loss: 0.3632\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3203 - val_loss: 0.3726\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3208 - val_loss: 0.3655\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3198 - val_loss: 0.3593\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3190 - val_loss: 0.3581\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3188 - val_loss: 0.3571\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3165 - val_loss: 0.3563\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3177 - val_loss: 0.3560\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3150 - val_loss: 0.3573\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3165 - val_loss: 0.3613\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3154 - val_loss: 0.3606\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3152 - val_loss: 0.3676\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3153 - val_loss: 0.3546\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3181 - val_loss: 0.3632\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3174 - val_loss: 0.3659\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3169 - val_loss: 0.3694\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3117 - val_loss: 0.3632\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3132 - val_loss: 0.3636\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3159 - val_loss: 0.3606\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3143 - val_loss: 0.3680\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3124 - val_loss: 0.3529\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3131 - val_loss: 0.3584\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3124 - val_loss: 0.3566\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3117 - val_loss: 0.3527\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3115 - val_loss: 0.3635\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3104 - val_loss: 0.3569\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3112 - val_loss: 0.3502\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3124 - val_loss: 0.3573\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3128 - val_loss: 0.3528\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3091 - val_loss: 0.3529\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3103 - val_loss: 0.3601\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3085 - val_loss: 0.3522\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3097 - val_loss: 0.3511\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3105 - val_loss: 0.3486\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3079 - val_loss: 0.3656\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3072 - val_loss: 0.3562\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3076 - val_loss: 0.3550\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3132 - val_loss: 0.3548\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3091 - val_loss: 0.3484\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3069 - val_loss: 0.3596\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3083 - val_loss: 0.3497\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3064 - val_loss: 0.3543\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3068 - val_loss: 0.3616\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3062 - val_loss: 0.3495\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3080 - val_loss: 0.3575\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3055 - val_loss: 0.3560\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3072 - val_loss: 0.3515\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3055 - val_loss: 0.3542\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3060 - val_loss: 0.3483\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3048 - val_loss: 0.3507\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3071 - val_loss: 0.3530\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3048 - val_loss: 0.3478\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3033 - val_loss: 0.3536\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3055 - val_loss: 0.3482\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3060 - val_loss: 0.3472\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3027 - val_loss: 0.3476\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3038 - val_loss: 0.3542\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3030 - val_loss: 0.3482\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3017 - val_loss: 0.3593\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3030 - val_loss: 0.3502\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3015 - val_loss: 0.3542\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3004 - val_loss: 0.3620\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3006 - val_loss: 0.3496\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3010 - val_loss: 0.3467\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3002 - val_loss: 0.3508\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3057 - val_loss: 0.3447\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2999 - val_loss: 0.3498\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3005 - val_loss: 0.3410\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3008 - val_loss: 0.3471\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2984 - val_loss: 0.3773\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3002 - val_loss: 0.3481\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2982 - val_loss: 0.3411\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2980 - val_loss: 0.3421\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2978 - val_loss: 0.3417\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2967 - val_loss: 0.3423\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2980 - val_loss: 0.3445\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2971 - val_loss: 0.3418\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2964 - val_loss: 0.3398\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2964 - val_loss: 0.3466\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2968 - val_loss: 0.3481\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2968 - val_loss: 0.3382\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2939 - val_loss: 0.3442\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2979 - val_loss: 0.3468\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2947 - val_loss: 0.3395\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3109 - val_loss: 0.3507\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3475 - val_loss: 0.3369\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2974 - val_loss: 0.3396\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2940 - val_loss: 0.3416\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2953 - val_loss: 0.3494\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2942 - val_loss: 0.3387\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2938 - val_loss: 0.3357\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2917 - val_loss: 0.3422\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2936 - val_loss: 0.3424\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2933 - val_loss: 0.3358\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2925 - val_loss: 0.3407\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2908 - val_loss: 0.3374\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2924 - val_loss: 0.3382\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2909 - val_loss: 0.3434\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2919 - val_loss: 0.3417\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2903 - val_loss: 0.3378\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2905 - val_loss: 0.3392\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3727\n",
      "[CV]  learning_rate=0.008883054605909529, n_hidden=1, n_neurons=47, total=  54.2s\n",
      "[CV] learning_rate=0.004799165091003534, n_hidden=1, n_neurons=31 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.4307 - val_loss: 0.8842\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.9115 - val_loss: 0.5458\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5422 - val_loss: 0.5006\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4941 - val_loss: 0.4840\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4702 - val_loss: 0.4516\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4583 - val_loss: 0.4426\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4474 - val_loss: 0.4355\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4414 - val_loss: 0.4304\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4318 - val_loss: 0.4370\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4288 - val_loss: 0.4216\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4247 - val_loss: 0.4256\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4183 - val_loss: 0.4096\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4139 - val_loss: 0.4058\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4109 - val_loss: 0.4061\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4084 - val_loss: 0.4219\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4061 - val_loss: 0.4037\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4044 - val_loss: 0.3988\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4030 - val_loss: 0.3986\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4003 - val_loss: 0.3982\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3990 - val_loss: 0.3947\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3983 - val_loss: 0.3934\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3947 - val_loss: 0.3933\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3940 - val_loss: 0.3915\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3922 - val_loss: 0.3907\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3977 - val_loss: 0.3905\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3894 - val_loss: 0.3900\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3887 - val_loss: 0.3900\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3885 - val_loss: 0.3872\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3868 - val_loss: 0.3861\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3857 - val_loss: 0.3838\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3851 - val_loss: 0.3855\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3852 - val_loss: 0.3838\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3836 - val_loss: 0.3829\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3818 - val_loss: 0.3808\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3827 - val_loss: 0.3828\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3814 - val_loss: 0.3807\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3844 - val_loss: 0.3808\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3829 - val_loss: 0.3810\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3795 - val_loss: 0.3782\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3787 - val_loss: 0.3785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3779 - val_loss: 0.3768\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3771 - val_loss: 0.3772\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3753 - val_loss: 0.3756\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3748 - val_loss: 0.3762\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3765 - val_loss: 0.3776\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3744 - val_loss: 0.3756\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3738 - val_loss: 0.3764\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3716 - val_loss: 0.3739\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3722 - val_loss: 0.3742\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3728 - val_loss: 0.3789\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3890 - val_loss: 0.3732\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3745 - val_loss: 0.3720\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3705 - val_loss: 0.3707\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3718 - val_loss: 0.3753\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3685 - val_loss: 0.3721\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3696 - val_loss: 0.3699\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3669 - val_loss: 0.3691\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3670 - val_loss: 0.3688\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3664 - val_loss: 0.3712\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3672 - val_loss: 0.3699\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3653 - val_loss: 0.3676\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3647 - val_loss: 0.3672\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3651 - val_loss: 0.3699\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3636 - val_loss: 0.3663\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3659 - val_loss: 0.3758\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3642 - val_loss: 0.3649\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3638 - val_loss: 0.3682\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3641 - val_loss: 0.3672\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3627 - val_loss: 0.3684\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3607 - val_loss: 0.3667\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3647 - val_loss: 0.3681\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3600 - val_loss: 0.3690\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3589 - val_loss: 0.3632\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3587 - val_loss: 0.3642\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3584 - val_loss: 0.3644\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3596 - val_loss: 0.3809\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3628 - val_loss: 0.3649\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3637 - val_loss: 0.3626\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3661 - val_loss: 0.3845\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3603 - val_loss: 0.3632\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3611 - val_loss: 0.3630\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3603 - val_loss: 0.3602\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3565 - val_loss: 0.3613\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3542 - val_loss: 0.3602\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3540 - val_loss: 0.3874\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3589 - val_loss: 0.3593\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3533 - val_loss: 0.3591\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3521 - val_loss: 0.3600\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3540 - val_loss: 0.3639\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3532 - val_loss: 0.3649\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3583 - val_loss: 0.3589\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3500 - val_loss: 0.3584\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3507 - val_loss: 0.3595\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3582 - val_loss: 0.3591\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3524 - val_loss: 0.3580\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3493 - val_loss: 0.3623\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3489 - val_loss: 0.3572\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3502 - val_loss: 0.3588\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3477 - val_loss: 0.3619\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3484 - val_loss: 0.3570\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3485 - val_loss: 0.3543\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3474 - val_loss: 0.3574\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3456 - val_loss: 0.3573\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3452 - val_loss: 0.3596\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3458 - val_loss: 0.3539\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3446 - val_loss: 0.3537\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3445 - val_loss: 0.3536\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3441 - val_loss: 0.3551\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3445 - val_loss: 0.3529\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3642 - val_loss: 0.3561\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3529 - val_loss: 0.3516\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3448 - val_loss: 0.3545\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3540 - val_loss: 0.3539\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3437 - val_loss: 0.3507\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3427 - val_loss: 0.3547\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3431 - val_loss: 0.3524\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3431 - val_loss: 0.3510\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3420 - val_loss: 0.3518\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3421 - val_loss: 0.3504\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3484 - val_loss: 0.3518\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3428 - val_loss: 0.3506\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3413 - val_loss: 0.3552\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3396 - val_loss: 0.3493\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3390 - val_loss: 0.3501\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3412 - val_loss: 0.3494\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3387 - val_loss: 0.3502\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3389 - val_loss: 0.3511\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3430 - val_loss: 0.3484\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3380 - val_loss: 0.3514\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3471 - val_loss: 0.3504\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3360 - val_loss: 0.3486\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3420 - val_loss: 0.3486\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3373 - val_loss: 0.3491\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3366 - val_loss: 0.3478\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3352 - val_loss: 0.3525\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3356 - val_loss: 0.3488\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3372 - val_loss: 0.3456\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3344 - val_loss: 0.3478\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3424 - val_loss: 0.3466\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3406 - val_loss: 0.3457\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3345 - val_loss: 0.3461\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3353 - val_loss: 0.3513\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3336 - val_loss: 0.3443\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3322 - val_loss: 0.3442\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3351 - val_loss: 0.3440\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3324 - val_loss: 0.3449\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3336 - val_loss: 0.3455\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3316 - val_loss: 0.3449\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3352 - val_loss: 0.3485\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3298 - val_loss: 0.3439\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3342 - val_loss: 0.3476\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3309 - val_loss: 0.3424\n",
      "Epoch 153/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3288 - val_loss: 0.3440\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3316 - val_loss: 0.3445\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3459 - val_loss: 0.3644\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3284 - val_loss: 0.3398\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3354 - val_loss: 0.3401\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3348 - val_loss: 0.3408\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3320 - val_loss: 0.3461\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3258 - val_loss: 0.3426\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3266 - val_loss: 0.3417\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3270 - val_loss: 0.3434\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3380 - val_loss: 0.3798\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3273 - val_loss: 0.3396\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3263 - val_loss: 0.3429\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3240 - val_loss: 0.3394\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3232 - val_loss: 0.3437\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3303 - val_loss: 0.3402\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3255 - val_loss: 0.3443\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3277 - val_loss: 0.3375\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3244 - val_loss: 0.3393\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3242 - val_loss: 0.3446\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3269 - val_loss: 0.3372\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3253 - val_loss: 0.3393\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3233 - val_loss: 0.3378\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3226 - val_loss: 0.3399\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3234 - val_loss: 0.3360\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3211 - val_loss: 0.3384\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3210 - val_loss: 0.3429\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3203 - val_loss: 0.3415\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3215 - val_loss: 0.3358\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3272 - val_loss: 0.3391\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3250 - val_loss: 0.3444\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3385 - val_loss: 0.3827\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4795 - val_loss: 0.3458\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3266 - val_loss: 0.3380\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4113 - val_loss: 0.3390\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3308 - val_loss: 0.3406\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3602 - val_loss: 0.3416\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3243 - val_loss: 0.3387\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3245 - val_loss: 0.3375\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3053\n",
      "[CV]  learning_rate=0.004799165091003534, n_hidden=1, n_neurons=31, total= 1.1min\n",
      "[CV] learning_rate=0.004799165091003534, n_hidden=1, n_neurons=31 ....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.2690 - val_loss: 0.6659\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6188 - val_loss: 0.5827\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5526 - val_loss: 0.5399\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5161 - val_loss: 0.5699\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4988 - val_loss: 0.4845\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4815 - val_loss: 0.4719\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4642 - val_loss: 0.4607\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4544 - val_loss: 0.4562\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4511 - val_loss: 0.4500\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4465 - val_loss: 0.4465\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4386 - val_loss: 0.4414\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4388 - val_loss: 0.4384\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4307 - val_loss: 0.4402\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4321 - val_loss: 0.4346\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4247 - val_loss: 0.4347\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4222 - val_loss: 0.4311\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4200 - val_loss: 0.4274\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4187 - val_loss: 0.4231\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4147 - val_loss: 0.4248\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4123 - val_loss: 0.4221\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4110 - val_loss: 0.4195\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4088 - val_loss: 0.4166\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4068 - val_loss: 0.4154\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4062 - val_loss: 0.4257\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4083 - val_loss: 0.4151\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4039 - val_loss: 0.4118\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4081 - val_loss: 0.4121\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3998 - val_loss: 0.4100\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4001 - val_loss: 0.4100\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3983 - val_loss: 0.4076\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3966 - val_loss: 0.4059\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3945 - val_loss: 0.4062\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3925 - val_loss: 0.4022\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3916 - val_loss: 0.4032\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3903 - val_loss: 0.4008\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3897 - val_loss: 0.4010\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3880 - val_loss: 0.3976\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3886 - val_loss: 0.3973\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3858 - val_loss: 0.3974\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3853 - val_loss: 0.3963\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3838 - val_loss: 0.3965\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3841 - val_loss: 0.3934\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3818 - val_loss: 0.3913\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3813 - val_loss: 0.3914\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3782 - val_loss: 0.3935\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3815 - val_loss: 0.3902\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3780 - val_loss: 0.3912\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3778 - val_loss: 0.3896\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3759 - val_loss: 0.3894\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3763 - val_loss: 0.4026\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3773 - val_loss: 0.3856\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3730 - val_loss: 0.4492\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3840 - val_loss: 0.3851\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3752 - val_loss: 0.3890\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3727 - val_loss: 0.3842\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3712 - val_loss: 0.3830\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3694 - val_loss: 0.3858\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3689 - val_loss: 0.3821\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3679 - val_loss: 0.3801\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3680 - val_loss: 0.3800\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3671 - val_loss: 0.3802\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3663 - val_loss: 0.3818\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3658 - val_loss: 0.3814\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3688 - val_loss: 0.3766\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3630 - val_loss: 0.3830\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3639 - val_loss: 0.3804\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3621 - val_loss: 0.3777\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3629 - val_loss: 0.4075\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3643 - val_loss: 0.3744\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3615 - val_loss: 0.3733\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3592 - val_loss: 0.3740\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3592 - val_loss: 0.3741\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3576 - val_loss: 0.3717\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3593 - val_loss: 0.3732\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3553 - val_loss: 0.3705\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3568 - val_loss: 0.3720\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3580 - val_loss: 0.3718\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3615 - val_loss: 0.3712\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3567 - val_loss: 0.4265\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3605 - val_loss: 0.3680\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3553 - val_loss: 0.3679\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3523 - val_loss: 0.3676\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3525 - val_loss: 0.3838\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3552 - val_loss: 0.3649\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3507 - val_loss: 0.3663\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3549 - val_loss: 0.3700\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3497 - val_loss: 0.3649\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3487 - val_loss: 0.3661\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3508 - val_loss: 0.3633\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3465 - val_loss: 0.3728\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3474 - val_loss: 0.3755\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3471 - val_loss: 0.3626\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3522 - val_loss: 0.3633\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3487 - val_loss: 0.3627\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3555 - val_loss: 0.3652\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3485 - val_loss: 0.3672\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3476 - val_loss: 0.3630\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3455 - val_loss: 0.3609\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3428 - val_loss: 0.3615\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3470 - val_loss: 0.3618\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3465 - val_loss: 0.3623\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3471 - val_loss: 0.3597\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3470 - val_loss: 0.3632\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3423 - val_loss: 0.3604\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3407 - val_loss: 0.3611\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3395 - val_loss: 0.3604\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3394 - val_loss: 0.3666\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3423 - val_loss: 0.3589\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3488 - val_loss: 0.3562\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3460 - val_loss: 0.3566\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3427 - val_loss: 0.3565\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3396 - val_loss: 0.3607\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3447 - val_loss: 0.3555\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3353 - val_loss: 0.3708\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3383 - val_loss: 0.3543\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3374 - val_loss: 0.3573\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3334 - val_loss: 0.3547\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3374 - val_loss: 0.3552\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3378 - val_loss: 0.3552\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3323 - val_loss: 0.3579\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3336 - val_loss: 0.3577\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3426 - val_loss: 0.3518\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3348 - val_loss: 0.3529\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3314 - val_loss: 0.3540\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3310 - val_loss: 0.3519\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3303 - val_loss: 0.3553\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3325 - val_loss: 0.3729\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3465 - val_loss: 0.3517\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3321 - val_loss: 0.3567\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3314 - val_loss: 0.3510\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3307 - val_loss: 0.3487\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3286 - val_loss: 0.3509\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3280 - val_loss: 0.3504\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3272 - val_loss: 0.3542\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3270 - val_loss: 0.3542\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3273 - val_loss: 0.3476\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3260 - val_loss: 0.3466\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3257 - val_loss: 0.3506\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3270 - val_loss: 0.3531\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3255 - val_loss: 0.3528\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3265 - val_loss: 0.3483\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3244 - val_loss: 0.3493\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3237 - val_loss: 0.3480\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3241 - val_loss: 0.3470\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3244 - val_loss: 0.3499\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3241 - val_loss: 0.3472\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3307 - val_loss: 0.3453\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3240 - val_loss: 0.3494\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3262 - val_loss: 0.3440\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3224 - val_loss: 0.3434\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3250 - val_loss: 0.3511\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3239 - val_loss: 0.3495\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3236 - val_loss: 0.3432\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3215 - val_loss: 0.3454\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3219 - val_loss: 0.3467\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3200 - val_loss: 0.3428\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3196 - val_loss: 0.3423\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3192 - val_loss: 0.3431\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3179 - val_loss: 0.3432\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3188 - val_loss: 0.3439\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3211 - val_loss: 0.3417\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3198 - val_loss: 0.3408\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3183 - val_loss: 0.3412\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3187 - val_loss: 0.3393\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3170 - val_loss: 0.3404\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3234 - val_loss: 0.3458\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3175 - val_loss: 0.3399\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3169 - val_loss: 0.3446\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3166 - val_loss: 0.3407\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3201 - val_loss: 0.3387\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3190 - val_loss: 0.3450\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3161 - val_loss: 0.3510\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3263 - val_loss: 0.3445\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3159 - val_loss: 0.3370\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3165 - val_loss: 0.3378\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3179 - val_loss: 0.3372\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3174 - val_loss: 0.3389\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3150 - val_loss: 0.3399\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3147 - val_loss: 0.3376\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3135 - val_loss: 0.3380\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3155 - val_loss: 0.3469\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3266 - val_loss: 0.3370\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3161 - val_loss: 0.3403\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3150 - val_loss: 0.3363\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3167 - val_loss: 0.3357\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3122 - val_loss: 0.3450\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3170 - val_loss: 0.3393\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3126 - val_loss: 0.3354\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3248 - val_loss: 0.3353\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3124 - val_loss: 0.3358\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3121 - val_loss: 0.3387\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3110 - val_loss: 0.3377\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3144 - val_loss: 0.3360\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3132 - val_loss: 0.3400\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3104 - val_loss: 0.3351\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3095 - val_loss: 0.3354\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3139 - val_loss: 0.3333\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3094 - val_loss: 0.3328\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3185 - val_loss: 0.3407\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3111 - val_loss: 0.3719\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3182 - val_loss: 0.3393\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3151 - val_loss: 0.3332\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3116 - val_loss: 0.3371\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3091 - val_loss: 0.3338\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3085 - val_loss: 0.3350\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3083 - val_loss: 0.3322\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3092 - val_loss: 0.3310\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3081 - val_loss: 0.3318\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3087 - val_loss: 0.3327\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3099 - val_loss: 0.3324\n",
      "Epoch 211/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3109 - val_loss: 0.3324\n",
      "Epoch 212/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3082 - val_loss: 0.3307\n",
      "Epoch 213/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3096 - val_loss: 0.3358\n",
      "Epoch 214/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3073 - val_loss: 0.3334\n",
      "Epoch 215/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3101 - val_loss: 0.3322\n",
      "Epoch 216/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3080 - val_loss: 0.3304\n",
      "Epoch 217/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3061 - val_loss: 0.3298\n",
      "Epoch 218/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3095 - val_loss: 0.3301\n",
      "Epoch 219/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3066 - val_loss: 0.3316\n",
      "Epoch 220/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3065 - val_loss: 0.3361\n",
      "Epoch 221/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3060 - val_loss: 0.3615\n",
      "Epoch 222/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4642 - val_loss: 0.3399\n",
      "Epoch 223/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3169 - val_loss: 0.3350\n",
      "Epoch 224/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3209 - val_loss: 0.3332\n",
      "Epoch 225/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3206 - val_loss: 0.3349\n",
      "Epoch 226/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3104 - val_loss: 0.3529\n",
      "Epoch 227/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3121 - val_loss: 0.3310\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5623\n",
      "[CV]  learning_rate=0.004799165091003534, n_hidden=1, n_neurons=31, total= 1.3min\n",
      "[CV] learning_rate=0.004799165091003534, n_hidden=1, n_neurons=31 ....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.2573 - val_loss: 0.6453\n",
      "Epoch 2/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.2396 - val_loss: 0.7164\n",
      "Epoch 3/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.7176 - val_loss: 0.6073\n",
      "Epoch 4/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5541 - val_loss: 0.5387\n",
      "Epoch 5/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5072 - val_loss: 0.5086\n",
      "Epoch 6/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4841 - val_loss: 0.4903\n",
      "Epoch 7/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4682 - val_loss: 0.4793\n",
      "Epoch 8/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4580 - val_loss: 0.4692\n",
      "Epoch 9/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4489 - val_loss: 0.4619\n",
      "Epoch 10/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4410 - val_loss: 0.4564\n",
      "Epoch 11/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4350 - val_loss: 0.4489\n",
      "Epoch 12/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4293 - val_loss: 0.4439\n",
      "Epoch 13/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4243 - val_loss: 0.4418\n",
      "Epoch 14/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4203 - val_loss: 0.4370\n",
      "Epoch 15/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4158 - val_loss: 0.4316\n",
      "Epoch 16/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4116 - val_loss: 0.4299\n",
      "Epoch 17/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4079 - val_loss: 0.4264\n",
      "Epoch 18/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4048 - val_loss: 0.4237\n",
      "Epoch 19/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4017 - val_loss: 0.4223\n",
      "Epoch 20/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3987 - val_loss: 0.4185\n",
      "Epoch 21/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3961 - val_loss: 0.4172\n",
      "Epoch 22/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3936 - val_loss: 0.4164\n",
      "Epoch 23/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3904 - val_loss: 0.4105\n",
      "Epoch 24/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3889 - val_loss: 0.4089\n",
      "Epoch 25/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3865 - val_loss: 0.4062\n",
      "Epoch 26/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3840 - val_loss: 0.4046\n",
      "Epoch 27/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3815 - val_loss: 0.4028\n",
      "Epoch 28/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3801 - val_loss: 0.4022\n",
      "Epoch 29/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3782 - val_loss: 0.4001\n",
      "Epoch 30/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3765 - val_loss: 0.3990\n",
      "Epoch 31/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3747 - val_loss: 0.3967\n",
      "Epoch 32/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3723 - val_loss: 0.3965\n",
      "Epoch 33/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3710 - val_loss: 0.3930\n",
      "Epoch 34/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3695 - val_loss: 0.3925\n",
      "Epoch 35/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3671 - val_loss: 0.3910\n",
      "Epoch 36/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3664 - val_loss: 0.3895\n",
      "Epoch 37/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3640 - val_loss: 0.3882\n",
      "Epoch 38/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3632 - val_loss: 0.3870\n",
      "Epoch 39/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3616 - val_loss: 0.3856\n",
      "Epoch 40/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3596 - val_loss: 0.3849\n",
      "Epoch 41/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3588 - val_loss: 0.3834\n",
      "Epoch 42/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3576 - val_loss: 0.3821\n",
      "Epoch 43/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3563 - val_loss: 0.3804\n",
      "Epoch 44/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3544 - val_loss: 0.3800\n",
      "Epoch 45/500\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3531 - val_loss: 0.3814\n",
      "Epoch 46/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3520 - val_loss: 0.3790\n",
      "Epoch 47/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3507 - val_loss: 0.3779\n",
      "Epoch 48/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3500 - val_loss: 0.3755\n",
      "Epoch 49/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3487 - val_loss: 0.3759\n",
      "Epoch 50/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3475 - val_loss: 0.3736\n",
      "Epoch 51/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3477 - val_loss: 0.3725\n",
      "Epoch 52/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3453 - val_loss: 0.3773\n",
      "Epoch 53/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3454 - val_loss: 0.3719\n",
      "Epoch 54/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3439 - val_loss: 0.3707\n",
      "Epoch 55/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3427 - val_loss: 0.3690\n",
      "Epoch 56/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3422 - val_loss: 0.3712\n",
      "Epoch 57/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3415 - val_loss: 0.3685\n",
      "Epoch 58/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3405 - val_loss: 0.3676\n",
      "Epoch 59/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3395 - val_loss: 0.3670\n",
      "Epoch 60/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3383 - val_loss: 0.3670\n",
      "Epoch 61/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3379 - val_loss: 0.3653\n",
      "Epoch 62/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3368 - val_loss: 0.3724\n",
      "Epoch 63/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3356 - val_loss: 0.3652\n",
      "Epoch 64/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3356 - val_loss: 0.3630\n",
      "Epoch 65/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3349 - val_loss: 0.3625\n",
      "Epoch 66/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3339 - val_loss: 0.3616\n",
      "Epoch 67/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3331 - val_loss: 0.3620\n",
      "Epoch 68/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3327 - val_loss: 0.3610\n",
      "Epoch 69/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3321 - val_loss: 0.3613\n",
      "Epoch 70/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3310 - val_loss: 0.3592\n",
      "Epoch 71/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3311 - val_loss: 0.3596\n",
      "Epoch 72/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3299 - val_loss: 0.3598\n",
      "Epoch 73/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3300 - val_loss: 0.3566\n",
      "Epoch 74/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3290 - val_loss: 0.3598\n",
      "Epoch 75/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3282 - val_loss: 0.3556\n",
      "Epoch 76/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3276 - val_loss: 0.3580\n",
      "Epoch 77/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3272 - val_loss: 0.3566\n",
      "Epoch 78/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3272 - val_loss: 0.3547\n",
      "Epoch 79/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3251 - val_loss: 0.3572\n",
      "Epoch 80/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3251 - val_loss: 0.3564\n",
      "Epoch 81/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3241 - val_loss: 0.3557\n",
      "Epoch 82/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3234 - val_loss: 0.3528\n",
      "Epoch 83/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3229 - val_loss: 0.3531\n",
      "Epoch 84/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3224 - val_loss: 0.3536\n",
      "Epoch 85/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3219 - val_loss: 0.3544\n",
      "Epoch 86/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3214 - val_loss: 0.3513\n",
      "Epoch 87/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3206 - val_loss: 0.3495\n",
      "Epoch 88/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3196 - val_loss: 0.3539\n",
      "Epoch 89/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3204 - val_loss: 0.3479\n",
      "Epoch 90/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3202 - val_loss: 0.3490\n",
      "Epoch 91/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3187 - val_loss: 0.3539\n",
      "Epoch 92/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3182 - val_loss: 0.3518\n",
      "Epoch 93/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3182 - val_loss: 0.3472\n",
      "Epoch 94/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3167 - val_loss: 0.3484\n",
      "Epoch 95/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3174 - val_loss: 0.3466\n",
      "Epoch 96/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3167 - val_loss: 0.3514\n",
      "Epoch 97/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3170 - val_loss: 0.3482\n",
      "Epoch 98/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3151 - val_loss: 0.3561\n",
      "Epoch 99/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3160 - val_loss: 0.3463\n",
      "Epoch 100/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3146 - val_loss: 0.3446\n",
      "Epoch 101/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3147 - val_loss: 0.3469\n",
      "Epoch 102/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3141 - val_loss: 0.3465\n",
      "Epoch 103/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3135 - val_loss: 0.3463\n",
      "Epoch 104/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3139 - val_loss: 0.3488\n",
      "Epoch 105/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3134 - val_loss: 0.3433\n",
      "Epoch 106/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3130 - val_loss: 0.3438\n",
      "Epoch 107/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3117 - val_loss: 0.3513\n",
      "Epoch 108/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3124 - val_loss: 0.3443\n",
      "Epoch 109/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3115 - val_loss: 0.3482\n",
      "Epoch 110/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3109 - val_loss: 0.3435\n",
      "Epoch 111/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3110 - val_loss: 0.3468\n",
      "Epoch 112/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3107 - val_loss: 0.3428\n",
      "Epoch 113/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3102 - val_loss: 0.3434\n",
      "Epoch 114/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3108 - val_loss: 0.3411\n",
      "Epoch 115/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3088 - val_loss: 0.3492\n",
      "Epoch 116/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3090 - val_loss: 0.3456\n",
      "Epoch 117/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3093 - val_loss: 0.3447\n",
      "Epoch 118/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3088 - val_loss: 0.3423\n",
      "Epoch 119/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3081 - val_loss: 0.3482\n",
      "Epoch 120/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3085 - val_loss: 0.3400\n",
      "Epoch 121/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3073 - val_loss: 0.3392\n",
      "Epoch 122/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3082 - val_loss: 0.3382\n",
      "Epoch 123/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3078 - val_loss: 0.3374\n",
      "Epoch 124/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3071 - val_loss: 0.3390\n",
      "Epoch 125/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3069 - val_loss: 0.3377\n",
      "Epoch 126/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3060 - val_loss: 0.3365\n",
      "Epoch 127/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3066 - val_loss: 0.3380\n",
      "Epoch 128/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3053 - val_loss: 0.3397\n",
      "Epoch 129/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3053 - val_loss: 0.3363\n",
      "Epoch 130/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3054 - val_loss: 0.3407\n",
      "Epoch 131/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3045 - val_loss: 0.3370\n",
      "Epoch 132/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3044 - val_loss: 0.3386\n",
      "Epoch 133/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3038 - val_loss: 0.3381\n",
      "Epoch 134/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3046 - val_loss: 0.3354\n",
      "Epoch 135/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3033 - val_loss: 0.3369\n",
      "Epoch 136/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3033 - val_loss: 0.3355\n",
      "Epoch 137/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3035 - val_loss: 0.3357\n",
      "Epoch 138/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3034 - val_loss: 0.3407\n",
      "Epoch 139/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3030 - val_loss: 0.3397\n",
      "Epoch 140/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3030 - val_loss: 0.3362\n",
      "Epoch 141/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3016 - val_loss: 0.3363\n",
      "Epoch 142/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3016 - val_loss: 0.3411\n",
      "Epoch 143/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3028 - val_loss: 0.3348\n",
      "Epoch 144/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3023 - val_loss: 0.3380\n",
      "Epoch 145/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3014 - val_loss: 0.3396\n",
      "Epoch 146/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3014 - val_loss: 0.3342\n",
      "Epoch 147/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3010 - val_loss: 0.3358\n",
      "Epoch 148/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3008 - val_loss: 0.3388\n",
      "Epoch 149/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3016 - val_loss: 0.3337\n",
      "Epoch 150/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3010 - val_loss: 0.3345\n",
      "Epoch 151/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3008 - val_loss: 0.3345\n",
      "Epoch 152/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3006 - val_loss: 0.3337\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3007 - val_loss: 0.3330\n",
      "Epoch 154/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2991 - val_loss: 0.3389\n",
      "Epoch 155/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2998 - val_loss: 0.3336\n",
      "Epoch 156/500\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.2994 - val_loss: 0.3396\n",
      "Epoch 157/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2993 - val_loss: 0.3341\n",
      "Epoch 158/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2994 - val_loss: 0.3316\n",
      "Epoch 159/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2991 - val_loss: 0.3330\n",
      "Epoch 160/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2990 - val_loss: 0.3338\n",
      "Epoch 161/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2994 - val_loss: 0.3324\n",
      "Epoch 162/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2979 - val_loss: 0.3344\n",
      "Epoch 163/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2986 - val_loss: 0.3321\n",
      "Epoch 164/500\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2983 - val_loss: 0.3307\n",
      "Epoch 165/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2980 - val_loss: 0.3304\n",
      "Epoch 166/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2979 - val_loss: 0.3319\n",
      "Epoch 167/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2973 - val_loss: 0.3326\n",
      "Epoch 168/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2974 - val_loss: 0.3310\n",
      "Epoch 169/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2974 - val_loss: 0.3343\n",
      "Epoch 170/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2970 - val_loss: 0.3348\n",
      "Epoch 171/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2965 - val_loss: 0.3326\n",
      "Epoch 172/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2969 - val_loss: 0.3317\n",
      "Epoch 173/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2964 - val_loss: 0.3315\n",
      "Epoch 174/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2968 - val_loss: 0.3290\n",
      "Epoch 175/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2964 - val_loss: 0.3313\n",
      "Epoch 176/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2960 - val_loss: 0.3301\n",
      "Epoch 177/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2959 - val_loss: 0.3319\n",
      "Epoch 178/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2971 - val_loss: 0.3315\n",
      "Epoch 179/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2956 - val_loss: 0.3286\n",
      "Epoch 180/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2956 - val_loss: 0.3338\n",
      "Epoch 181/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2950 - val_loss: 0.3311\n",
      "Epoch 182/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2948 - val_loss: 0.3310\n",
      "Epoch 183/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2954 - val_loss: 0.3284\n",
      "Epoch 184/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2948 - val_loss: 0.3291\n",
      "Epoch 185/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2953 - val_loss: 0.3285\n",
      "Epoch 186/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2949 - val_loss: 0.3323\n",
      "Epoch 187/500\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.2947 - val_loss: 0.3296\n",
      "Epoch 188/500\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2949 - val_loss: 0.3320\n",
      "Epoch 189/500\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2941 - val_loss: 0.3289\n",
      "Epoch 190/500\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2937 - val_loss: 0.3324\n",
      "Epoch 191/500\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2940 - val_loss: 0.3294\n",
      "Epoch 192/500\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2937 - val_loss: 0.3275\n",
      "Epoch 193/500\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.2939 - val_loss: 0.3307\n",
      "Epoch 194/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2931 - val_loss: 0.3307\n",
      "Epoch 195/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2934 - val_loss: 0.3285\n",
      "Epoch 196/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2926 - val_loss: 0.3327\n",
      "Epoch 197/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2930 - val_loss: 0.3323\n",
      "Epoch 198/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2926 - val_loss: 0.3305\n",
      "Epoch 199/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2931 - val_loss: 0.3317\n",
      "Epoch 200/500\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2930 - val_loss: 0.3270\n",
      "Epoch 201/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2925 - val_loss: 0.3341\n",
      "Epoch 202/500\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2929 - val_loss: 0.3290\n",
      "Epoch 203/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2928 - val_loss: 0.3296\n",
      "Epoch 204/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2926 - val_loss: 0.3281\n",
      "Epoch 205/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2928 - val_loss: 0.3304\n",
      "Epoch 206/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2915 - val_loss: 0.3276\n",
      "Epoch 207/500\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.2915 - val_loss: 0.3273\n",
      "Epoch 208/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2914 - val_loss: 0.3306\n",
      "Epoch 209/500\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.2919 - val_loss: 0.3314\n",
      "Epoch 210/500\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2916 - val_loss: 0.3332\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3431\n",
      "[CV]  learning_rate=0.004799165091003534, n_hidden=1, n_neurons=31, total= 1.2min\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 56.0min finished\n",
      "/home/joschi/anaconda3/envs/tfgpu/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11610/11610 [==============================] - 1s 53us/sample - loss: 1.8090 - val_loss: 0.6907\n",
      "Epoch 2/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.6559 - val_loss: 0.6091\n",
      "Epoch 3/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5900 - val_loss: 0.5719\n",
      "Epoch 4/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.5612 - val_loss: 0.5493\n",
      "Epoch 5/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.5332 - val_loss: 0.5269\n",
      "Epoch 6/500\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.5161 - val_loss: 0.5131\n",
      "Epoch 7/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.5001 - val_loss: 0.4994\n",
      "Epoch 8/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4870 - val_loss: 0.4880\n",
      "Epoch 9/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4793 - val_loss: 0.4818\n",
      "Epoch 10/500\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4690 - val_loss: 0.4723\n",
      "Epoch 11/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4620 - val_loss: 0.4650\n",
      "Epoch 12/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4565 - val_loss: 0.4607\n",
      "Epoch 13/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4499 - val_loss: 0.4536\n",
      "Epoch 14/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4450 - val_loss: 0.4490\n",
      "Epoch 15/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4404 - val_loss: 0.4466\n",
      "Epoch 16/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4364 - val_loss: 0.4428\n",
      "Epoch 17/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4325 - val_loss: 0.4380\n",
      "Epoch 18/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4284 - val_loss: 0.4332\n",
      "Epoch 19/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4253 - val_loss: 0.4300\n",
      "Epoch 20/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4222 - val_loss: 0.4274\n",
      "Epoch 21/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4196 - val_loss: 0.4259\n",
      "Epoch 22/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4166 - val_loss: 0.4220\n",
      "Epoch 23/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4143 - val_loss: 0.4185\n",
      "Epoch 24/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4112 - val_loss: 0.4179\n",
      "Epoch 25/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4101 - val_loss: 0.4145\n",
      "Epoch 26/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4073 - val_loss: 0.4126\n",
      "Epoch 27/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4050 - val_loss: 0.4105\n",
      "Epoch 28/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.4029 - val_loss: 0.4098\n",
      "Epoch 29/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.4012 - val_loss: 0.4077\n",
      "Epoch 30/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3997 - val_loss: 0.4058\n",
      "Epoch 31/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3978 - val_loss: 0.4042\n",
      "Epoch 32/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3966 - val_loss: 0.4027\n",
      "Epoch 33/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3948 - val_loss: 0.4012\n",
      "Epoch 34/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3938 - val_loss: 0.3987\n",
      "Epoch 35/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3918 - val_loss: 0.3974\n",
      "Epoch 36/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3905 - val_loss: 0.3975\n",
      "Epoch 37/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3882 - val_loss: 0.3943\n",
      "Epoch 38/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3873 - val_loss: 0.3929\n",
      "Epoch 39/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3859 - val_loss: 0.3931\n",
      "Epoch 40/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3864 - val_loss: 0.3910\n",
      "Epoch 41/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3831 - val_loss: 0.3901\n",
      "Epoch 42/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3818 - val_loss: 0.3876\n",
      "Epoch 43/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3797 - val_loss: 0.3881\n",
      "Epoch 44/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3783 - val_loss: 0.3859\n",
      "Epoch 45/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3770 - val_loss: 0.3849\n",
      "Epoch 46/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3753 - val_loss: 0.3846\n",
      "Epoch 47/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3745 - val_loss: 0.3829\n",
      "Epoch 48/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3738 - val_loss: 0.3815\n",
      "Epoch 49/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3723 - val_loss: 0.3810\n",
      "Epoch 50/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3712 - val_loss: 0.3797\n",
      "Epoch 51/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3699 - val_loss: 0.3776\n",
      "Epoch 52/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3690 - val_loss: 0.3769\n",
      "Epoch 53/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3677 - val_loss: 0.3750\n",
      "Epoch 54/500\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3667 - val_loss: 0.3746\n",
      "Epoch 55/500\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3656 - val_loss: 0.3746\n",
      "Epoch 56/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3646 - val_loss: 0.3731\n",
      "Epoch 57/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3637 - val_loss: 0.3735\n",
      "Epoch 58/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3625 - val_loss: 0.3725\n",
      "Epoch 59/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3616 - val_loss: 0.3701\n",
      "Epoch 60/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3606 - val_loss: 0.3701\n",
      "Epoch 61/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3600 - val_loss: 0.3685\n",
      "Epoch 62/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3588 - val_loss: 0.3685\n",
      "Epoch 63/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3579 - val_loss: 0.3681\n",
      "Epoch 64/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3569 - val_loss: 0.3669\n",
      "Epoch 65/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3561 - val_loss: 0.3655\n",
      "Epoch 66/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3549 - val_loss: 0.3667\n",
      "Epoch 67/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3540 - val_loss: 0.3658\n",
      "Epoch 68/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3536 - val_loss: 0.3636\n",
      "Epoch 69/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3525 - val_loss: 0.3621\n",
      "Epoch 70/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3518 - val_loss: 0.3617\n",
      "Epoch 71/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3508 - val_loss: 0.3607\n",
      "Epoch 72/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3500 - val_loss: 0.3607\n",
      "Epoch 73/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3490 - val_loss: 0.3605\n",
      "Epoch 74/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3484 - val_loss: 0.3596\n",
      "Epoch 75/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3477 - val_loss: 0.3597\n",
      "Epoch 76/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3469 - val_loss: 0.3606\n",
      "Epoch 77/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3460 - val_loss: 0.3572\n",
      "Epoch 78/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3453 - val_loss: 0.3575\n",
      "Epoch 79/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3451 - val_loss: 0.3572\n",
      "Epoch 80/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3444 - val_loss: 0.3556\n",
      "Epoch 81/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3434 - val_loss: 0.3559\n",
      "Epoch 82/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3427 - val_loss: 0.3578\n",
      "Epoch 83/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3421 - val_loss: 0.3561\n",
      "Epoch 84/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3414 - val_loss: 0.3538\n",
      "Epoch 85/500\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3406 - val_loss: 0.3533\n",
      "Epoch 86/500\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3402 - val_loss: 0.3531\n",
      "Epoch 87/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3396 - val_loss: 0.3533\n",
      "Epoch 88/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3390 - val_loss: 0.3517\n",
      "Epoch 89/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3379 - val_loss: 0.3530\n",
      "Epoch 90/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3376 - val_loss: 0.3504\n",
      "Epoch 91/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3373 - val_loss: 0.3506\n",
      "Epoch 92/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3366 - val_loss: 0.3502\n",
      "Epoch 93/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3359 - val_loss: 0.3506\n",
      "Epoch 94/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3352 - val_loss: 0.3493\n",
      "Epoch 95/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3342 - val_loss: 0.3484\n",
      "Epoch 96/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3340 - val_loss: 0.3498\n",
      "Epoch 97/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3334 - val_loss: 0.3479\n",
      "Epoch 98/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3330 - val_loss: 0.3463\n",
      "Epoch 99/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3324 - val_loss: 0.3486\n",
      "Epoch 100/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3320 - val_loss: 0.3474\n",
      "Epoch 101/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3317 - val_loss: 0.3479\n",
      "Epoch 102/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3309 - val_loss: 0.3469\n",
      "Epoch 103/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3305 - val_loss: 0.3445\n",
      "Epoch 104/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3299 - val_loss: 0.3462\n",
      "Epoch 105/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3294 - val_loss: 0.3447\n",
      "Epoch 106/500\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3285 - val_loss: 0.3436\n",
      "Epoch 107/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3283 - val_loss: 0.3428\n",
      "Epoch 108/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3282 - val_loss: 0.3432\n",
      "Epoch 109/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3277 - val_loss: 0.3432\n",
      "Epoch 110/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3281 - val_loss: 0.3426\n",
      "Epoch 111/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3279 - val_loss: 0.3411\n",
      "Epoch 112/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3291 - val_loss: 0.3440\n",
      "Epoch 113/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3299 - val_loss: 0.3443\n",
      "Epoch 114/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3323 - val_loss: 0.3428\n",
      "Epoch 115/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3328 - val_loss: 0.3402\n",
      "Epoch 116/500\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3331 - val_loss: 0.3432\n",
      "Epoch 117/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3333 - val_loss: 0.3421\n",
      "Epoch 118/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3339 - val_loss: 0.3406\n",
      "Epoch 119/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3333 - val_loss: 0.3394\n",
      "Epoch 120/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3328 - val_loss: 0.3421\n",
      "Epoch 121/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3317 - val_loss: 0.3388\n",
      "Epoch 122/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3312 - val_loss: 0.3420\n",
      "Epoch 123/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3306 - val_loss: 0.3388\n",
      "Epoch 124/500\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3284 - val_loss: 0.3395\n",
      "Epoch 125/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3284 - val_loss: 0.3371\n",
      "Epoch 126/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3269 - val_loss: 0.3393\n",
      "Epoch 127/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3249 - val_loss: 0.3376\n",
      "Epoch 128/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3229 - val_loss: 0.3372\n",
      "Epoch 129/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3218 - val_loss: 0.3358\n",
      "Epoch 130/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3216 - val_loss: 0.3379\n",
      "Epoch 131/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3195 - val_loss: 0.3347\n",
      "Epoch 132/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3186 - val_loss: 0.3363\n",
      "Epoch 133/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3177 - val_loss: 0.3359\n",
      "Epoch 134/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3168 - val_loss: 0.3373\n",
      "Epoch 135/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3165 - val_loss: 0.3342\n",
      "Epoch 136/500\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3158 - val_loss: 0.3336\n",
      "Epoch 137/500\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3158 - val_loss: 0.3331\n",
      "Epoch 138/500\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3150 - val_loss: 0.3327\n",
      "Epoch 139/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3144 - val_loss: 0.3352\n",
      "Epoch 140/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3143 - val_loss: 0.3323\n",
      "Epoch 141/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3140 - val_loss: 0.3328\n",
      "Epoch 142/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3134 - val_loss: 0.3333\n",
      "Epoch 143/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3133 - val_loss: 0.3319\n",
      "Epoch 144/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3130 - val_loss: 0.3315\n",
      "Epoch 145/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3130 - val_loss: 0.3323\n",
      "Epoch 146/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3123 - val_loss: 0.3303\n",
      "Epoch 147/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3125 - val_loss: 0.3311\n",
      "Epoch 148/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3120 - val_loss: 0.3300\n",
      "Epoch 149/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3117 - val_loss: 0.3313\n",
      "Epoch 150/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3108 - val_loss: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3106 - val_loss: 0.3300\n",
      "Epoch 152/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3108 - val_loss: 0.3290\n",
      "Epoch 153/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3114 - val_loss: 0.3288\n",
      "Epoch 154/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3114 - val_loss: 0.3279\n",
      "Epoch 155/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3120 - val_loss: 0.3284\n",
      "Epoch 156/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3115 - val_loss: 0.3296\n",
      "Epoch 157/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3114 - val_loss: 0.3290\n",
      "Epoch 158/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3116 - val_loss: 0.3288\n",
      "Epoch 159/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3120 - val_loss: 0.3291\n",
      "Epoch 160/500\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3133 - val_loss: 0.3264\n",
      "Epoch 161/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3164 - val_loss: 0.3290\n",
      "Epoch 162/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3170 - val_loss: 0.3261\n",
      "Epoch 163/500\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3174 - val_loss: 0.3272\n",
      "Epoch 164/500\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3179 - val_loss: 0.3267\n",
      "Epoch 165/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3170 - val_loss: 0.3297\n",
      "Epoch 166/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3150 - val_loss: 0.3290\n",
      "Epoch 167/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3146 - val_loss: 0.3287\n",
      "Epoch 168/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3131 - val_loss: 0.3368\n",
      "Epoch 169/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3126 - val_loss: 0.3282\n",
      "Epoch 170/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3120 - val_loss: 0.3257\n",
      "Epoch 171/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3108 - val_loss: 0.3262\n",
      "Epoch 172/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3083 - val_loss: 0.3248\n",
      "Epoch 173/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3074 - val_loss: 0.3252\n",
      "Epoch 174/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3056 - val_loss: 0.3258\n",
      "Epoch 175/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3056 - val_loss: 0.3240\n",
      "Epoch 176/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3049 - val_loss: 0.3227\n",
      "Epoch 177/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3047 - val_loss: 0.3251\n",
      "Epoch 178/500\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3031 - val_loss: 0.3229\n",
      "Epoch 179/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3029 - val_loss: 0.3222\n",
      "Epoch 180/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3025 - val_loss: 0.3233\n",
      "Epoch 181/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3017 - val_loss: 0.3278\n",
      "Epoch 182/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3013 - val_loss: 0.3229\n",
      "Epoch 183/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3012 - val_loss: 0.3215\n",
      "Epoch 184/500\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3004 - val_loss: 0.3223\n",
      "Epoch 185/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3009 - val_loss: 0.3212\n",
      "Epoch 186/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3000 - val_loss: 0.3234\n",
      "Epoch 187/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2996 - val_loss: 0.3235\n",
      "Epoch 188/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2998 - val_loss: 0.3224\n",
      "Epoch 189/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2991 - val_loss: 0.3254\n",
      "Epoch 190/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2986 - val_loss: 0.3227\n",
      "Epoch 191/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2984 - val_loss: 0.3212\n",
      "Epoch 192/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2983 - val_loss: 0.3195\n",
      "Epoch 193/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2978 - val_loss: 0.3212\n",
      "Epoch 194/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.2969 - val_loss: 0.3193\n",
      "Epoch 195/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2973 - val_loss: 0.3192\n",
      "Epoch 196/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2970 - val_loss: 0.3206\n",
      "Epoch 197/500\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.2965 - val_loss: 0.3221\n",
      "Epoch 198/500\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.2963 - val_loss: 0.3204\n",
      "Epoch 199/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.2959 - val_loss: 0.3201\n",
      "Epoch 200/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2958 - val_loss: 0.3201\n",
      "Epoch 201/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2953 - val_loss: 0.3198\n",
      "Epoch 202/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2954 - val_loss: 0.3180\n",
      "Epoch 203/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2952 - val_loss: 0.3193\n",
      "Epoch 204/500\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.2946 - val_loss: 0.3196\n",
      "Epoch 205/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2943 - val_loss: 0.3179\n",
      "Epoch 206/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2943 - val_loss: 0.3174\n",
      "Epoch 207/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2938 - val_loss: 0.3171\n",
      "Epoch 208/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2934 - val_loss: 0.3170\n",
      "Epoch 209/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2939 - val_loss: 0.3184\n",
      "Epoch 210/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2933 - val_loss: 0.3201\n",
      "Epoch 211/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2933 - val_loss: 0.3169\n",
      "Epoch 212/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2928 - val_loss: 0.3159\n",
      "Epoch 213/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2927 - val_loss: 0.3179\n",
      "Epoch 214/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2918 - val_loss: 0.3202\n",
      "Epoch 215/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2922 - val_loss: 0.3208\n",
      "Epoch 216/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2917 - val_loss: 0.3175\n",
      "Epoch 217/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2919 - val_loss: 0.3153\n",
      "Epoch 218/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2911 - val_loss: 0.3175\n",
      "Epoch 219/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2915 - val_loss: 0.3148\n",
      "Epoch 220/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2911 - val_loss: 0.3152\n",
      "Epoch 221/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2912 - val_loss: 0.3144\n",
      "Epoch 222/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2911 - val_loss: 0.3154\n",
      "Epoch 223/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2918 - val_loss: 0.3164\n",
      "Epoch 224/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2926 - val_loss: 0.3135\n",
      "Epoch 225/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2941 - val_loss: 0.3151\n",
      "Epoch 226/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2946 - val_loss: 0.3160\n",
      "Epoch 227/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2998 - val_loss: 0.3167\n",
      "Epoch 228/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3050 - val_loss: 0.3136\n",
      "Epoch 229/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3136 - val_loss: 0.3155\n",
      "Epoch 230/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3079 - val_loss: 0.3149\n",
      "Epoch 231/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3038 - val_loss: 0.3189\n",
      "Epoch 232/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2985 - val_loss: 0.3135\n",
      "Epoch 233/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2932 - val_loss: 0.3156\n",
      "Epoch 234/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2905 - val_loss: 0.3125\n",
      "Epoch 235/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2892 - val_loss: 0.3142\n",
      "Epoch 236/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2883 - val_loss: 0.3181\n",
      "Epoch 237/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2885 - val_loss: 0.3131\n",
      "Epoch 238/500\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.2885 - val_loss: 0.3154\n",
      "Epoch 239/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2876 - val_loss: 0.3141\n",
      "Epoch 240/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2870 - val_loss: 0.3160\n",
      "Epoch 241/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2875 - val_loss: 0.3127\n",
      "Epoch 242/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2872 - val_loss: 0.3152\n",
      "Epoch 243/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2872 - val_loss: 0.3115\n",
      "Epoch 244/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2870 - val_loss: 0.3137\n",
      "Epoch 245/500\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2863 - val_loss: 0.3153\n",
      "Epoch 246/500\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2864 - val_loss: 0.3118\n",
      "Epoch 247/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2859 - val_loss: 0.3103\n",
      "Epoch 248/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2863 - val_loss: 0.3128\n",
      "Epoch 249/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2861 - val_loss: 0.3114\n",
      "Epoch 250/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2861 - val_loss: 0.3102\n",
      "Epoch 251/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2858 - val_loss: 0.3115\n",
      "Epoch 252/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2853 - val_loss: 0.3129\n",
      "Epoch 253/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2851 - val_loss: 0.3100\n",
      "Epoch 254/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2849 - val_loss: 0.3100\n",
      "Epoch 255/500\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.2845 - val_loss: 0.3127\n",
      "Epoch 256/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2848 - val_loss: 0.3104\n",
      "Epoch 257/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2839 - val_loss: 0.3111\n",
      "Epoch 258/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2845 - val_loss: 0.3094\n",
      "Epoch 259/500\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2838 - val_loss: 0.3100\n",
      "Epoch 260/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2841 - val_loss: 0.3095\n",
      "Epoch 261/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2837 - val_loss: 0.3084\n",
      "Epoch 262/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2835 - val_loss: 0.3094\n",
      "Epoch 263/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2834 - val_loss: 0.3076\n",
      "Epoch 264/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2835 - val_loss: 0.3082\n",
      "Epoch 265/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2831 - val_loss: 0.3075\n",
      "Epoch 266/500\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2827 - val_loss: 0.3097\n",
      "Epoch 267/500\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2828 - val_loss: 0.3075\n",
      "Epoch 268/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2826 - val_loss: 0.3084\n",
      "Epoch 269/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2827 - val_loss: 0.3074\n",
      "Epoch 270/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2823 - val_loss: 0.3064\n",
      "Epoch 271/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2819 - val_loss: 0.3079\n",
      "Epoch 272/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2820 - val_loss: 0.3077\n",
      "Epoch 273/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2819 - val_loss: 0.3089\n",
      "Epoch 274/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2818 - val_loss: 0.3072\n",
      "Epoch 275/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2811 - val_loss: 0.3067\n",
      "Epoch 276/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2813 - val_loss: 0.3066\n",
      "Epoch 277/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2812 - val_loss: 0.3084\n",
      "Epoch 278/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2811 - val_loss: 0.3066\n",
      "Epoch 279/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2807 - val_loss: 0.3081\n",
      "Epoch 280/500\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.2803 - val_loss: 0.3069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f3cf7fc4fd0>,\n",
       "                   iid='warn', n_iter=20, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f3cee236400>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,...\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(1e-3, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=20, cv=3,\n",
    "                                  verbose=2)\n",
    "rnd_search_cv.fit(X_train_scaled, y_train, epochs=500, batch_size=32,\n",
    "                 validation_data=(X_valid_scaled, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available:  True\n",
      "Params:  {'learning_rate': 0.0010450997151351185, 'n_hidden': 2, 'n_neurons': 61}\n",
      "Score:  -0.3230247050292732\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU available: \", tf.test.is_gpu_available())\n",
    "print(\"Params: \", rnd_search_cv.best_params_)\n",
    "print(\"Score: \", rnd_search_cv.best_score_)\n",
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 23us/sample - loss: 0.3128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3128184953632281"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### 2. Draw an ANN using the original artificial neurons (like the ones in Figure 10-3) that computes A ⊕ B (where ⊕ represents the XOR operation). Hint: A ⊕ B = (A∧ ¬ B) ∨ (¬ A  B).\n",
    "\n",
    "\n",
    "### 3. Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of threshold logic units trained using the Perceptron training algorithm)? How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier? \n",
    "\n",
    "Generally it is preferable to use Logistic Regressiong rather than a classical Perceptron, because it can output class probabilities instead of making the decision on a hard threshold. However, we can use the logistic activation function for our MLP instead of a step function (like heaviside and sgn), which outputs class probabilities, just like Logistic Regression.\n",
    "\n",
    "### 4. Why was the logistic activation function a key ingredient in training the first MLPs?\n",
    "\n",
    "The logistic activation function was so important, because unlike the step function it is differentiable with nonzero derivatives everywhere. This means that we can use gradient descent to optimize our Perceptron and make progress towards a (local or global) optimum with every step.\n",
    "\n",
    "### 5. Name three popular activation functions. Can you draw them?\n",
    "\n",
    "Among the most popular activation functions are the hyperpoblic tangent function \"tanh\", the rectified linear unit function \"ReLU\" and the step function signum.\n",
    "* tanh(z) = 2σ(2z) – 1, where σ is the logistic function. Just like σ it is s-shaped, but its values range from -1 to 1 instead of from 0 to 1. However, a huge problem is that, due to the s-shape of the function, the function's gradients are close to zero for large and small values of z. This means that our ANN converges very slow, if we are unlucky and end up with the vanishing gradient problem.\n",
    "* ReLU(z) = max(0, z). Obviously, ReLU is flat zero until 0, where a straight with slope 1 starts. ReLU is a very simple activation function, but it works very well, as long as it is used in hidden layers. It can be computed very fast. One drawback is that it is not differentiable in 0. An alternative is the similar looking ELU function.\n",
    "* sgn(z) = -1, if z < 0, = 0 if z = 0, = 1 if z > 0. It is a step function with a single step at z = 0 (or actually two steps, one might argue). Nowadays, sgn is not used anymore, because due to its flat nature, sgn always has derivate 0, making it unusable for gradient descent. Another disadvantage is the undifferentiability in z = 0.\n",
    "\n",
    "\n",
    "### 6. Suppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function.\n",
    "\n",
    "* What is the shape of the input matrix X?\n",
    "* What about the shape of the hidden layer’s weight vector Wh, and the shape of its bias vector bh?\n",
    "* What is the shape of the output layer’s weight vector Wo, and its bias vector bo?\n",
    "* What is the shape of the network’s output matrix Y?\n",
    "* Write the equation that computes the network’s output matrix Y as a function of X, W_h, b_h, W_o and b_o.\n",
    "\n",
    "### 7. How many neurons do you need in the output layer if you want to classify email into spam or ham? What activation function should you use in the output layer? If instead you want to tackle MNIST, how many neurons do you need in the output layer, using what activation function? Answer the same questions for getting your network to predict housing prices as in Chapter 2.\n",
    "\n",
    "### 8. What is backpropagation and how does it work? What is the difference between backpropagation and reverse-mode autodiff?\n",
    "\n",
    "### 9. Can you list all the hyperparameters you can tweak in an MLP? If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?\n",
    "\n",
    "### 10. Train a deep MLP on the MNIST dataset and see if you can get over 98% precision. Try adding all the bells and whistles (i.e., save checkpoints, use early stopping, plot learning curves using TensorBoard, and so on).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/500\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.4768 - accuracy: 0.8276 - val_loss: 0.3517 - val_accuracy: 0.8750\n",
      "Epoch 2/500\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.3603 - accuracy: 0.8679 - val_loss: 0.3407 - val_accuracy: 0.8786\n",
      "Epoch 3/500\n",
      "55000/55000 [==============================] - 3s 64us/sample - loss: 0.3253 - accuracy: 0.8802 - val_loss: 0.3518 - val_accuracy: 0.8714\n",
      "Epoch 4/500\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.3021 - accuracy: 0.8888 - val_loss: 0.2970 - val_accuracy: 0.8916\n",
      "Epoch 5/500\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.2835 - accuracy: 0.8941 - val_loss: 0.3214 - val_accuracy: 0.8840\n",
      "Epoch 6/500\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.2676 - accuracy: 0.8996 - val_loss: 0.2939 - val_accuracy: 0.8944\n",
      "Epoch 7/500\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.2557 - accuracy: 0.9040 - val_loss: 0.2934 - val_accuracy: 0.8978\n",
      "Epoch 8/500\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.2432 - accuracy: 0.9066 - val_loss: 0.3099 - val_accuracy: 0.8900\n",
      "Epoch 9/500\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.2319 - accuracy: 0.9114 - val_loss: 0.2995 - val_accuracy: 0.8974\n",
      "Epoch 10/500\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.2212 - accuracy: 0.9149 - val_loss: 0.3092 - val_accuracy: 0.8962\n",
      "Epoch 11/500\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.2139 - accuracy: 0.9181 - val_loss: 0.3266 - val_accuracy: 0.8908\n",
      "Epoch 12/500\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.2055 - accuracy: 0.9211 - val_loss: 0.3028 - val_accuracy: 0.9002\n",
      "Epoch 13/500\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.1964 - accuracy: 0.9254 - val_loss: 0.3294 - val_accuracy: 0.8888\n",
      "Epoch 14/500\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.1914 - accuracy: 0.9270 - val_loss: 0.3477 - val_accuracy: 0.8998\n",
      "Epoch 15/500\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.1868 - accuracy: 0.9291 - val_loss: 0.3188 - val_accuracy: 0.8992\n",
      "Epoch 16/500\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.1792 - accuracy: 0.9310 - val_loss: 0.3601 - val_accuracy: 0.8980\n",
      "Epoch 17/500\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.1715 - accuracy: 0.9348 - val_loss: 0.3434 - val_accuracy: 0.8968\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                 restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"mnist_model.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.4503 - accuracy: 0.8421\n"
     ]
    }
   ],
   "source": [
    "test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
