{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0-preview is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f05cc02ea58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f05cc04c358>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode=\"fan_avg\",\n",
    "                                                distribution=\"uniform\")\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "layer = keras.layers.Dense(10, activation=leaky_relu,\n",
    "                          kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(10, activation=\"selu\",\n",
    "                          kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0830 21:48:39.812587 139662994405184 deprecation.py:323] From /home/joschi/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4149: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),    \n",
    "    keras.layers.Dense(500, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 580,646\n",
      "Trainable params: 577,278\n",
      "Non-trainable params: 3,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'cond/Identity' type=Identity>,\n",
       " <tf.Operation 'cond_1/Identity' type=Identity>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 10s 182us/sample - loss: 0.4842 - accuracy: 0.8269 - val_loss: 0.3485 - val_accuracy: 0.8734\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.3759 - accuracy: 0.8621 - val_loss: 0.3334 - val_accuracy: 0.8758\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.3345 - accuracy: 0.8771 - val_loss: 0.3192 - val_accuracy: 0.8798\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 9s 163us/sample - loss: 0.3074 - accuracy: 0.8857 - val_loss: 0.3095 - val_accuracy: 0.8868\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 9s 161us/sample - loss: 0.2852 - accuracy: 0.8943 - val_loss: 0.2966 - val_accuracy: 0.8886\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 9s 163us/sample - loss: 0.2651 - accuracy: 0.8992 - val_loss: 0.3072 - val_accuracy: 0.8906\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.2486 - accuracy: 0.9062 - val_loss: 0.3047 - val_accuracy: 0.8924\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2346 - accuracy: 0.9123 - val_loss: 0.2908 - val_accuracy: 0.8954\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.2224 - accuracy: 0.9168 - val_loss: 0.3087 - val_accuracy: 0.8912\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2108 - accuracy: 0.9206 - val_loss: 0.2810 - val_accuracy: 0.8982\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1995 - accuracy: 0.9243 - val_loss: 0.2931 - val_accuracy: 0.8966\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1901 - accuracy: 0.9280 - val_loss: 0.2877 - val_accuracy: 0.9008\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1810 - accuracy: 0.9302 - val_loss: 0.3001 - val_accuracy: 0.9006\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1704 - accuracy: 0.9344 - val_loss: 0.2982 - val_accuracy: 0.9014\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1655 - accuracy: 0.9377 - val_loss: 0.3134 - val_accuracy: 0.9004\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1583 - accuracy: 0.9400 - val_loss: 0.3138 - val_accuracy: 0.8974\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 9s 163us/sample - loss: 0.1516 - accuracy: 0.9418 - val_loss: 0.3304 - val_accuracy: 0.9026\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1451 - accuracy: 0.9439 - val_loss: 0.3379 - val_accuracy: 0.8946\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1427 - accuracy: 0.9464 - val_loss: 0.3488 - val_accuracy: 0.8958\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1348 - accuracy: 0.9492 - val_loss: 0.3263 - val_accuracy: 0.9004\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                 restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.3147 - accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: my_model_A.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8f5cc3520da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_model_A.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_B_on_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_B_on_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_saved_model_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m                   (export_dir,\n\u001b[1;32m     82\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: my_model_A.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-64697b5fde76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_A_clone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_A_clone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_A' is not defined"
     ]
    }
   ],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_B_on_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b4c4fe94dbc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_B_on_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\",\n\u001b[1;32m      4\u001b[0m                     metrics=\"accuracy\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_B_on_A' is not defined"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\",\n",
    "                    metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponantial_decay(lr0, s):\n",
    "    def exponantial_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponantial_decay_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.4226 - accuracy: 0.8468 - val_loss: 0.3783 - val_accuracy: 0.8646\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.3574 - accuracy: 0.8680 - val_loss: 0.3666 - val_accuracy: 0.8664\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.3254 - accuracy: 0.8802 - val_loss: 0.3650 - val_accuracy: 0.8668\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.2999 - accuracy: 0.8881 - val_loss: 0.3345 - val_accuracy: 0.8806\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.2801 - accuracy: 0.8963 - val_loss: 0.3141 - val_accuracy: 0.8860\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.2572 - accuracy: 0.9029 - val_loss: 0.3233 - val_accuracy: 0.8830\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2389 - accuracy: 0.9101 - val_loss: 0.3038 - val_accuracy: 0.8926\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2201 - accuracy: 0.9162 - val_loss: 0.2899 - val_accuracy: 0.8982\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.2025 - accuracy: 0.9235 - val_loss: 0.2951 - val_accuracy: 0.8942\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1881 - accuracy: 0.9289 - val_loss: 0.3033 - val_accuracy: 0.8988\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1760 - accuracy: 0.9335 - val_loss: 0.2971 - val_accuracy: 0.9052\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1612 - accuracy: 0.9381 - val_loss: 0.3151 - val_accuracy: 0.8988\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 9s 163us/sample - loss: 0.1501 - accuracy: 0.9426 - val_loss: 0.3136 - val_accuracy: 0.9022\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1405 - accuracy: 0.9459 - val_loss: 0.3165 - val_accuracy: 0.9014\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1296 - accuracy: 0.9505 - val_loss: 0.3228 - val_accuracy: 0.9064\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1186 - accuracy: 0.9542 - val_loss: 0.3467 - val_accuracy: 0.9046\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.1126 - accuracy: 0.9569 - val_loss: 0.3611 - val_accuracy: 0.8982\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1048 - accuracy: 0.9588 - val_loss: 0.3627 - val_accuracy: 0.9014\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.3156 - accuracy: 0.8952\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),    \n",
    "    keras.layers.Dense(500, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 10s 185us/sample - loss: 0.4804 - accuracy: 0.8268 - val_loss: 0.3757 - val_accuracy: 0.8618\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.3726 - accuracy: 0.8635 - val_loss: 0.3282 - val_accuracy: 0.8742\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.3369 - accuracy: 0.8746 - val_loss: 0.3156 - val_accuracy: 0.8832\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.3044 - accuracy: 0.8866 - val_loss: 0.2999 - val_accuracy: 0.8902\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 9s 169us/sample - loss: 0.2848 - accuracy: 0.8928 - val_loss: 0.3039 - val_accuracy: 0.8930\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.2639 - accuracy: 0.9005 - val_loss: 0.3109 - val_accuracy: 0.8874\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.2484 - accuracy: 0.9073 - val_loss: 0.2962 - val_accuracy: 0.8942\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.2339 - accuracy: 0.9132 - val_loss: 0.2904 - val_accuracy: 0.8930\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2233 - accuracy: 0.9151 - val_loss: 0.2974 - val_accuracy: 0.8980\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.2094 - accuracy: 0.9209 - val_loss: 0.2940 - val_accuracy: 0.8960\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.2009 - accuracy: 0.9245 - val_loss: 0.2861 - val_accuracy: 0.8926\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.1886 - accuracy: 0.9296 - val_loss: 0.3043 - val_accuracy: 0.8958\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1815 - accuracy: 0.9312 - val_loss: 0.3017 - val_accuracy: 0.8966\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.1723 - accuracy: 0.9347 - val_loss: 0.2909 - val_accuracy: 0.9018\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1637 - accuracy: 0.9378 - val_loss: 0.3086 - val_accuracy: 0.9006\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.1577 - accuracy: 0.9403 - val_loss: 0.3066 - val_accuracy: 0.9004\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1189 - accuracy: 0.9555 - val_loss: 0.3111 - val_accuracy: 0.9070\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1128 - accuracy: 0.9571 - val_loss: 0.3144 - val_accuracy: 0.9064\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1057 - accuracy: 0.9606 - val_loss: 0.3277 - val_accuracy: 0.9046\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.0971 - accuracy: 0.9622 - val_loss: 0.3350 - val_accuracy: 0.9062\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.0934 - accuracy: 0.9641 - val_loss: 0.3509 - val_accuracy: 0.9032\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.3196 - accuracy: 0.8933\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 20 * len(X_train) // 32\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation=\"selu\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(500),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\", \n",
    "                     kernel_initializer=\"glorot_uniform\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 5s 97us/sample - loss: 2.7632 - accuracy: 0.7746 - val_loss: 0.9901 - val_accuracy: 0.7462\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.9107 - accuracy: 0.7903 - val_loss: 0.9019 - val_accuracy: 0.8008\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.8866 - accuracy: 0.7999 - val_loss: 0.8826 - val_accuracy: 0.7972\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.8804 - accuracy: 0.8049 - val_loss: 0.8477 - val_accuracy: 0.8158\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.8742 - accuracy: 0.8058 - val_loss: 0.8265 - val_accuracy: 0.8230\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.8661 - accuracy: 0.8108 - val_loss: 0.8548 - val_accuracy: 0.8224\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.8660 - accuracy: 0.8097 - val_loss: 0.8941 - val_accuracy: 0.7866\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.8674 - accuracy: 0.8109 - val_loss: 0.8347 - val_accuracy: 0.8238\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.8596 - accuracy: 0.8126 - val_loss: 0.8545 - val_accuracy: 0.8212\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.8612 - accuracy: 0.8131 - val_loss: 0.8186 - val_accuracy: 0.8328\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.8684 - accuracy: 0.8111 - val_loss: 0.8375 - val_accuracy: 0.8168\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.8569 - accuracy: 0.8153 - val_loss: 0.8445 - val_accuracy: 0.8222\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.8624 - accuracy: 0.8131 - val_loss: 0.8249 - val_accuracy: 0.8400\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.8582 - accuracy: 0.8148 - val_loss: 0.8285 - val_accuracy: 0.8222\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.8521 - accuracy: 0.8161 - val_loss: 0.8467 - val_accuracy: 0.8252\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.8577 - accuracy: 0.8145 - val_loss: 0.8151 - val_accuracy: 0.8370\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.8532 - accuracy: 0.8159 - val_loss: 0.8772 - val_accuracy: 0.8114\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.8535 - accuracy: 0.8155 - val_loss: 0.8317 - val_accuracy: 0.8336\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.8564 - accuracy: 0.8168 - val_loss: 0.8458 - val_accuracy: 0.8180\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.8549 - accuracy: 0.8156 - val_loss: 0.9310 - val_accuracy: 0.8030\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.8532 - accuracy: 0.8178 - val_loss: 0.8703 - val_accuracy: 0.7972\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8635 - accuracy: 0.8130 - val_loss: 0.8323 - val_accuracy: 0.8242\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.8551 - accuracy: 0.8169 - val_loss: 0.8242 - val_accuracy: 0.8256\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.8521 - accuracy: 0.8164 - val_loss: 0.8527 - val_accuracy: 0.8242\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.8544 - accuracy: 0.8167 - val_loss: 0.8328 - val_accuracy: 0.8248\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.8540 - accuracy: 0.8159 - val_loss: 0.8859 - val_accuracy: 0.8102\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   epochs=100,\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 44us/sample - loss: 0.8486 - accuracy: 0.8186\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(500, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.7010 - accuracy: 0.7488 - val_loss: 0.4460 - val_accuracy: 0.8370\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.5265 - accuracy: 0.8053 - val_loss: 0.3940 - val_accuracy: 0.8536\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.4942 - accuracy: 0.8174 - val_loss: 0.3810 - val_accuracy: 0.8554\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.4761 - accuracy: 0.8245 - val_loss: 0.4213 - val_accuracy: 0.8396\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.4584 - accuracy: 0.8323 - val_loss: 0.3574 - val_accuracy: 0.8706\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.4431 - accuracy: 0.8380 - val_loss: 0.3660 - val_accuracy: 0.8706\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.4362 - accuracy: 0.8409 - val_loss: 0.3407 - val_accuracy: 0.8710\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.4258 - accuracy: 0.8439 - val_loss: 0.3565 - val_accuracy: 0.8664\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.4185 - accuracy: 0.8463 - val_loss: 0.3294 - val_accuracy: 0.8802\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.4121 - accuracy: 0.8506 - val_loss: 0.3498 - val_accuracy: 0.8666\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.4061 - accuracy: 0.8530 - val_loss: 0.3294 - val_accuracy: 0.8772\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.4046 - accuracy: 0.8534 - val_loss: 0.3214 - val_accuracy: 0.8782\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.3947 - accuracy: 0.8568 - val_loss: 0.3204 - val_accuracy: 0.8772\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.3946 - accuracy: 0.8574 - val_loss: 0.3228 - val_accuracy: 0.8844\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.3918 - accuracy: 0.8573 - val_loss: 0.3277 - val_accuracy: 0.8804\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.3831 - accuracy: 0.8600 - val_loss: 0.3260 - val_accuracy: 0.8776\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3846 - accuracy: 0.8618 - val_loss: 0.3082 - val_accuracy: 0.8872\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.3783 - accuracy: 0.8623 - val_loss: 0.3029 - val_accuracy: 0.8882\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.3772 - accuracy: 0.8619 - val_loss: 0.3154 - val_accuracy: 0.8828\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3749 - accuracy: 0.8638 - val_loss: 0.3055 - val_accuracy: 0.8862\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3749 - accuracy: 0.8648 - val_loss: 0.3051 - val_accuracy: 0.8896\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3693 - accuracy: 0.8660 - val_loss: 0.3074 - val_accuracy: 0.8902\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3675 - accuracy: 0.8678 - val_loss: 0.3054 - val_accuracy: 0.8848\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3670 - accuracy: 0.8661 - val_loss: 0.3134 - val_accuracy: 0.8902\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3653 - accuracy: 0.8678 - val_loss: 0.3150 - val_accuracy: 0.8858\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3633 - accuracy: 0.8684 - val_loss: 0.3068 - val_accuracy: 0.8878\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3636 - accuracy: 0.8685 - val_loss: 0.3318 - val_accuracy: 0.8794\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.3644 - accuracy: 0.8690 - val_loss: 0.3132 - val_accuracy: 0.8862\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 42us/sample - loss: 0.3377 - accuracy: 0.8772\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=15,\n",
    "                                                 restore_best_weights=True)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(500, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.3),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 7s 125us/sample - loss: 0.7229 - accuracy: 0.7390 - val_loss: 0.4445 - val_accuracy: 0.8338\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.5369 - accuracy: 0.8026 - val_loss: 0.4081 - val_accuracy: 0.8454\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.4928 - accuracy: 0.8182 - val_loss: 0.3913 - val_accuracy: 0.8512\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.4644 - accuracy: 0.8294 - val_loss: 0.3728 - val_accuracy: 0.8564\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.4426 - accuracy: 0.8349 - val_loss: 0.3503 - val_accuracy: 0.8658\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.4309 - accuracy: 0.8390 - val_loss: 0.3433 - val_accuracy: 0.8704\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.4180 - accuracy: 0.8455 - val_loss: 0.3377 - val_accuracy: 0.8734\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.4068 - accuracy: 0.8476 - val_loss: 0.3344 - val_accuracy: 0.8726\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3980 - accuracy: 0.8520 - val_loss: 0.3194 - val_accuracy: 0.8828\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3903 - accuracy: 0.8538 - val_loss: 0.3231 - val_accuracy: 0.8830\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3887 - accuracy: 0.8553 - val_loss: 0.3207 - val_accuracy: 0.8828\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3806 - accuracy: 0.8580 - val_loss: 0.3213 - val_accuracy: 0.8860\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3745 - accuracy: 0.8605 - val_loss: 0.3050 - val_accuracy: 0.8876\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3700 - accuracy: 0.8638 - val_loss: 0.3067 - val_accuracy: 0.8882\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3652 - accuracy: 0.8633 - val_loss: 0.3173 - val_accuracy: 0.8818\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3599 - accuracy: 0.8664 - val_loss: 0.3016 - val_accuracy: 0.8894\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3582 - accuracy: 0.8687 - val_loss: 0.3073 - val_accuracy: 0.8852\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3531 - accuracy: 0.8689 - val_loss: 0.3011 - val_accuracy: 0.8870\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.3498 - accuracy: 0.8693 - val_loss: 0.3034 - val_accuracy: 0.8874\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.3495 - accuracy: 0.8701 - val_loss: 0.2991 - val_accuracy: 0.8920\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3475 - accuracy: 0.8703 - val_loss: 0.3068 - val_accuracy: 0.8884\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3453 - accuracy: 0.8715 - val_loss: 0.2952 - val_accuracy: 0.8908\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3424 - accuracy: 0.8718 - val_loss: 0.2970 - val_accuracy: 0.8896\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3368 - accuracy: 0.8741 - val_loss: 0.2988 - val_accuracy: 0.8846\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3368 - accuracy: 0.8741 - val_loss: 0.2942 - val_accuracy: 0.8914\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3376 - accuracy: 0.8749 - val_loss: 0.2933 - val_accuracy: 0.8916\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3333 - accuracy: 0.8763 - val_loss: 0.3003 - val_accuracy: 0.8888\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3290 - accuracy: 0.8780 - val_loss: 0.2937 - val_accuracy: 0.8900\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3289 - accuracy: 0.8775 - val_loss: 0.2879 - val_accuracy: 0.8896\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3253 - accuracy: 0.8789 - val_loss: 0.2883 - val_accuracy: 0.8932\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3295 - accuracy: 0.8785 - val_loss: 0.2931 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.3272 - accuracy: 0.8784 - val_loss: 0.2825 - val_accuracy: 0.8954\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3249 - accuracy: 0.8786 - val_loss: 0.2838 - val_accuracy: 0.8936\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3179 - accuracy: 0.8813 - val_loss: 0.2853 - val_accuracy: 0.8986\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3240 - accuracy: 0.8783 - val_loss: 0.2840 - val_accuracy: 0.8962\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3147 - accuracy: 0.8816 - val_loss: 0.2935 - val_accuracy: 0.8928\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3186 - accuracy: 0.8801 - val_loss: 0.2846 - val_accuracy: 0.9010\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3185 - accuracy: 0.8807 - val_loss: 0.2913 - val_accuracy: 0.8938\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3159 - accuracy: 0.8831 - val_loss: 0.2790 - val_accuracy: 0.8932\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3140 - accuracy: 0.8829 - val_loss: 0.2770 - val_accuracy: 0.8984\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3111 - accuracy: 0.8824 - val_loss: 0.2797 - val_accuracy: 0.8948\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3100 - accuracy: 0.8829 - val_loss: 0.2889 - val_accuracy: 0.8970\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3090 - accuracy: 0.8836 - val_loss: 0.2852 - val_accuracy: 0.8964\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3085 - accuracy: 0.8841 - val_loss: 0.2842 - val_accuracy: 0.8976\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3081 - accuracy: 0.8848 - val_loss: 0.2980 - val_accuracy: 0.8928\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3065 - accuracy: 0.8857 - val_loss: 0.2852 - val_accuracy: 0.8974\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3064 - accuracy: 0.8866 - val_loss: 0.2837 - val_accuracy: 0.8978\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3041 - accuracy: 0.8865 - val_loss: 0.2832 - val_accuracy: 0.8990\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3052 - accuracy: 0.8864 - val_loss: 0.2795 - val_accuracy: 0.9002\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3034 - accuracy: 0.8853 - val_loss: 0.2797 - val_accuracy: 0.8976\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2992 - accuracy: 0.8866 - val_loss: 0.2735 - val_accuracy: 0.9016\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2984 - accuracy: 0.8890 - val_loss: 0.2822 - val_accuracy: 0.9008\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3037 - accuracy: 0.8851 - val_loss: 0.2844 - val_accuracy: 0.8964\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3038 - accuracy: 0.8873 - val_loss: 0.2857 - val_accuracy: 0.8980\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2971 - accuracy: 0.8882 - val_loss: 0.2750 - val_accuracy: 0.8998\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2976 - accuracy: 0.8875 - val_loss: 0.2878 - val_accuracy: 0.8974\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.2966 - accuracy: 0.8904 - val_loss: 0.2797 - val_accuracy: 0.8970\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2999 - accuracy: 0.8876 - val_loss: 0.2810 - val_accuracy: 0.8986\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.2974 - accuracy: 0.8886 - val_loss: 0.2822 - val_accuracy: 0.8966\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2953 - accuracy: 0.8893 - val_loss: 0.2690 - val_accuracy: 0.8988\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2940 - accuracy: 0.8903 - val_loss: 0.2809 - val_accuracy: 0.9008\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.2903 - accuracy: 0.8911 - val_loss: 0.2758 - val_accuracy: 0.9018\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2941 - accuracy: 0.8896 - val_loss: 0.2801 - val_accuracy: 0.9002\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2920 - accuracy: 0.8902 - val_loss: 0.2796 - val_accuracy: 0.8990\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2917 - accuracy: 0.8902 - val_loss: 0.2774 - val_accuracy: 0.8996\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2894 - accuracy: 0.8918 - val_loss: 0.2766 - val_accuracy: 0.9012\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2887 - accuracy: 0.8901 - val_loss: 0.2758 - val_accuracy: 0.8998\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2903 - accuracy: 0.8904 - val_loss: 0.2732 - val_accuracy: 0.9028\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2857 - accuracy: 0.8932 - val_loss: 0.2737 - val_accuracy: 0.8984\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2854 - accuracy: 0.8933 - val_loss: 0.2904 - val_accuracy: 0.8956\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2906 - accuracy: 0.8926 - val_loss: 0.2759 - val_accuracy: 0.9030\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.2864 - accuracy: 0.8932 - val_loss: 0.2817 - val_accuracy: 0.9010\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.2860 - accuracy: 0.8924 - val_loss: 0.2831 - val_accuracy: 0.8948\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2858 - accuracy: 0.8934 - val_loss: 0.2725 - val_accuracy: 0.8982\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2846 - accuracy: 0.8936 - val_loss: 0.2936 - val_accuracy: 0.8980\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.3053 - accuracy: 0.8909\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test, training=True)\n",
    "                       for sample in range(100)])\n",
    "\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.22, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.07, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.12, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.51, 0.  , 0.46]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.13, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.07, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.42, 0.  , 0.49]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.04, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.03, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.34, 0.  , 0.57]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.32, 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.38, 0.  , 0.42, 0.  , 0.19]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.24, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.37, 0.  , 0.63]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.69, 0.  , 0.28]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.02, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.17, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.31, 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.  , 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.75, 0.  , 0.24]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.32, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.75]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.28, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.63, 0.  , 0.02, 0.  , 0.36]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.27, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.19, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.03, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.51, 0.  , 0.24, 0.  , 0.24]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.39, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.19, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.26, 0.  , 0.58]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.1 , 0.  , 0.87]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.15, 0.  , 0.2 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f03d9176438>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                  kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(500, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.Nadam(),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 10s 184us/sample - loss: 0.7377 - accuracy: 0.7446 - val_loss: 0.4297 - val_accuracy: 0.8410\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.5443 - accuracy: 0.8024 - val_loss: 0.4059 - val_accuracy: 0.8524\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.5020 - accuracy: 0.8166 - val_loss: 0.3975 - val_accuracy: 0.8566\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.4862 - accuracy: 0.8203 - val_loss: 0.3744 - val_accuracy: 0.8634\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.4723 - accuracy: 0.8281 - val_loss: 0.3843 - val_accuracy: 0.8598\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.4678 - accuracy: 0.8305 - val_loss: 0.3541 - val_accuracy: 0.8674\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.4505 - accuracy: 0.8366 - val_loss: 0.3878 - val_accuracy: 0.8628\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.4468 - accuracy: 0.8373 - val_loss: 0.3387 - val_accuracy: 0.8770\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.4409 - accuracy: 0.8397 - val_loss: 0.3422 - val_accuracy: 0.8746\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.4322 - accuracy: 0.8419 - val_loss: 0.3355 - val_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.4324 - accuracy: 0.8443 - val_loss: 0.3413 - val_accuracy: 0.8776\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.4282 - accuracy: 0.8443 - val_loss: 0.3352 - val_accuracy: 0.8768\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.4227 - accuracy: 0.8474 - val_loss: 0.3337 - val_accuracy: 0.8758\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.4190 - accuracy: 0.8483 - val_loss: 0.3437 - val_accuracy: 0.8690\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 10s 176us/sample - loss: 0.4134 - accuracy: 0.8499 - val_loss: 0.3443 - val_accuracy: 0.8758\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.4129 - accuracy: 0.8504 - val_loss: 0.3300 - val_accuracy: 0.8790\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.4137 - accuracy: 0.8507 - val_loss: 0.3230 - val_accuracy: 0.8824\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.4135 - accuracy: 0.8515 - val_loss: 0.3293 - val_accuracy: 0.8792\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.4094 - accuracy: 0.8525 - val_loss: 0.3416 - val_accuracy: 0.8876\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.4038 - accuracy: 0.8549 - val_loss: 0.3300 - val_accuracy: 0.8812\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.4031 - accuracy: 0.8541 - val_loss: 0.3348 - val_accuracy: 0.8772\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.4045 - accuracy: 0.8532 - val_loss: 0.3109 - val_accuracy: 0.8850\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.4041 - accuracy: 0.8543 - val_loss: 0.3101 - val_accuracy: 0.8850\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3972 - accuracy: 0.8567 - val_loss: 0.3071 - val_accuracy: 0.8862\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.3957 - accuracy: 0.8572 - val_loss: 0.3209 - val_accuracy: 0.8806\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 10s 176us/sample - loss: 0.3948 - accuracy: 0.8567 - val_loss: 0.3287 - val_accuracy: 0.8794\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.3930 - accuracy: 0.8577 - val_loss: 0.3076 - val_accuracy: 0.8890\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.3921 - accuracy: 0.8583 - val_loss: 0.3086 - val_accuracy: 0.8842\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3944 - accuracy: 0.8591 - val_loss: 0.3107 - val_accuracy: 0.8894\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.3556 - accuracy: 0.8700 - val_loss: 0.2933 - val_accuracy: 0.8920\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3453 - accuracy: 0.8720 - val_loss: 0.2952 - val_accuracy: 0.8944\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3473 - accuracy: 0.8722 - val_loss: 0.2946 - val_accuracy: 0.8938\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.3414 - accuracy: 0.8747 - val_loss: 0.2943 - val_accuracy: 0.8936\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 9s 173us/sample - loss: 0.3411 - accuracy: 0.8769 - val_loss: 0.2943 - val_accuracy: 0.8928\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 9s 171us/sample - loss: 0.3387 - accuracy: 0.8767 - val_loss: 0.2974 - val_accuracy: 0.8924\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.3216 - accuracy: 0.8817 - val_loss: 0.2868 - val_accuracy: 0.8982\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.3180 - accuracy: 0.8830 - val_loss: 0.2846 - val_accuracy: 0.8976\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3140 - accuracy: 0.8830 - val_loss: 0.2864 - val_accuracy: 0.8966\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.3151 - accuracy: 0.8847 - val_loss: 0.2831 - val_accuracy: 0.8990\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3096 - accuracy: 0.8861 - val_loss: 0.2834 - val_accuracy: 0.8978\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3111 - accuracy: 0.8864 - val_loss: 0.2808 - val_accuracy: 0.8986\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.3110 - accuracy: 0.8868 - val_loss: 0.2855 - val_accuracy: 0.8972\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3095 - accuracy: 0.8852 - val_loss: 0.2776 - val_accuracy: 0.8996\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3113 - accuracy: 0.8851 - val_loss: 0.2779 - val_accuracy: 0.9012\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3064 - accuracy: 0.8835 - val_loss: 0.2787 - val_accuracy: 0.8976\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3079 - accuracy: 0.8869 - val_loss: 0.2807 - val_accuracy: 0.8942\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.3025 - accuracy: 0.8870 - val_loss: 0.2802 - val_accuracy: 0.8974\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.3018 - accuracy: 0.8869 - val_loss: 0.2775 - val_accuracy: 0.8976\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.2979 - accuracy: 0.8887 - val_loss: 0.2746 - val_accuracy: 0.8992\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.2954 - accuracy: 0.8897 - val_loss: 0.2742 - val_accuracy: 0.8982\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.2921 - accuracy: 0.8910 - val_loss: 0.2778 - val_accuracy: 0.8994\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.2972 - accuracy: 0.8902 - val_loss: 0.2723 - val_accuracy: 0.9006\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 9s 173us/sample - loss: 0.2952 - accuracy: 0.8897 - val_loss: 0.2740 - val_accuracy: 0.8998\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.2947 - accuracy: 0.8915 - val_loss: 0.2737 - val_accuracy: 0.9002\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.2961 - accuracy: 0.8903 - val_loss: 0.2748 - val_accuracy: 0.9004\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.2918 - accuracy: 0.8907 - val_loss: 0.2744 - val_accuracy: 0.8992\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.2900 - accuracy: 0.8918 - val_loss: 0.2742 - val_accuracy: 0.9008\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.2900 - accuracy: 0.8913 - val_loss: 0.2707 - val_accuracy: 0.9020\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.2867 - accuracy: 0.8931 - val_loss: 0.2697 - val_accuracy: 0.9036\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.2875 - accuracy: 0.8921 - val_loss: 0.2719 - val_accuracy: 0.9004\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.2847 - accuracy: 0.8932 - val_loss: 0.2715 - val_accuracy: 0.8990\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.2837 - accuracy: 0.8930 - val_loss: 0.2721 - val_accuracy: 0.9008\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.2835 - accuracy: 0.8957 - val_loss: 0.2733 - val_accuracy: 0.9006\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.2848 - accuracy: 0.8936 - val_loss: 0.2707 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.2838 - accuracy: 0.8934 - val_loss: 0.2714 - val_accuracy: 0.9018\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.2832 - accuracy: 0.8934 - val_loss: 0.2713 - val_accuracy: 0.9014\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.2804 - accuracy: 0.8947 - val_loss: 0.2701 - val_accuracy: 0.9022\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.2811 - accuracy: 0.8952 - val_loss: 0.2702 - val_accuracy: 0.9020\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.2825 - accuracy: 0.8933 - val_loss: 0.2708 - val_accuracy: 0.9026\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.2793 - accuracy: 0.8951 - val_loss: 0.2715 - val_accuracy: 0.9024\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.2809 - accuracy: 0.8941 - val_loss: 0.2706 - val_accuracy: 0.9014\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.2808 - accuracy: 0.8951 - val_loss: 0.2703 - val_accuracy: 0.9024\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.2833 - accuracy: 0.8930 - val_loss: 0.2703 - val_accuracy: 0.9030\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.2823 - accuracy: 0.8927 - val_loss: 0.2700 - val_accuracy: 0.9032\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/sample - loss: 0.3062 - accuracy: 0.8903\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.1),\n",
    "    keras.layers.Dense(500, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.3),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.1),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.Nadam(),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 12s 215us/sample - loss: 0.8760 - accuracy: 0.6718 - val_loss: 0.8886 - val_accuracy: 0.7148\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.7192 - accuracy: 0.7303 - val_loss: 0.7470 - val_accuracy: 0.7904\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.6836 - accuracy: 0.7429 - val_loss: 0.7350 - val_accuracy: 0.8030\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.6626 - accuracy: 0.7501 - val_loss: 0.6259 - val_accuracy: 0.8064\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.6470 - accuracy: 0.7581 - val_loss: 0.6751 - val_accuracy: 0.8018\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.6354 - accuracy: 0.7614 - val_loss: 0.5958 - val_accuracy: 0.8154\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.6256 - accuracy: 0.7650 - val_loss: 0.6520 - val_accuracy: 0.8172\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.6220 - accuracy: 0.7663 - val_loss: 0.5917 - val_accuracy: 0.8240\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.6127 - accuracy: 0.7714 - val_loss: 0.5769 - val_accuracy: 0.8256\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.6133 - accuracy: 0.7706 - val_loss: 0.6125 - val_accuracy: 0.8176\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.6082 - accuracy: 0.7702 - val_loss: 0.7038 - val_accuracy: 0.8172\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.6017 - accuracy: 0.7739 - val_loss: 0.5927 - val_accuracy: 0.8330\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5984 - accuracy: 0.7766 - val_loss: 0.5345 - val_accuracy: 0.8462\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.5952 - accuracy: 0.7764 - val_loss: 0.7448 - val_accuracy: 0.8110\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5981 - accuracy: 0.7789 - val_loss: 0.6440 - val_accuracy: 0.8214\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5887 - accuracy: 0.7773 - val_loss: 0.5771 - val_accuracy: 0.8372\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5854 - accuracy: 0.7804 - val_loss: 0.5651 - val_accuracy: 0.8350\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5909 - accuracy: 0.7769 - val_loss: 0.5302 - val_accuracy: 0.8404\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5860 - accuracy: 0.7795 - val_loss: 0.5593 - val_accuracy: 0.8412\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5868 - accuracy: 0.7798 - val_loss: 0.5195 - val_accuracy: 0.8458\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5832 - accuracy: 0.7815 - val_loss: 0.6405 - val_accuracy: 0.8258\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5853 - accuracy: 0.7794 - val_loss: 0.5615 - val_accuracy: 0.8350\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5851 - accuracy: 0.7803 - val_loss: 0.5718 - val_accuracy: 0.8414\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5810 - accuracy: 0.7829 - val_loss: 0.6328 - val_accuracy: 0.8420\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5775 - accuracy: 0.7832 - val_loss: 0.7335 - val_accuracy: 0.8180\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5597 - accuracy: 0.7910 - val_loss: 0.5270 - val_accuracy: 0.8424\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5597 - accuracy: 0.7902 - val_loss: 0.5311 - val_accuracy: 0.8442\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 11s 207us/sample - loss: 0.5480 - accuracy: 0.7934 - val_loss: 0.5268 - val_accuracy: 0.8454\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5517 - accuracy: 0.7910 - val_loss: 0.5334 - val_accuracy: 0.8564\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5427 - accuracy: 0.7930 - val_loss: 0.5088 - val_accuracy: 0.8566\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5442 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.8512\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5423 - accuracy: 0.7953 - val_loss: 0.5497 - val_accuracy: 0.8594\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5412 - accuracy: 0.7976 - val_loss: 0.5572 - val_accuracy: 0.8520\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.5384 - accuracy: 0.7970 - val_loss: 0.5491 - val_accuracy: 0.8468\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.5373 - accuracy: 0.7979 - val_loss: 0.5038 - val_accuracy: 0.8546\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5377 - accuracy: 0.7977 - val_loss: 0.5147 - val_accuracy: 0.8586\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.5325 - accuracy: 0.8000 - val_loss: 0.5218 - val_accuracy: 0.8512\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.5354 - accuracy: 0.7980 - val_loss: 0.4693 - val_accuracy: 0.8618\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5380 - accuracy: 0.7972 - val_loss: 0.5124 - val_accuracy: 0.8580\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5337 - accuracy: 0.8003 - val_loss: 0.5274 - val_accuracy: 0.8564\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5374 - accuracy: 0.7992 - val_loss: 0.4913 - val_accuracy: 0.8554\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5342 - accuracy: 0.7976 - val_loss: 0.4986 - val_accuracy: 0.8612\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.5340 - accuracy: 0.7991 - val_loss: 0.4827 - val_accuracy: 0.8598\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5232 - accuracy: 0.8025 - val_loss: 0.5444 - val_accuracy: 0.8530\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5236 - accuracy: 0.8021 - val_loss: 0.5019 - val_accuracy: 0.8588\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5232 - accuracy: 0.8037 - val_loss: 0.4678 - val_accuracy: 0.8624\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5175 - accuracy: 0.8034 - val_loss: 0.4897 - val_accuracy: 0.8578\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5198 - accuracy: 0.8031 - val_loss: 0.4914 - val_accuracy: 0.8600\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5170 - accuracy: 0.8047 - val_loss: 0.4616 - val_accuracy: 0.8628\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5127 - accuracy: 0.8063 - val_loss: 0.4734 - val_accuracy: 0.8612\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5122 - accuracy: 0.8073 - val_loss: 0.4864 - val_accuracy: 0.8602\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 11s 207us/sample - loss: 0.5153 - accuracy: 0.8052 - val_loss: 0.4872 - val_accuracy: 0.8628\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5120 - accuracy: 0.8081 - val_loss: 0.4742 - val_accuracy: 0.8640\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.5137 - accuracy: 0.8050 - val_loss: 0.5174 - val_accuracy: 0.8572\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.5074 - accuracy: 0.8080 - val_loss: 0.4747 - val_accuracy: 0.8620\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5050 - accuracy: 0.8091 - val_loss: 0.4764 - val_accuracy: 0.8616\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5025 - accuracy: 0.8083 - val_loss: 0.4450 - val_accuracy: 0.8692\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5084 - accuracy: 0.8072 - val_loss: 0.4644 - val_accuracy: 0.8650\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5024 - accuracy: 0.8097 - val_loss: 0.4727 - val_accuracy: 0.8642\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.5000 - accuracy: 0.8112 - val_loss: 0.4701 - val_accuracy: 0.8624\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5047 - accuracy: 0.8112 - val_loss: 0.4706 - val_accuracy: 0.8636\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5080 - accuracy: 0.8077 - val_loss: 0.4596 - val_accuracy: 0.8642\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.5020 - accuracy: 0.8088 - val_loss: 0.4405 - val_accuracy: 0.8672\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.4993 - accuracy: 0.8118 - val_loss: 0.4580 - val_accuracy: 0.8660\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.4956 - accuracy: 0.8126 - val_loss: 0.4621 - val_accuracy: 0.8650\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5018 - accuracy: 0.8100 - val_loss: 0.4657 - val_accuracy: 0.8656\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5010 - accuracy: 0.8103 - val_loss: 0.4731 - val_accuracy: 0.8648\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.4957 - accuracy: 0.8120 - val_loss: 0.4722 - val_accuracy: 0.8644\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.4982 - accuracy: 0.8120 - val_loss: 0.4658 - val_accuracy: 0.8618\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.4998 - accuracy: 0.8122 - val_loss: 0.4595 - val_accuracy: 0.8648\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.4999 - accuracy: 0.8125 - val_loss: 0.4708 - val_accuracy: 0.8642\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.4935 - accuracy: 0.8122 - val_loss: 0.4609 - val_accuracy: 0.8644\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.4970 - accuracy: 0.8123 - val_loss: 0.4543 - val_accuracy: 0.8656\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.4961 - accuracy: 0.8115 - val_loss: 0.4593 - val_accuracy: 0.8644\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.4969 - accuracy: 0.8110 - val_loss: 0.4570 - val_accuracy: 0.8656\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.4957 - accuracy: 0.8127 - val_loss: 0.4563 - val_accuracy: 0.8664\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.4953 - accuracy: 0.8132 - val_loss: 0.4566 - val_accuracy: 0.8664\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.4957 - accuracy: 0.8122 - val_loss: 0.4578 - val_accuracy: 0.8654\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 45us/sample - loss: 0.5186 - accuracy: 0.8539\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
