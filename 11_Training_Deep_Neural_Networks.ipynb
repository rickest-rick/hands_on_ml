{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0-preview is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f95490a6a58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f95490b8320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode=\"fan_avg\",\n",
    "                                                distribution=\"uniform\")\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "layer = keras.layers.Dense(10, activation=leaky_relu,\n",
    "                          kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(10, activation=\"selu\",\n",
    "                          kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1012 17:15:08.338925 140279272294208 deprecation.py:323] From /home/joschi/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4149: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),    \n",
    "    keras.layers.Dense(500, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 580,646\n",
      "Trainable params: 577,278\n",
      "Non-trainable params: 3,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'cond/Identity' type=Identity>,\n",
       " <tf.Operation 'cond_1/Identity' type=Identity>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 10s 191us/sample - loss: 0.4796 - accuracy: 0.8273 - val_loss: 0.3482 - val_accuracy: 0.8718\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.3733 - accuracy: 0.8638 - val_loss: 0.3266 - val_accuracy: 0.8762\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.3340 - accuracy: 0.8773 - val_loss: 0.3185 - val_accuracy: 0.8802\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 9s 163us/sample - loss: 0.3076 - accuracy: 0.8861 - val_loss: 0.3009 - val_accuracy: 0.8924\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.2880 - accuracy: 0.8928 - val_loss: 0.2923 - val_accuracy: 0.8918\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.2669 - accuracy: 0.8999 - val_loss: 0.3091 - val_accuracy: 0.8920\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2503 - accuracy: 0.9050 - val_loss: 0.2959 - val_accuracy: 0.8950\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2366 - accuracy: 0.9103 - val_loss: 0.2907 - val_accuracy: 0.8962\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2237 - accuracy: 0.9157 - val_loss: 0.3056 - val_accuracy: 0.8916\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.2123 - accuracy: 0.9199 - val_loss: 0.2830 - val_accuracy: 0.8966\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.2019 - accuracy: 0.9236 - val_loss: 0.3076 - val_accuracy: 0.8934\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1914 - accuracy: 0.9275 - val_loss: 0.2982 - val_accuracy: 0.8946\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1849 - accuracy: 0.9297 - val_loss: 0.3040 - val_accuracy: 0.8962\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1739 - accuracy: 0.9339 - val_loss: 0.3039 - val_accuracy: 0.9004\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1671 - accuracy: 0.9367 - val_loss: 0.3200 - val_accuracy: 0.8950\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1565 - accuracy: 0.9416 - val_loss: 0.3125 - val_accuracy: 0.8996\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1539 - accuracy: 0.9409 - val_loss: 0.3225 - val_accuracy: 0.9048\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1455 - accuracy: 0.9438 - val_loss: 0.3397 - val_accuracy: 0.8950\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1426 - accuracy: 0.9459 - val_loss: 0.3626 - val_accuracy: 0.8936\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1353 - accuracy: 0.9488 - val_loss: 0.3254 - val_accuracy: 0.9040\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                 restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.3114 - accuracy: 0.8935\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: my_model_A.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8f5cc3520da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_model_A.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_B_on_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_B_on_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_saved_model_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m                   (export_dir,\n\u001b[1;32m     82\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: my_model_A.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\",\n",
    "                    metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponantial_decay(lr0, s):\n",
    "    def exponantial_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponantial_decay_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.4228 - accuracy: 0.8471 - val_loss: 0.3781 - val_accuracy: 0.8616\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.3611 - accuracy: 0.8666 - val_loss: 0.3554 - val_accuracy: 0.8728\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.3297 - accuracy: 0.8780 - val_loss: 0.3551 - val_accuracy: 0.8700\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.3030 - accuracy: 0.8868 - val_loss: 0.3379 - val_accuracy: 0.8766\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.2832 - accuracy: 0.8940 - val_loss: 0.3142 - val_accuracy: 0.8864\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.2597 - accuracy: 0.9022 - val_loss: 0.3200 - val_accuracy: 0.8820\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2378 - accuracy: 0.9122 - val_loss: 0.2996 - val_accuracy: 0.8962\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.2209 - accuracy: 0.9162 - val_loss: 0.3023 - val_accuracy: 0.8968\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.2047 - accuracy: 0.9223 - val_loss: 0.2950 - val_accuracy: 0.8894\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1888 - accuracy: 0.9287 - val_loss: 0.2990 - val_accuracy: 0.8964\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.1768 - accuracy: 0.9324 - val_loss: 0.3081 - val_accuracy: 0.8982\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.1629 - accuracy: 0.9375 - val_loss: 0.3204 - val_accuracy: 0.9008\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1514 - accuracy: 0.9426 - val_loss: 0.3265 - val_accuracy: 0.9018\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1418 - accuracy: 0.9459 - val_loss: 0.3266 - val_accuracy: 0.8998\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.1305 - accuracy: 0.9503 - val_loss: 0.3375 - val_accuracy: 0.8994\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1202 - accuracy: 0.9543 - val_loss: 0.3497 - val_accuracy: 0.8960\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1129 - accuracy: 0.9567 - val_loss: 0.3614 - val_accuracy: 0.9018\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1072 - accuracy: 0.9583 - val_loss: 0.3622 - val_accuracy: 0.9040\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.0978 - accuracy: 0.9625 - val_loss: 0.3631 - val_accuracy: 0.9014\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.3235 - accuracy: 0.8872\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),    \n",
    "    keras.layers.Dense(500, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 10s 183us/sample - loss: 0.4834 - accuracy: 0.8257 - val_loss: 0.3731 - val_accuracy: 0.8668\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.3783 - accuracy: 0.8611 - val_loss: 0.3338 - val_accuracy: 0.8802\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.3350 - accuracy: 0.8759 - val_loss: 0.3071 - val_accuracy: 0.8882\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.3086 - accuracy: 0.8862 - val_loss: 0.3003 - val_accuracy: 0.8890\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.2837 - accuracy: 0.8934 - val_loss: 0.3234 - val_accuracy: 0.8830\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2645 - accuracy: 0.9016 - val_loss: 0.2902 - val_accuracy: 0.8944\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.2496 - accuracy: 0.9066 - val_loss: 0.2904 - val_accuracy: 0.8886\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.2377 - accuracy: 0.9099 - val_loss: 0.2809 - val_accuracy: 0.9010\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.2204 - accuracy: 0.9166 - val_loss: 0.2982 - val_accuracy: 0.8930\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.2124 - accuracy: 0.9201 - val_loss: 0.2768 - val_accuracy: 0.8988\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.2001 - accuracy: 0.9252 - val_loss: 0.2891 - val_accuracy: 0.8960\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.1930 - accuracy: 0.9269 - val_loss: 0.2899 - val_accuracy: 0.9036\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1796 - accuracy: 0.9322 - val_loss: 0.2992 - val_accuracy: 0.9024\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 9s 170us/sample - loss: 0.1742 - accuracy: 0.9336 - val_loss: 0.2945 - val_accuracy: 0.9026\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.1656 - accuracy: 0.9378 - val_loss: 0.3016 - val_accuracy: 0.9020\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 9s 163us/sample - loss: 0.1277 - accuracy: 0.9522 - val_loss: 0.3032 - val_accuracy: 0.9052\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 9s 165us/sample - loss: 0.1201 - accuracy: 0.9545 - val_loss: 0.3143 - val_accuracy: 0.9036\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.1122 - accuracy: 0.9575 - val_loss: 0.3214 - val_accuracy: 0.9036\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 9s 164us/sample - loss: 0.1039 - accuracy: 0.9605 - val_loss: 0.3364 - val_accuracy: 0.9060\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.1002 - accuracy: 0.9624 - val_loss: 0.3403 - val_accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.3197 - accuracy: 0.8930\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 20 * len(X_train) // 32\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation=\"selu\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(500),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\", \n",
    "                     kernel_initializer=\"glorot_uniform\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 2.8658 - accuracy: 0.7750 - val_loss: 0.8761 - val_accuracy: 0.8128\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.9082 - accuracy: 0.7919 - val_loss: 0.8718 - val_accuracy: 0.8016\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.8767 - accuracy: 0.8004 - val_loss: 0.8829 - val_accuracy: 0.7988\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8718 - accuracy: 0.8033 - val_loss: 0.8341 - val_accuracy: 0.8200\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.8700 - accuracy: 0.8036 - val_loss: 0.8887 - val_accuracy: 0.7982\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8619 - accuracy: 0.8080 - val_loss: 0.8167 - val_accuracy: 0.8250\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8603 - accuracy: 0.8057 - val_loss: 0.8326 - val_accuracy: 0.8194\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.8562 - accuracy: 0.8077 - val_loss: 0.8702 - val_accuracy: 0.8074\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.8609 - accuracy: 0.8060 - val_loss: 0.8909 - val_accuracy: 0.8032\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.8561 - accuracy: 0.8089 - val_loss: 0.8249 - val_accuracy: 0.8216\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.8554 - accuracy: 0.8096 - val_loss: 0.8230 - val_accuracy: 0.8266\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8522 - accuracy: 0.8099 - val_loss: 0.8287 - val_accuracy: 0.8254\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.8536 - accuracy: 0.8110 - val_loss: 0.8832 - val_accuracy: 0.7940\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8533 - accuracy: 0.8101 - val_loss: 0.8525 - val_accuracy: 0.8048\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.8539 - accuracy: 0.8126 - val_loss: 0.8251 - val_accuracy: 0.8222\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.8502 - accuracy: 0.8104 - val_loss: 0.8117 - val_accuracy: 0.8260\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.8554 - accuracy: 0.8111 - val_loss: 0.8308 - val_accuracy: 0.8178\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8477 - accuracy: 0.8126 - val_loss: 0.8179 - val_accuracy: 0.8228\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.8568 - accuracy: 0.8116 - val_loss: 0.7967 - val_accuracy: 0.8276\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.8510 - accuracy: 0.8123 - val_loss: 0.8511 - val_accuracy: 0.8180\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8487 - accuracy: 0.8135 - val_loss: 0.8178 - val_accuracy: 0.8284\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.8505 - accuracy: 0.8115 - val_loss: 0.8022 - val_accuracy: 0.8308\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.8479 - accuracy: 0.8131 - val_loss: 0.8318 - val_accuracy: 0.8176\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8514 - accuracy: 0.8135 - val_loss: 0.8630 - val_accuracy: 0.8072\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.8447 - accuracy: 0.8156 - val_loss: 0.8080 - val_accuracy: 0.8318\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.8553 - accuracy: 0.8117 - val_loss: 0.8222 - val_accuracy: 0.8282\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.8409 - accuracy: 0.8162 - val_loss: 0.8641 - val_accuracy: 0.8040\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8515 - accuracy: 0.8134 - val_loss: 0.9340 - val_accuracy: 0.7928\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.8470 - accuracy: 0.8156 - val_loss: 0.8275 - val_accuracy: 0.8240\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   epochs=100,\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 45us/sample - loss: 0.8363 - accuracy: 0.8149\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(500, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.4889 - accuracy: 0.8212 - val_loss: 0.4183 - val_accuracy: 0.8498\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.3805 - accuracy: 0.8591 - val_loss: 0.3478 - val_accuracy: 0.8786\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.3406 - accuracy: 0.8719 - val_loss: 0.3615 - val_accuracy: 0.8650\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.3203 - accuracy: 0.8797 - val_loss: 0.3548 - val_accuracy: 0.8648\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.3001 - accuracy: 0.8859 - val_loss: 0.3459 - val_accuracy: 0.8760\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.2853 - accuracy: 0.8922 - val_loss: 0.3396 - val_accuracy: 0.8752\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.2681 - accuracy: 0.8996 - val_loss: 0.3285 - val_accuracy: 0.8810\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.2600 - accuracy: 0.9030 - val_loss: 0.3061 - val_accuracy: 0.8936\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.2493 - accuracy: 0.9055 - val_loss: 0.3222 - val_accuracy: 0.8860\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.2394 - accuracy: 0.9088 - val_loss: 0.3111 - val_accuracy: 0.8940\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.2294 - accuracy: 0.9128 - val_loss: 0.3510 - val_accuracy: 0.8812\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.2222 - accuracy: 0.9150 - val_loss: 0.2999 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.2138 - accuracy: 0.9177 - val_loss: 0.3218 - val_accuracy: 0.8898\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.2038 - accuracy: 0.9216 - val_loss: 0.3337 - val_accuracy: 0.8940\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.1999 - accuracy: 0.9243 - val_loss: 0.3127 - val_accuracy: 0.8984\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1902 - accuracy: 0.9275 - val_loss: 0.3812 - val_accuracy: 0.8928\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.1872 - accuracy: 0.9273 - val_loss: 0.3259 - val_accuracy: 0.8944\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.1797 - accuracy: 0.9305 - val_loss: 0.3583 - val_accuracy: 0.8926\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.1780 - accuracy: 0.9327 - val_loss: 0.3524 - val_accuracy: 0.8956\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.1769 - accuracy: 0.9331 - val_loss: 0.3513 - val_accuracy: 0.8972\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.1648 - accuracy: 0.9364 - val_loss: 0.3760 - val_accuracy: 0.8926\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.1634 - accuracy: 0.9378 - val_loss: 0.3549 - val_accuracy: 0.9036\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.3443 - accuracy: 0.8859\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=15,\n",
    "                                                 restore_best_weights=True)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(500, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.3),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.7214 - accuracy: 0.7420 - val_loss: 0.4442 - val_accuracy: 0.8366\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.5416 - accuracy: 0.7999 - val_loss: 0.3864 - val_accuracy: 0.8570\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.4939 - accuracy: 0.8174 - val_loss: 0.3820 - val_accuracy: 0.8576\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.4633 - accuracy: 0.8276 - val_loss: 0.3670 - val_accuracy: 0.8654\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.4464 - accuracy: 0.8345 - val_loss: 0.3637 - val_accuracy: 0.8666\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.4277 - accuracy: 0.8389 - val_loss: 0.3530 - val_accuracy: 0.8642\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.4192 - accuracy: 0.8448 - val_loss: 0.3413 - val_accuracy: 0.8754\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.4051 - accuracy: 0.8484 - val_loss: 0.3333 - val_accuracy: 0.8690\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.4005 - accuracy: 0.8503 - val_loss: 0.3179 - val_accuracy: 0.8808\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3923 - accuracy: 0.8533 - val_loss: 0.3191 - val_accuracy: 0.8798\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3842 - accuracy: 0.8567 - val_loss: 0.3189 - val_accuracy: 0.8806\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3803 - accuracy: 0.8589 - val_loss: 0.3147 - val_accuracy: 0.8808\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3751 - accuracy: 0.8598 - val_loss: 0.3148 - val_accuracy: 0.8826\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3684 - accuracy: 0.8631 - val_loss: 0.3127 - val_accuracy: 0.8860\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3656 - accuracy: 0.8642 - val_loss: 0.2992 - val_accuracy: 0.8888\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3620 - accuracy: 0.8651 - val_loss: 0.3058 - val_accuracy: 0.8876\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3577 - accuracy: 0.8673 - val_loss: 0.3011 - val_accuracy: 0.8862\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3537 - accuracy: 0.8676 - val_loss: 0.3022 - val_accuracy: 0.8910\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3535 - accuracy: 0.8702 - val_loss: 0.3080 - val_accuracy: 0.8886\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3511 - accuracy: 0.8702 - val_loss: 0.2888 - val_accuracy: 0.8900\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3449 - accuracy: 0.8715 - val_loss: 0.2910 - val_accuracy: 0.8928\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3460 - accuracy: 0.8721 - val_loss: 0.2907 - val_accuracy: 0.8942\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3439 - accuracy: 0.8715 - val_loss: 0.2920 - val_accuracy: 0.8914\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3411 - accuracy: 0.8738 - val_loss: 0.2914 - val_accuracy: 0.8938\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3370 - accuracy: 0.8746 - val_loss: 0.2886 - val_accuracy: 0.8916\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3327 - accuracy: 0.8749 - val_loss: 0.2816 - val_accuracy: 0.8940\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3357 - accuracy: 0.8750 - val_loss: 0.2823 - val_accuracy: 0.8974\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3323 - accuracy: 0.8756 - val_loss: 0.2863 - val_accuracy: 0.8940\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3307 - accuracy: 0.8766 - val_loss: 0.2864 - val_accuracy: 0.8930\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3296 - accuracy: 0.8772 - val_loss: 0.2904 - val_accuracy: 0.8914\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3287 - accuracy: 0.8774 - val_loss: 0.2894 - val_accuracy: 0.8950\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3242 - accuracy: 0.8783 - val_loss: 0.2821 - val_accuracy: 0.8936\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3222 - accuracy: 0.8803 - val_loss: 0.2852 - val_accuracy: 0.8956\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3227 - accuracy: 0.8790 - val_loss: 0.2834 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3196 - accuracy: 0.8800 - val_loss: 0.2882 - val_accuracy: 0.8956\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3180 - accuracy: 0.8808 - val_loss: 0.2841 - val_accuracy: 0.8940\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3170 - accuracy: 0.8802 - val_loss: 0.2901 - val_accuracy: 0.8954\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3192 - accuracy: 0.8807 - val_loss: 0.2885 - val_accuracy: 0.8964\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3168 - accuracy: 0.8820 - val_loss: 0.2859 - val_accuracy: 0.8976\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3146 - accuracy: 0.8823 - val_loss: 0.2844 - val_accuracy: 0.8960\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3145 - accuracy: 0.8815 - val_loss: 0.2779 - val_accuracy: 0.8998\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3091 - accuracy: 0.8840 - val_loss: 0.2835 - val_accuracy: 0.8926\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3117 - accuracy: 0.8831 - val_loss: 0.2885 - val_accuracy: 0.8922\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3107 - accuracy: 0.8848 - val_loss: 0.2850 - val_accuracy: 0.8960\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3080 - accuracy: 0.8848 - val_loss: 0.2771 - val_accuracy: 0.8996\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3081 - accuracy: 0.8845 - val_loss: 0.2796 - val_accuracy: 0.8996\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3049 - accuracy: 0.8862 - val_loss: 0.2806 - val_accuracy: 0.8988\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3049 - accuracy: 0.8866 - val_loss: 0.2801 - val_accuracy: 0.8998\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3061 - accuracy: 0.8851 - val_loss: 0.2795 - val_accuracy: 0.8970\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3041 - accuracy: 0.8881 - val_loss: 0.2863 - val_accuracy: 0.8978\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.3045 - accuracy: 0.8860 - val_loss: 0.2760 - val_accuracy: 0.8984\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3022 - accuracy: 0.8850 - val_loss: 0.2739 - val_accuracy: 0.8996\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3006 - accuracy: 0.8868 - val_loss: 0.2741 - val_accuracy: 0.8990\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.3013 - accuracy: 0.8860 - val_loss: 0.2835 - val_accuracy: 0.8984\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3010 - accuracy: 0.8867 - val_loss: 0.2827 - val_accuracy: 0.8952\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2980 - accuracy: 0.8884 - val_loss: 0.2777 - val_accuracy: 0.9008\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.2990 - accuracy: 0.8891 - val_loss: 0.2866 - val_accuracy: 0.8996\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2983 - accuracy: 0.8889 - val_loss: 0.2815 - val_accuracy: 0.9014\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2947 - accuracy: 0.8883 - val_loss: 0.2825 - val_accuracy: 0.9008\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2958 - accuracy: 0.8884 - val_loss: 0.2789 - val_accuracy: 0.9020\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2943 - accuracy: 0.8894 - val_loss: 0.2733 - val_accuracy: 0.9010\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2940 - accuracy: 0.8902 - val_loss: 0.2779 - val_accuracy: 0.9006\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2913 - accuracy: 0.8892 - val_loss: 0.2767 - val_accuracy: 0.8972\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2968 - accuracy: 0.8885 - val_loss: 0.2791 - val_accuracy: 0.8994\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.2915 - accuracy: 0.8911 - val_loss: 0.2734 - val_accuracy: 0.9032\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2921 - accuracy: 0.8904 - val_loss: 0.2714 - val_accuracy: 0.8994\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2921 - accuracy: 0.8913 - val_loss: 0.2733 - val_accuracy: 0.9006\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2941 - accuracy: 0.8914 - val_loss: 0.2725 - val_accuracy: 0.9014\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2873 - accuracy: 0.8915 - val_loss: 0.2659 - val_accuracy: 0.9044\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2901 - accuracy: 0.8913 - val_loss: 0.2784 - val_accuracy: 0.9010\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2904 - accuracy: 0.8916 - val_loss: 0.2885 - val_accuracy: 0.8984\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2868 - accuracy: 0.8919 - val_loss: 0.2719 - val_accuracy: 0.9006\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2866 - accuracy: 0.8925 - val_loss: 0.2803 - val_accuracy: 0.9048\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2873 - accuracy: 0.8914 - val_loss: 0.2742 - val_accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2841 - accuracy: 0.8925 - val_loss: 0.2727 - val_accuracy: 0.9020\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2865 - accuracy: 0.8924 - val_loss: 0.2754 - val_accuracy: 0.9006\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2879 - accuracy: 0.8922 - val_loss: 0.2795 - val_accuracy: 0.9010\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2849 - accuracy: 0.8939 - val_loss: 0.2719 - val_accuracy: 0.9026\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2856 - accuracy: 0.8937 - val_loss: 0.2742 - val_accuracy: 0.9030\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2832 - accuracy: 0.8937 - val_loss: 0.2824 - val_accuracy: 0.8992\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2804 - accuracy: 0.8941 - val_loss: 0.2724 - val_accuracy: 0.9020\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2830 - accuracy: 0.8940 - val_loss: 0.2919 - val_accuracy: 0.8978\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2823 - accuracy: 0.8928 - val_loss: 0.2738 - val_accuracy: 0.9000\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.2785 - accuracy: 0.8957 - val_loss: 0.2705 - val_accuracy: 0.9030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.3036 - accuracy: 0.8902\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test, training=True)\n",
    "                       for sample in range(100)])\n",
    "\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.93]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.34, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.69, 0.  , 0.3 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.12, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.04, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.28, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.72, 0.  , 0.2 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.34, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.37, 0.  , 0.47]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.51, 0.  , 0.48]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.  , 0.  , 0.58]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.19, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.11, 0.  , 0.75]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.71, 0.  , 0.27]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.11, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.22, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.45, 0.  , 0.07, 0.  , 0.48]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.13, 0.  , 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.12, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.15, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.43, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.74, 0.  , 0.26]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.05, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.4 , 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.01, 0.  , 0.  , 0.01, 0.  , 0.1 , 0.  , 0.28, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.11, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.39, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.29, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.45, 0.  , 0.17, 0.  , 0.38]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.25, 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.4 , 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.06, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.8 , 0.  , 0.13]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.32, 0.  , 0.09, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.57, 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.13, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.42, 0.  , 0.57]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.46, 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.1 , 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.1 , 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.48, 0.  , 0.08, 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.82, 0.  , 0.18]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.16, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.01, 0.  , 0.01, 0.  , 0.23, 0.  , 0.45, 0.  , 0.28]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.01, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.25, 0.01, 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.81, 0.  , 0.06, 0.  , 0.13]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.42, 0.  , 0.57]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.17, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.94]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.2 , 0.  , 0.76]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.2 , 0.  , 0.22]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f93c835b320>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                  kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(500, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.Nadam(),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 7s 131us/sample - loss: 0.5140 - accuracy: 0.8161 - val_loss: 0.3742 - val_accuracy: 0.8668\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.3886 - accuracy: 0.8577 - val_loss: 0.3668 - val_accuracy: 0.8618\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.3539 - accuracy: 0.8694 - val_loss: 0.3511 - val_accuracy: 0.8704\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.3308 - accuracy: 0.8779 - val_loss: 0.3840 - val_accuracy: 0.8678\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.3134 - accuracy: 0.8830 - val_loss: 0.3193 - val_accuracy: 0.8858\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.3004 - accuracy: 0.8876 - val_loss: 0.3197 - val_accuracy: 0.8898\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.2868 - accuracy: 0.8928 - val_loss: 0.3477 - val_accuracy: 0.8804\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.2778 - accuracy: 0.8959 - val_loss: 0.3068 - val_accuracy: 0.8924\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.2678 - accuracy: 0.8993 - val_loss: 0.3260 - val_accuracy: 0.8820\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.2573 - accuracy: 0.9019 - val_loss: 0.3201 - val_accuracy: 0.8890\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.2498 - accuracy: 0.9059 - val_loss: 0.3313 - val_accuracy: 0.8892\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.2420 - accuracy: 0.9089 - val_loss: 0.3327 - val_accuracy: 0.8904\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.2327 - accuracy: 0.9118 - val_loss: 0.3506 - val_accuracy: 0.8832\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.1838 - accuracy: 0.9278 - val_loss: 0.3012 - val_accuracy: 0.8986\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.1698 - accuracy: 0.9346 - val_loss: 0.3182 - val_accuracy: 0.8994\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.1634 - accuracy: 0.9363 - val_loss: 0.3363 - val_accuracy: 0.8972\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.1551 - accuracy: 0.9395 - val_loss: 0.3272 - val_accuracy: 0.9014\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.1475 - accuracy: 0.9421 - val_loss: 0.3550 - val_accuracy: 0.8938\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.1417 - accuracy: 0.9447 - val_loss: 0.3956 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.1084 - accuracy: 0.9575 - val_loss: 0.3813 - val_accuracy: 0.9016\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.1024 - accuracy: 0.9600 - val_loss: 0.3779 - val_accuracy: 0.9034\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.0958 - accuracy: 0.9626 - val_loss: 0.3919 - val_accuracy: 0.9026\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.0901 - accuracy: 0.9652 - val_loss: 0.3912 - val_accuracy: 0.9024\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.0841 - accuracy: 0.9672 - val_loss: 0.4215 - val_accuracy: 0.9012\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.0669 - accuracy: 0.9746 - val_loss: 0.4327 - val_accuracy: 0.9022\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.0620 - accuracy: 0.9763 - val_loss: 0.4504 - val_accuracy: 0.9066\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.0588 - accuracy: 0.9778 - val_loss: 0.4476 - val_accuracy: 0.9060\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.0545 - accuracy: 0.9794 - val_loss: 0.4695 - val_accuracy: 0.9038\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.0517 - accuracy: 0.9805 - val_loss: 0.4759 - val_accuracy: 0.9058\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.3351 - accuracy: 0.8917\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.1),\n",
    "    keras.layers.Dense(500, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.3),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.1),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.Nadam(),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 12s 214us/sample - loss: 0.8786 - accuracy: 0.6698 - val_loss: 0.7569 - val_accuracy: 0.7676\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.7258 - accuracy: 0.7285 - val_loss: 0.8173 - val_accuracy: 0.7730\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.6839 - accuracy: 0.7431 - val_loss: 0.7621 - val_accuracy: 0.7872\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.6619 - accuracy: 0.7511 - val_loss: 0.6520 - val_accuracy: 0.8092\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.6478 - accuracy: 0.7566 - val_loss: 0.7159 - val_accuracy: 0.7988\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.6315 - accuracy: 0.7633 - val_loss: 0.5826 - val_accuracy: 0.8220\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.6199 - accuracy: 0.7666 - val_loss: 0.6834 - val_accuracy: 0.8202\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.6187 - accuracy: 0.7657 - val_loss: 0.6171 - val_accuracy: 0.8102\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.6166 - accuracy: 0.7667 - val_loss: 0.6643 - val_accuracy: 0.8262\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.6122 - accuracy: 0.7725 - val_loss: 0.6188 - val_accuracy: 0.8260\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.6068 - accuracy: 0.7719 - val_loss: 0.6131 - val_accuracy: 0.8312\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5782 - accuracy: 0.7815 - val_loss: 0.5706 - val_accuracy: 0.8282\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5709 - accuracy: 0.7841 - val_loss: 0.5597 - val_accuracy: 0.8352\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5661 - accuracy: 0.7857 - val_loss: 0.6258 - val_accuracy: 0.8300\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.5644 - accuracy: 0.7882 - val_loss: 0.5568 - val_accuracy: 0.8384\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.5615 - accuracy: 0.7889 - val_loss: 0.5016 - val_accuracy: 0.8462\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.5614 - accuracy: 0.7885 - val_loss: 0.5399 - val_accuracy: 0.8438\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.5567 - accuracy: 0.7900 - val_loss: 0.5088 - val_accuracy: 0.8478\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5551 - accuracy: 0.7916 - val_loss: 0.5937 - val_accuracy: 0.8350\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5510 - accuracy: 0.7904 - val_loss: 0.5366 - val_accuracy: 0.8470\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5539 - accuracy: 0.7894 - val_loss: 0.5051 - val_accuracy: 0.8476\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5453 - accuracy: 0.7927 - val_loss: 0.4790 - val_accuracy: 0.8568\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5340 - accuracy: 0.7954 - val_loss: 0.5330 - val_accuracy: 0.8536\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5329 - accuracy: 0.7995 - val_loss: 0.5079 - val_accuracy: 0.8518\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5348 - accuracy: 0.7958 - val_loss: 0.4950 - val_accuracy: 0.8444\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 11s 199us/sample - loss: 0.5329 - accuracy: 0.7972 - val_loss: 0.4978 - val_accuracy: 0.8562\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5293 - accuracy: 0.8009 - val_loss: 0.4689 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5300 - accuracy: 0.7995 - val_loss: 0.4921 - val_accuracy: 0.8590\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5265 - accuracy: 0.7997 - val_loss: 0.5055 - val_accuracy: 0.8558\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5284 - accuracy: 0.8005 - val_loss: 0.5003 - val_accuracy: 0.8492\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5258 - accuracy: 0.8016 - val_loss: 0.4850 - val_accuracy: 0.8560\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5287 - accuracy: 0.7995 - val_loss: 0.4895 - val_accuracy: 0.8574\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5199 - accuracy: 0.8005 - val_loss: 0.4895 - val_accuracy: 0.8564\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.5168 - accuracy: 0.8038 - val_loss: 0.4730 - val_accuracy: 0.8586\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5186 - accuracy: 0.8050 - val_loss: 0.4915 - val_accuracy: 0.8558\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5226 - accuracy: 0.8014 - val_loss: 0.4927 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5218 - accuracy: 0.8021 - val_loss: 0.4774 - val_accuracy: 0.8548\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5120 - accuracy: 0.8058 - val_loss: 0.4730 - val_accuracy: 0.8556\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5124 - accuracy: 0.8057 - val_loss: 0.4706 - val_accuracy: 0.8580\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5127 - accuracy: 0.8041 - val_loss: 0.4777 - val_accuracy: 0.8588\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5133 - accuracy: 0.8049 - val_loss: 0.4708 - val_accuracy: 0.8582\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 11s 200us/sample - loss: 0.5115 - accuracy: 0.8071 - val_loss: 0.4814 - val_accuracy: 0.8610\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 45us/sample - loss: 0.5545 - accuracy: 0.8407\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### 1. Is it okay to initialize all the weights to the same value as long as that value is selected randomly using He initialization?\n",
    "\n",
    "No, because \n",
    "\n",
    "### 2. Is it okay to initialize the bias terms to 0?\n",
    "\n",
    "Yes, because\n",
    "\n",
    "### 3. Name three advantages of the SELU activation function over ReLU.\n",
    "1. differentiable at 0\n",
    "2. non-zero gradients for negative inputs\n",
    "3. self-normalising as long as the net only consists of dense layers and all layers use SELU as activation function and the following conditions are met:\n",
    "  3.1 input features must be standardized (mean 0 and standard deviation 1)\n",
    "  3.2 hidden layer's weight must be initialized using LeCun normal initialization\n",
    "  3.3 network's architecture must be sequential\n",
    "\n",
    "### 4. In which cases would you want to use each of the following activation functions: SELU, leaky ReLU (and its variants), ReLU, tanh, logistic, and softmax?\n",
    "SELU: \n",
    "\n",
    "leaky ReLU:\n",
    "\n",
    "ReLU:\n",
    "\n",
    "tanh:\n",
    "\n",
    "logistic: \n",
    "\n",
    "softmax: \n",
    "\n",
    "### 5. What may happen if you set the momentum hyperparameter too close to 1 (e.g., 0.99999) when using an SGD optimizer?\n",
    "\n",
    "\n",
    "### 6. Name three ways you can produce a sparse model.\n",
    "1. strong l1 regularization\n",
    "2. set very tiny values to 0\n",
    "3. apply Dual Averaging\n",
    "\n",
    "### 7. Does dropout slow down training? Does it slow down inference (i.e., making predictions on new instances)? What are about MC dropout?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Pretraining on an auxiliary task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
